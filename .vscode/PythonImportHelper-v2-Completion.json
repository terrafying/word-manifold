[
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "NamedTuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "NamedTuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TYPE_CHECKING",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "NamedTuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "NamedTuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "auto",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "auto",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "auto",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "auto",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "auto",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "auto",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "auto",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "auto",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "auto",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "auto",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "euclidean_distances",
        "importPath": "sklearn.metrics.pairwise",
        "description": "sklearn.metrics.pairwise",
        "isExtraImport": true,
        "detail": "sklearn.metrics.pairwise",
        "documentation": {}
    },
    {
        "label": "cosine_distances",
        "importPath": "sklearn.metrics.pairwise",
        "description": "sklearn.metrics.pairwise",
        "isExtraImport": true,
        "detail": "sklearn.metrics.pairwise",
        "documentation": {}
    },
    {
        "label": "euclidean_distances",
        "importPath": "sklearn.metrics.pairwise",
        "description": "sklearn.metrics.pairwise",
        "isExtraImport": true,
        "detail": "sklearn.metrics.pairwise",
        "documentation": {}
    },
    {
        "label": "euclidean_distances",
        "importPath": "sklearn.metrics.pairwise",
        "description": "sklearn.metrics.pairwise",
        "isExtraImport": true,
        "detail": "sklearn.metrics.pairwise",
        "documentation": {}
    },
    {
        "label": "cosine_distances",
        "importPath": "sklearn.metrics.pairwise",
        "description": "sklearn.metrics.pairwise",
        "isExtraImport": true,
        "detail": "sklearn.metrics.pairwise",
        "documentation": {}
    },
    {
        "label": "euclidean_distances",
        "importPath": "sklearn.metrics.pairwise",
        "description": "sklearn.metrics.pairwise",
        "isExtraImport": true,
        "detail": "sklearn.metrics.pairwise",
        "documentation": {}
    },
    {
        "label": "Counter",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "Counter",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "Counter",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "Counter",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "Counter",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "CellType",
        "importPath": "word_manifold.types",
        "description": "word_manifold.types",
        "isExtraImport": true,
        "detail": "word_manifold.types",
        "documentation": {}
    },
    {
        "label": "DistanceType",
        "importPath": "word_manifold.types",
        "description": "word_manifold.types",
        "isExtraImport": true,
        "detail": "word_manifold.types",
        "documentation": {}
    },
    {
        "label": "CellType",
        "importPath": "word_manifold.types",
        "description": "word_manifold.types",
        "isExtraImport": true,
        "detail": "word_manifold.types",
        "documentation": {}
    },
    {
        "label": "DistanceType",
        "importPath": "word_manifold.types",
        "description": "word_manifold.types",
        "isExtraImport": true,
        "detail": "word_manifold.types",
        "documentation": {}
    },
    {
        "label": "CellType",
        "importPath": "word_manifold.types",
        "description": "word_manifold.types",
        "isExtraImport": true,
        "detail": "word_manifold.types",
        "documentation": {}
    },
    {
        "label": "CellType",
        "importPath": "word_manifold.types",
        "description": "word_manifold.types",
        "isExtraImport": true,
        "detail": "word_manifold.types",
        "documentation": {}
    },
    {
        "label": "CellType",
        "importPath": "word_manifold.types",
        "description": "word_manifold.types",
        "isExtraImport": true,
        "detail": "word_manifold.types",
        "documentation": {}
    },
    {
        "label": "DistanceType",
        "importPath": "word_manifold.types",
        "description": "word_manifold.types",
        "isExtraImport": true,
        "detail": "word_manifold.types",
        "documentation": {}
    },
    {
        "label": "VectorManifold",
        "importPath": "word_manifold.manifold.vector_manifold",
        "description": "word_manifold.manifold.vector_manifold",
        "isExtraImport": true,
        "detail": "word_manifold.manifold.vector_manifold",
        "documentation": {}
    },
    {
        "label": "VectorManifold",
        "importPath": "word_manifold.manifold.vector_manifold",
        "description": "word_manifold.manifold.vector_manifold",
        "isExtraImport": true,
        "detail": "word_manifold.manifold.vector_manifold",
        "documentation": {}
    },
    {
        "label": "Cell",
        "importPath": "word_manifold.manifold.vector_manifold",
        "description": "word_manifold.manifold.vector_manifold",
        "isExtraImport": true,
        "detail": "word_manifold.manifold.vector_manifold",
        "documentation": {}
    },
    {
        "label": "CellType",
        "importPath": "word_manifold.manifold.vector_manifold",
        "description": "word_manifold.manifold.vector_manifold",
        "isExtraImport": true,
        "detail": "word_manifold.manifold.vector_manifold",
        "documentation": {}
    },
    {
        "label": "VectorManifold",
        "importPath": "word_manifold.manifold.vector_manifold",
        "description": "word_manifold.manifold.vector_manifold",
        "isExtraImport": true,
        "detail": "word_manifold.manifold.vector_manifold",
        "documentation": {}
    },
    {
        "label": "VectorManifold",
        "importPath": "word_manifold.manifold.vector_manifold",
        "description": "word_manifold.manifold.vector_manifold",
        "isExtraImport": true,
        "detail": "word_manifold.manifold.vector_manifold",
        "documentation": {}
    },
    {
        "label": "VectorManifold",
        "importPath": "word_manifold.manifold.vector_manifold",
        "description": "word_manifold.manifold.vector_manifold",
        "isExtraImport": true,
        "detail": "word_manifold.manifold.vector_manifold",
        "documentation": {}
    },
    {
        "label": "CellType",
        "importPath": "word_manifold.manifold.vector_manifold",
        "description": "word_manifold.manifold.vector_manifold",
        "isExtraImport": true,
        "detail": "word_manifold.manifold.vector_manifold",
        "documentation": {}
    },
    {
        "label": "Cell",
        "importPath": "word_manifold.manifold.vector_manifold",
        "description": "word_manifold.manifold.vector_manifold",
        "isExtraImport": true,
        "detail": "word_manifold.manifold.vector_manifold",
        "documentation": {}
    },
    {
        "label": "VectorManifold",
        "importPath": "word_manifold.manifold.vector_manifold",
        "description": "word_manifold.manifold.vector_manifold",
        "isExtraImport": true,
        "detail": "word_manifold.manifold.vector_manifold",
        "documentation": {}
    },
    {
        "label": "CellType",
        "importPath": "word_manifold.manifold.vector_manifold",
        "description": "word_manifold.manifold.vector_manifold",
        "isExtraImport": true,
        "detail": "word_manifold.manifold.vector_manifold",
        "documentation": {}
    },
    {
        "label": "VectorManifold",
        "importPath": "word_manifold.manifold.vector_manifold",
        "description": "word_manifold.manifold.vector_manifold",
        "isExtraImport": true,
        "detail": "word_manifold.manifold.vector_manifold",
        "documentation": {}
    },
    {
        "label": "VectorManifold",
        "importPath": "word_manifold.manifold.vector_manifold",
        "description": "word_manifold.manifold.vector_manifold",
        "isExtraImport": true,
        "detail": "word_manifold.manifold.vector_manifold",
        "documentation": {}
    },
    {
        "label": "VectorManifold",
        "importPath": "word_manifold.manifold.vector_manifold",
        "description": "word_manifold.manifold.vector_manifold",
        "isExtraImport": true,
        "detail": "word_manifold.manifold.vector_manifold",
        "documentation": {}
    },
    {
        "label": "VectorManifold",
        "importPath": "word_manifold.manifold.vector_manifold",
        "description": "word_manifold.manifold.vector_manifold",
        "isExtraImport": true,
        "detail": "word_manifold.manifold.vector_manifold",
        "documentation": {}
    },
    {
        "label": "Cell",
        "importPath": "word_manifold.manifold.vector_manifold",
        "description": "word_manifold.manifold.vector_manifold",
        "isExtraImport": true,
        "detail": "word_manifold.manifold.vector_manifold",
        "documentation": {}
    },
    {
        "label": "CellType",
        "importPath": "word_manifold.manifold.vector_manifold",
        "description": "word_manifold.manifold.vector_manifold",
        "isExtraImport": true,
        "detail": "word_manifold.manifold.vector_manifold",
        "documentation": {}
    },
    {
        "label": "VectorManifold",
        "importPath": "word_manifold.manifold.vector_manifold",
        "description": "word_manifold.manifold.vector_manifold",
        "isExtraImport": true,
        "detail": "word_manifold.manifold.vector_manifold",
        "documentation": {}
    },
    {
        "label": "VectorManifold",
        "importPath": "word_manifold.manifold.vector_manifold",
        "description": "word_manifold.manifold.vector_manifold",
        "isExtraImport": true,
        "detail": "word_manifold.manifold.vector_manifold",
        "documentation": {}
    },
    {
        "label": "VectorManifold",
        "importPath": "word_manifold.manifold.vector_manifold",
        "description": "word_manifold.manifold.vector_manifold",
        "isExtraImport": true,
        "detail": "word_manifold.manifold.vector_manifold",
        "documentation": {}
    },
    {
        "label": "CellType",
        "importPath": "word_manifold.manifold.vector_manifold",
        "description": "word_manifold.manifold.vector_manifold",
        "isExtraImport": true,
        "detail": "word_manifold.manifold.vector_manifold",
        "documentation": {}
    },
    {
        "label": "VectorManifold",
        "importPath": "word_manifold.manifold.vector_manifold",
        "description": "word_manifold.manifold.vector_manifold",
        "isExtraImport": true,
        "detail": "word_manifold.manifold.vector_manifold",
        "documentation": {}
    },
    {
        "label": "CellType",
        "importPath": "word_manifold.manifold.vector_manifold",
        "description": "word_manifold.manifold.vector_manifold",
        "isExtraImport": true,
        "detail": "word_manifold.manifold.vector_manifold",
        "documentation": {}
    },
    {
        "label": "VectorManifold",
        "importPath": "word_manifold.manifold.vector_manifold",
        "description": "word_manifold.manifold.vector_manifold",
        "isExtraImport": true,
        "detail": "word_manifold.manifold.vector_manifold",
        "documentation": {}
    },
    {
        "label": "VectorManifold",
        "importPath": "word_manifold.manifold.vector_manifold",
        "description": "word_manifold.manifold.vector_manifold",
        "isExtraImport": true,
        "detail": "word_manifold.manifold.vector_manifold",
        "documentation": {}
    },
    {
        "label": "Cell",
        "importPath": "word_manifold.manifold.vector_manifold",
        "description": "word_manifold.manifold.vector_manifold",
        "isExtraImport": true,
        "detail": "word_manifold.manifold.vector_manifold",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "time",
        "importPath": "time",
        "description": "time",
        "isExtraImport": true,
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "WordEmbeddings",
        "importPath": "word_manifold.embeddings.word_embeddings",
        "description": "word_manifold.embeddings.word_embeddings",
        "isExtraImport": true,
        "detail": "word_manifold.embeddings.word_embeddings",
        "documentation": {}
    },
    {
        "label": "WordEmbeddings",
        "importPath": "word_manifold.embeddings.word_embeddings",
        "description": "word_manifold.embeddings.word_embeddings",
        "isExtraImport": true,
        "detail": "word_manifold.embeddings.word_embeddings",
        "documentation": {}
    },
    {
        "label": "WordEmbeddings",
        "importPath": "word_manifold.embeddings.word_embeddings",
        "description": "word_manifold.embeddings.word_embeddings",
        "isExtraImport": true,
        "detail": "word_manifold.embeddings.word_embeddings",
        "documentation": {}
    },
    {
        "label": "OCCULT_TERMS",
        "importPath": "word_manifold.embeddings.word_embeddings",
        "description": "word_manifold.embeddings.word_embeddings",
        "isExtraImport": true,
        "detail": "word_manifold.embeddings.word_embeddings",
        "documentation": {}
    },
    {
        "label": "WordEmbeddings",
        "importPath": "word_manifold.embeddings.word_embeddings",
        "description": "word_manifold.embeddings.word_embeddings",
        "isExtraImport": true,
        "detail": "word_manifold.embeddings.word_embeddings",
        "documentation": {}
    },
    {
        "label": "WordEmbeddings",
        "importPath": "word_manifold.embeddings.word_embeddings",
        "description": "word_manifold.embeddings.word_embeddings",
        "isExtraImport": true,
        "detail": "word_manifold.embeddings.word_embeddings",
        "documentation": {}
    },
    {
        "label": "WordEmbeddings",
        "importPath": "word_manifold.embeddings.word_embeddings",
        "description": "word_manifold.embeddings.word_embeddings",
        "isExtraImport": true,
        "detail": "word_manifold.embeddings.word_embeddings",
        "documentation": {}
    },
    {
        "label": "OCCULT_TERMS",
        "importPath": "word_manifold.embeddings.word_embeddings",
        "description": "word_manifold.embeddings.word_embeddings",
        "isExtraImport": true,
        "detail": "word_manifold.embeddings.word_embeddings",
        "documentation": {}
    },
    {
        "label": "WordEmbeddings",
        "importPath": "word_manifold.embeddings.word_embeddings",
        "description": "word_manifold.embeddings.word_embeddings",
        "isExtraImport": true,
        "detail": "word_manifold.embeddings.word_embeddings",
        "documentation": {}
    },
    {
        "label": "WordEmbeddings",
        "importPath": "word_manifold.embeddings.word_embeddings",
        "description": "word_manifold.embeddings.word_embeddings",
        "isExtraImport": true,
        "detail": "word_manifold.embeddings.word_embeddings",
        "documentation": {}
    },
    {
        "label": "WordEmbeddings",
        "importPath": "word_manifold.embeddings.word_embeddings",
        "description": "word_manifold.embeddings.word_embeddings",
        "isExtraImport": true,
        "detail": "word_manifold.embeddings.word_embeddings",
        "documentation": {}
    },
    {
        "label": "WordEmbeddings",
        "importPath": "word_manifold.embeddings.word_embeddings",
        "description": "word_manifold.embeddings.word_embeddings",
        "isExtraImport": true,
        "detail": "word_manifold.embeddings.word_embeddings",
        "documentation": {}
    },
    {
        "label": "WordEmbeddings",
        "importPath": "word_manifold.embeddings.word_embeddings",
        "description": "word_manifold.embeddings.word_embeddings",
        "isExtraImport": true,
        "detail": "word_manifold.embeddings.word_embeddings",
        "documentation": {}
    },
    {
        "label": "WordEmbeddings",
        "importPath": "word_manifold.embeddings.word_embeddings",
        "description": "word_manifold.embeddings.word_embeddings",
        "isExtraImport": true,
        "detail": "word_manifold.embeddings.word_embeddings",
        "documentation": {}
    },
    {
        "label": "WordEmbeddings",
        "importPath": "word_manifold.embeddings.word_embeddings",
        "description": "word_manifold.embeddings.word_embeddings",
        "isExtraImport": true,
        "detail": "word_manifold.embeddings.word_embeddings",
        "documentation": {}
    },
    {
        "label": "WordEmbeddings",
        "importPath": "word_manifold.embeddings.word_embeddings",
        "description": "word_manifold.embeddings.word_embeddings",
        "isExtraImport": true,
        "detail": "word_manifold.embeddings.word_embeddings",
        "documentation": {}
    },
    {
        "label": "WordEmbeddings",
        "importPath": "word_manifold.embeddings.word_embeddings",
        "description": "word_manifold.embeddings.word_embeddings",
        "isExtraImport": true,
        "detail": "word_manifold.embeddings.word_embeddings",
        "documentation": {}
    },
    {
        "label": "WordEmbeddings",
        "importPath": "word_manifold.embeddings.word_embeddings",
        "description": "word_manifold.embeddings.word_embeddings",
        "isExtraImport": true,
        "detail": "word_manifold.embeddings.word_embeddings",
        "documentation": {}
    },
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "AutoTokenizer",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "AutoModel",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "AutoTokenizer",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "AutoModel",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "AutoTokenizer",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "AutoModel",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "AutoModelForSequenceClassification",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "pipeline",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "AutoTokenizer",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "AutoModel",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "spacy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "spacy",
        "description": "spacy",
        "detail": "spacy",
        "documentation": {}
    },
    {
        "label": "Token",
        "importPath": "spacy.tokens",
        "description": "spacy.tokens",
        "isExtraImport": true,
        "detail": "spacy.tokens",
        "documentation": {}
    },
    {
        "label": "Token",
        "importPath": "spacy.tokens",
        "description": "spacy.tokens",
        "isExtraImport": true,
        "detail": "spacy.tokens",
        "documentation": {}
    },
    {
        "label": "WordEmbeddings",
        "importPath": "word_manifold.embeddings",
        "description": "word_manifold.embeddings",
        "isExtraImport": true,
        "detail": "word_manifold.embeddings",
        "documentation": {}
    },
    {
        "label": "WordEmbeddings",
        "importPath": "word_manifold.embeddings",
        "description": "word_manifold.embeddings",
        "isExtraImport": true,
        "detail": "word_manifold.embeddings",
        "documentation": {}
    },
    {
        "label": "WordEmbeddings",
        "importPath": "word_manifold.embeddings",
        "description": "word_manifold.embeddings",
        "isExtraImport": true,
        "detail": "word_manifold.embeddings",
        "documentation": {}
    },
    {
        "label": "WordEmbeddings",
        "importPath": "word_manifold.embeddings",
        "description": "word_manifold.embeddings",
        "isExtraImport": true,
        "detail": "word_manifold.embeddings",
        "documentation": {}
    },
    {
        "label": "HyperToolsVisualizer",
        "importPath": "word_manifold.visualization.hypertools_visualizer",
        "description": "word_manifold.visualization.hypertools_visualizer",
        "isExtraImport": true,
        "detail": "word_manifold.visualization.hypertools_visualizer",
        "documentation": {}
    },
    {
        "label": "HyperToolsVisualizer",
        "importPath": "word_manifold.visualization.hypertools_visualizer",
        "description": "word_manifold.visualization.hypertools_visualizer",
        "isExtraImport": true,
        "detail": "word_manifold.visualization.hypertools_visualizer",
        "documentation": {}
    },
    {
        "label": "HyperToolsVisualizer",
        "importPath": "word_manifold.visualization.hypertools_visualizer",
        "description": "word_manifold.visualization.hypertools_visualizer",
        "isExtraImport": true,
        "detail": "word_manifold.visualization.hypertools_visualizer",
        "documentation": {}
    },
    {
        "label": "HyperToolsVisualizer",
        "importPath": "word_manifold.visualization.hypertools_visualizer",
        "description": "word_manifold.visualization.hypertools_visualizer",
        "isExtraImport": true,
        "detail": "word_manifold.visualization.hypertools_visualizer",
        "documentation": {}
    },
    {
        "label": "HyperToolsVisualizer",
        "importPath": "word_manifold.visualization.hypertools_visualizer",
        "description": "word_manifold.visualization.hypertools_visualizer",
        "isExtraImport": true,
        "detail": "word_manifold.visualization.hypertools_visualizer",
        "documentation": {}
    },
    {
        "label": "HyperToolsVisualizer",
        "importPath": "word_manifold.visualization.hypertools_visualizer",
        "description": "word_manifold.visualization.hypertools_visualizer",
        "isExtraImport": true,
        "detail": "word_manifold.visualization.hypertools_visualizer",
        "documentation": {}
    },
    {
        "label": "HyperToolsVisualizer",
        "importPath": "word_manifold.visualization.hypertools_visualizer",
        "description": "word_manifold.visualization.hypertools_visualizer",
        "isExtraImport": true,
        "detail": "word_manifold.visualization.hypertools_visualizer",
        "documentation": {}
    },
    {
        "label": "HyperToolsVisualizer",
        "importPath": "word_manifold.visualization.hypertools_visualizer",
        "description": "word_manifold.visualization.hypertools_visualizer",
        "isExtraImport": true,
        "detail": "word_manifold.visualization.hypertools_visualizer",
        "documentation": {}
    },
    {
        "label": "RitualWorking",
        "importPath": "word_manifold.examples.ritual_evolution",
        "description": "word_manifold.examples.ritual_evolution",
        "isExtraImport": true,
        "detail": "word_manifold.examples.ritual_evolution",
        "documentation": {}
    },
    {
        "label": "RitualWorking",
        "importPath": "word_manifold.examples.ritual_evolution",
        "description": "word_manifold.examples.ritual_evolution",
        "isExtraImport": true,
        "detail": "word_manifold.examples.ritual_evolution",
        "documentation": {}
    },
    {
        "label": "create_predefined_rules",
        "importPath": "word_manifold.automata.cellular_rules",
        "description": "word_manifold.automata.cellular_rules",
        "isExtraImport": true,
        "detail": "word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "CellularRule",
        "importPath": "word_manifold.automata.cellular_rules",
        "description": "word_manifold.automata.cellular_rules",
        "isExtraImport": true,
        "detail": "word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "RuleParameterSet",
        "importPath": "word_manifold.automata.cellular_rules",
        "description": "word_manifold.automata.cellular_rules",
        "isExtraImport": true,
        "detail": "word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "RuleSequence",
        "importPath": "word_manifold.automata.cellular_rules",
        "description": "word_manifold.automata.cellular_rules",
        "isExtraImport": true,
        "detail": "word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "HermeticPrinciple",
        "importPath": "word_manifold.automata.cellular_rules",
        "description": "word_manifold.automata.cellular_rules",
        "isExtraImport": true,
        "detail": "word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "ElementalForce",
        "importPath": "word_manifold.automata.cellular_rules",
        "description": "word_manifold.automata.cellular_rules",
        "isExtraImport": true,
        "detail": "word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "VibrationDirection",
        "importPath": "word_manifold.automata.cellular_rules",
        "description": "word_manifold.automata.cellular_rules",
        "isExtraImport": true,
        "detail": "word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "create_predefined_rules",
        "importPath": "word_manifold.automata.cellular_rules",
        "description": "word_manifold.automata.cellular_rules",
        "isExtraImport": true,
        "detail": "word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "create_predefined_rules",
        "importPath": "word_manifold.automata.cellular_rules",
        "description": "word_manifold.automata.cellular_rules",
        "isExtraImport": true,
        "detail": "word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "create_predefined_rules",
        "importPath": "word_manifold.automata.cellular_rules",
        "description": "word_manifold.automata.cellular_rules",
        "isExtraImport": true,
        "detail": "word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "create_predefined_sequences",
        "importPath": "word_manifold.automata.cellular_rules",
        "description": "word_manifold.automata.cellular_rules",
        "isExtraImport": true,
        "detail": "word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "create_predefined_rules",
        "importPath": "word_manifold.automata.cellular_rules",
        "description": "word_manifold.automata.cellular_rules",
        "isExtraImport": true,
        "detail": "word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "create_predefined_rules",
        "importPath": "word_manifold.automata.cellular_rules",
        "description": "word_manifold.automata.cellular_rules",
        "isExtraImport": true,
        "detail": "word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "CellularRule",
        "importPath": "word_manifold.automata.cellular_rules",
        "description": "word_manifold.automata.cellular_rules",
        "isExtraImport": true,
        "detail": "word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "RuleParameterSet",
        "importPath": "word_manifold.automata.cellular_rules",
        "description": "word_manifold.automata.cellular_rules",
        "isExtraImport": true,
        "detail": "word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "RuleSequence",
        "importPath": "word_manifold.automata.cellular_rules",
        "description": "word_manifold.automata.cellular_rules",
        "isExtraImport": true,
        "detail": "word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "HermeticPrinciple",
        "importPath": "word_manifold.automata.cellular_rules",
        "description": "word_manifold.automata.cellular_rules",
        "isExtraImport": true,
        "detail": "word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "ElementalForce",
        "importPath": "word_manifold.automata.cellular_rules",
        "description": "word_manifold.automata.cellular_rules",
        "isExtraImport": true,
        "detail": "word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "VibrationDirection",
        "importPath": "word_manifold.automata.cellular_rules",
        "description": "word_manifold.automata.cellular_rules",
        "isExtraImport": true,
        "detail": "word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "create_predefined_rules",
        "importPath": "word_manifold.automata.cellular_rules",
        "description": "word_manifold.automata.cellular_rules",
        "isExtraImport": true,
        "detail": "word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "create_predefined_rules",
        "importPath": "word_manifold.automata.cellular_rules",
        "description": "word_manifold.automata.cellular_rules",
        "isExtraImport": true,
        "detail": "word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "create_predefined_rules",
        "importPath": "word_manifold.automata.cellular_rules",
        "description": "word_manifold.automata.cellular_rules",
        "isExtraImport": true,
        "detail": "word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "CellularRule",
        "importPath": "word_manifold.automata.cellular_rules",
        "description": "word_manifold.automata.cellular_rules",
        "isExtraImport": true,
        "detail": "word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "RuleSequence",
        "importPath": "word_manifold.automata.cellular_rules",
        "description": "word_manifold.automata.cellular_rules",
        "isExtraImport": true,
        "detail": "word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "create_predefined_rules",
        "importPath": "word_manifold.automata.cellular_rules",
        "description": "word_manifold.automata.cellular_rules",
        "isExtraImport": true,
        "detail": "word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "matplotlib.animation",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.animation",
        "description": "matplotlib.animation",
        "detail": "matplotlib.animation",
        "documentation": {}
    },
    {
        "label": "FuncAnimation",
        "importPath": "matplotlib.animation",
        "description": "matplotlib.animation",
        "isExtraImport": true,
        "detail": "matplotlib.animation",
        "documentation": {}
    },
    {
        "label": "FFMpegWriter",
        "importPath": "matplotlib.animation",
        "description": "matplotlib.animation",
        "isExtraImport": true,
        "detail": "matplotlib.animation",
        "documentation": {}
    },
    {
        "label": "FuncAnimation",
        "importPath": "matplotlib.animation",
        "description": "matplotlib.animation",
        "isExtraImport": true,
        "detail": "matplotlib.animation",
        "documentation": {}
    },
    {
        "label": "FFMpegWriter",
        "importPath": "matplotlib.animation",
        "description": "matplotlib.animation",
        "isExtraImport": true,
        "detail": "matplotlib.animation",
        "documentation": {}
    },
    {
        "label": "FuncAnimation",
        "importPath": "matplotlib.animation",
        "description": "matplotlib.animation",
        "isExtraImport": true,
        "detail": "matplotlib.animation",
        "documentation": {}
    },
    {
        "label": "FuncAnimation",
        "importPath": "matplotlib.animation",
        "description": "matplotlib.animation",
        "isExtraImport": true,
        "detail": "matplotlib.animation",
        "documentation": {}
    },
    {
        "label": "FuncAnimation",
        "importPath": "matplotlib.animation",
        "description": "matplotlib.animation",
        "isExtraImport": true,
        "detail": "matplotlib.animation",
        "documentation": {}
    },
    {
        "label": "PillowWriter",
        "importPath": "matplotlib.animation",
        "description": "matplotlib.animation",
        "isExtraImport": true,
        "detail": "matplotlib.animation",
        "documentation": {}
    },
    {
        "label": "FuncAnimation",
        "importPath": "matplotlib.animation",
        "description": "matplotlib.animation",
        "isExtraImport": true,
        "detail": "matplotlib.animation",
        "documentation": {}
    },
    {
        "label": "FFMpegWriter",
        "importPath": "matplotlib.animation",
        "description": "matplotlib.animation",
        "isExtraImport": true,
        "detail": "matplotlib.animation",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "string",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "string",
        "description": "string",
        "detail": "string",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "datetime",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "datetime",
        "description": "datetime",
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "imageio",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "imageio",
        "description": "imageio",
        "detail": "imageio",
        "documentation": {}
    },
    {
        "label": "glob",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "glob",
        "description": "glob",
        "detail": "glob",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageDraw",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageFont",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageDraw",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageFont",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "PyPDF2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "PyPDF2",
        "description": "PyPDF2",
        "detail": "PyPDF2",
        "documentation": {}
    },
    {
        "label": "io",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "io",
        "description": "io",
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "StringIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "StringIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "pickle",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pickle",
        "description": "pickle",
        "detail": "pickle",
        "documentation": {}
    },
    {
        "label": "requests",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "requests",
        "description": "requests",
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "BeautifulSoup",
        "importPath": "bs4",
        "description": "bs4",
        "isExtraImport": true,
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "BeautifulSoup",
        "importPath": "bs4",
        "description": "bs4",
        "isExtraImport": true,
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "nltk",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "nltk",
        "description": "nltk",
        "detail": "nltk",
        "documentation": {}
    },
    {
        "label": "word_tokenize",
        "importPath": "nltk.tokenize",
        "description": "nltk.tokenize",
        "isExtraImport": true,
        "detail": "nltk.tokenize",
        "documentation": {}
    },
    {
        "label": "sent_tokenize",
        "importPath": "nltk.tokenize",
        "description": "nltk.tokenize",
        "isExtraImport": true,
        "detail": "nltk.tokenize",
        "documentation": {}
    },
    {
        "label": "word_tokenize",
        "importPath": "nltk.tokenize",
        "description": "nltk.tokenize",
        "isExtraImport": true,
        "detail": "nltk.tokenize",
        "documentation": {}
    },
    {
        "label": "sent_tokenize",
        "importPath": "nltk.tokenize",
        "description": "nltk.tokenize",
        "isExtraImport": true,
        "detail": "nltk.tokenize",
        "documentation": {}
    },
    {
        "label": "stopwords",
        "importPath": "nltk.corpus",
        "description": "nltk.corpus",
        "isExtraImport": true,
        "detail": "nltk.corpus",
        "documentation": {}
    },
    {
        "label": "stopwords",
        "importPath": "nltk.corpus",
        "description": "nltk.corpus",
        "isExtraImport": true,
        "detail": "nltk.corpus",
        "documentation": {}
    },
    {
        "label": "hashlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "hashlib",
        "description": "hashlib",
        "detail": "hashlib",
        "documentation": {}
    },
    {
        "label": "functools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "functools",
        "description": "functools",
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "wraps",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "wraps",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "lru_cache",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "lru_cache",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "AutomataSystem",
        "importPath": "word_manifold.automata.system",
        "description": "word_manifold.automata.system",
        "isExtraImport": true,
        "detail": "word_manifold.automata.system",
        "documentation": {}
    },
    {
        "label": "EvolutionPattern",
        "importPath": "word_manifold.automata.system",
        "description": "word_manifold.automata.system",
        "isExtraImport": true,
        "detail": "word_manifold.automata.system",
        "documentation": {}
    },
    {
        "label": "AutomataSystem",
        "importPath": "word_manifold.automata.system",
        "description": "word_manifold.automata.system",
        "isExtraImport": true,
        "detail": "word_manifold.automata.system",
        "documentation": {}
    },
    {
        "label": "EvolutionPattern",
        "importPath": "word_manifold.automata.system",
        "description": "word_manifold.automata.system",
        "isExtraImport": true,
        "detail": "word_manifold.automata.system",
        "documentation": {}
    },
    {
        "label": "SystemState",
        "importPath": "word_manifold.automata.system",
        "description": "word_manifold.automata.system",
        "isExtraImport": true,
        "detail": "word_manifold.automata.system",
        "documentation": {}
    },
    {
        "label": "AutomataSystem",
        "importPath": "word_manifold.automata.system",
        "description": "word_manifold.automata.system",
        "isExtraImport": true,
        "detail": "word_manifold.automata.system",
        "documentation": {}
    },
    {
        "label": "EvolutionPattern",
        "importPath": "word_manifold.automata.system",
        "description": "word_manifold.automata.system",
        "isExtraImport": true,
        "detail": "word_manifold.automata.system",
        "documentation": {}
    },
    {
        "label": "AutomataSystem",
        "importPath": "word_manifold.automata.system",
        "description": "word_manifold.automata.system",
        "isExtraImport": true,
        "detail": "word_manifold.automata.system",
        "documentation": {}
    },
    {
        "label": "EvolutionPattern",
        "importPath": "word_manifold.automata.system",
        "description": "word_manifold.automata.system",
        "isExtraImport": true,
        "detail": "word_manifold.automata.system",
        "documentation": {}
    },
    {
        "label": "AutomataSystem",
        "importPath": "word_manifold.automata.system",
        "description": "word_manifold.automata.system",
        "isExtraImport": true,
        "detail": "word_manifold.automata.system",
        "documentation": {}
    },
    {
        "label": "EvolutionPattern",
        "importPath": "word_manifold.automata.system",
        "description": "word_manifold.automata.system",
        "isExtraImport": true,
        "detail": "word_manifold.automata.system",
        "documentation": {}
    },
    {
        "label": "SystemState",
        "importPath": "word_manifold.automata.system",
        "description": "word_manifold.automata.system",
        "isExtraImport": true,
        "detail": "word_manifold.automata.system",
        "documentation": {}
    },
    {
        "label": "AutomataSystem",
        "importPath": "word_manifold.automata.system",
        "description": "word_manifold.automata.system",
        "isExtraImport": true,
        "detail": "word_manifold.automata.system",
        "documentation": {}
    },
    {
        "label": "EvolutionPattern",
        "importPath": "word_manifold.automata.system",
        "description": "word_manifold.automata.system",
        "isExtraImport": true,
        "detail": "word_manifold.automata.system",
        "documentation": {}
    },
    {
        "label": "AutomataSystem",
        "importPath": "word_manifold.automata.system",
        "description": "word_manifold.automata.system",
        "isExtraImport": true,
        "detail": "word_manifold.automata.system",
        "documentation": {}
    },
    {
        "label": "EvolutionPattern",
        "importPath": "word_manifold.automata.system",
        "description": "word_manifold.automata.system",
        "isExtraImport": true,
        "detail": "word_manifold.automata.system",
        "documentation": {}
    },
    {
        "label": "VectorManifold",
        "importPath": "word_manifold.manifold",
        "description": "word_manifold.manifold",
        "isExtraImport": true,
        "detail": "word_manifold.manifold",
        "documentation": {}
    },
    {
        "label": "VectorManifold",
        "importPath": "word_manifold.manifold",
        "description": "word_manifold.manifold",
        "isExtraImport": true,
        "detail": "word_manifold.manifold",
        "documentation": {}
    },
    {
        "label": "shutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shutil",
        "description": "shutil",
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "ConvexHull",
        "importPath": "scipy.spatial",
        "description": "scipy.spatial",
        "isExtraImport": true,
        "detail": "scipy.spatial",
        "documentation": {}
    },
    {
        "label": "ConvexHull",
        "importPath": "scipy.spatial",
        "description": "scipy.spatial",
        "isExtraImport": true,
        "detail": "scipy.spatial",
        "documentation": {}
    },
    {
        "label": "splprep",
        "importPath": "scipy.interpolate",
        "description": "scipy.interpolate",
        "isExtraImport": true,
        "detail": "scipy.interpolate",
        "documentation": {}
    },
    {
        "label": "splev",
        "importPath": "scipy.interpolate",
        "description": "scipy.interpolate",
        "isExtraImport": true,
        "detail": "scipy.interpolate",
        "documentation": {}
    },
    {
        "label": "Rbf",
        "importPath": "scipy.interpolate",
        "description": "scipy.interpolate",
        "isExtraImport": true,
        "detail": "scipy.interpolate",
        "documentation": {}
    },
    {
        "label": "PchipInterpolator",
        "importPath": "scipy.interpolate",
        "description": "scipy.interpolate",
        "isExtraImport": true,
        "detail": "scipy.interpolate",
        "documentation": {}
    },
    {
        "label": "PchipInterpolator",
        "importPath": "scipy.interpolate",
        "description": "scipy.interpolate",
        "isExtraImport": true,
        "detail": "scipy.interpolate",
        "documentation": {}
    },
    {
        "label": "splprep",
        "importPath": "scipy.interpolate",
        "description": "scipy.interpolate",
        "isExtraImport": true,
        "detail": "scipy.interpolate",
        "documentation": {}
    },
    {
        "label": "splev",
        "importPath": "scipy.interpolate",
        "description": "scipy.interpolate",
        "isExtraImport": true,
        "detail": "scipy.interpolate",
        "documentation": {}
    },
    {
        "label": "KMeans",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "DBSCAN",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "KMeans",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "KMeans",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "MiniBatchKMeans",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "AgglomerativeClustering",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "Birch",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "FeatureAgglomeration",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "SpectralClustering",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "KMeans",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "MiniBatchKMeans",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "AgglomerativeClustering",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "Birch",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "FeatureAgglomeration",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "SpectralClustering",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "KMeans",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "TSNE",
        "importPath": "sklearn.manifold",
        "description": "sklearn.manifold",
        "isExtraImport": true,
        "detail": "sklearn.manifold",
        "documentation": {}
    },
    {
        "label": "TSNE",
        "importPath": "sklearn.manifold",
        "description": "sklearn.manifold",
        "isExtraImport": true,
        "detail": "sklearn.manifold",
        "documentation": {}
    },
    {
        "label": "MDS",
        "importPath": "sklearn.manifold",
        "description": "sklearn.manifold",
        "isExtraImport": true,
        "detail": "sklearn.manifold",
        "documentation": {}
    },
    {
        "label": "SpectralEmbedding",
        "importPath": "sklearn.manifold",
        "description": "sklearn.manifold",
        "isExtraImport": true,
        "detail": "sklearn.manifold",
        "documentation": {}
    },
    {
        "label": "LocallyLinearEmbedding",
        "importPath": "sklearn.manifold",
        "description": "sklearn.manifold",
        "isExtraImport": true,
        "detail": "sklearn.manifold",
        "documentation": {}
    },
    {
        "label": "Isomap",
        "importPath": "sklearn.manifold",
        "description": "sklearn.manifold",
        "isExtraImport": true,
        "detail": "sklearn.manifold",
        "documentation": {}
    },
    {
        "label": "TSNE",
        "importPath": "sklearn.manifold",
        "description": "sklearn.manifold",
        "isExtraImport": true,
        "detail": "sklearn.manifold",
        "documentation": {}
    },
    {
        "label": "MDS",
        "importPath": "sklearn.manifold",
        "description": "sklearn.manifold",
        "isExtraImport": true,
        "detail": "sklearn.manifold",
        "documentation": {}
    },
    {
        "label": "SpectralEmbedding",
        "importPath": "sklearn.manifold",
        "description": "sklearn.manifold",
        "isExtraImport": true,
        "detail": "sklearn.manifold",
        "documentation": {}
    },
    {
        "label": "LocallyLinearEmbedding",
        "importPath": "sklearn.manifold",
        "description": "sklearn.manifold",
        "isExtraImport": true,
        "detail": "sklearn.manifold",
        "documentation": {}
    },
    {
        "label": "Isomap",
        "importPath": "sklearn.manifold",
        "description": "sklearn.manifold",
        "isExtraImport": true,
        "detail": "sklearn.manifold",
        "documentation": {}
    },
    {
        "label": "umap",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "umap",
        "description": "umap",
        "detail": "umap",
        "documentation": {}
    },
    {
        "label": "UMAP",
        "importPath": "umap",
        "description": "umap",
        "isExtraImport": true,
        "detail": "umap",
        "documentation": {}
    },
    {
        "label": "UMAP",
        "importPath": "umap",
        "description": "umap",
        "isExtraImport": true,
        "detail": "umap",
        "documentation": {}
    },
    {
        "label": "librosa",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "librosa",
        "description": "librosa",
        "detail": "librosa",
        "documentation": {}
    },
    {
        "label": "torch.nn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn",
        "description": "torch.nn",
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "torch.nn.functional",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn.functional",
        "description": "torch.nn.functional",
        "detail": "torch.nn.functional",
        "documentation": {}
    },
    {
        "label": "scipy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "scipy",
        "description": "scipy",
        "detail": "scipy",
        "documentation": {}
    },
    {
        "label": "signal",
        "importPath": "scipy",
        "description": "scipy",
        "isExtraImport": true,
        "detail": "scipy",
        "documentation": {}
    },
    {
        "label": "click",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "click",
        "description": "click",
        "detail": "click",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "hypertools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "hypertools",
        "description": "hypertools",
        "detail": "hypertools",
        "documentation": {}
    },
    {
        "label": "warnings",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "warnings",
        "description": "warnings",
        "detail": "warnings",
        "documentation": {}
    },
    {
        "label": "matplotlib.colors",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.colors",
        "description": "matplotlib.colors",
        "detail": "matplotlib.colors",
        "documentation": {}
    },
    {
        "label": "LinearSegmentedColormap",
        "importPath": "matplotlib.colors",
        "description": "matplotlib.colors",
        "isExtraImport": true,
        "detail": "matplotlib.colors",
        "documentation": {}
    },
    {
        "label": "Axes3D",
        "importPath": "mpl_toolkits.mplot3d",
        "description": "mpl_toolkits.mplot3d",
        "isExtraImport": true,
        "detail": "mpl_toolkits.mplot3d",
        "documentation": {}
    },
    {
        "label": "Axes3D",
        "importPath": "mpl_toolkits.mplot3d",
        "description": "mpl_toolkits.mplot3d",
        "isExtraImport": true,
        "detail": "mpl_toolkits.mplot3d",
        "documentation": {}
    },
    {
        "label": "Axes3D",
        "importPath": "mpl_toolkits.mplot3d",
        "description": "mpl_toolkits.mplot3d",
        "isExtraImport": true,
        "detail": "mpl_toolkits.mplot3d",
        "documentation": {}
    },
    {
        "label": "proj3d",
        "importPath": "mpl_toolkits.mplot3d",
        "description": "mpl_toolkits.mplot3d",
        "isExtraImport": true,
        "detail": "mpl_toolkits.mplot3d",
        "documentation": {}
    },
    {
        "label": "proj3d",
        "importPath": "mpl_toolkits.mplot3d",
        "description": "mpl_toolkits.mplot3d",
        "isExtraImport": true,
        "detail": "mpl_toolkits.mplot3d",
        "documentation": {}
    },
    {
        "label": "seaborn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "seaborn",
        "description": "seaborn",
        "detail": "seaborn",
        "documentation": {}
    },
    {
        "label": "cdist",
        "importPath": "scipy.spatial.distance",
        "description": "scipy.spatial.distance",
        "isExtraImport": true,
        "detail": "scipy.spatial.distance",
        "documentation": {}
    },
    {
        "label": "cdist",
        "importPath": "scipy.spatial.distance",
        "description": "scipy.spatial.distance",
        "isExtraImport": true,
        "detail": "scipy.spatial.distance",
        "documentation": {}
    },
    {
        "label": "cdist",
        "importPath": "scipy.spatial.distance",
        "description": "scipy.spatial.distance",
        "isExtraImport": true,
        "detail": "scipy.spatial.distance",
        "documentation": {}
    },
    {
        "label": "plotly.graph_objects",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "plotly.graph_objects",
        "description": "plotly.graph_objects",
        "detail": "plotly.graph_objects",
        "documentation": {}
    },
    {
        "label": "Dash",
        "importPath": "dash",
        "description": "dash",
        "isExtraImport": true,
        "detail": "dash",
        "documentation": {}
    },
    {
        "label": "html",
        "importPath": "dash",
        "description": "dash",
        "isExtraImport": true,
        "detail": "dash",
        "documentation": {}
    },
    {
        "label": "dcc",
        "importPath": "dash",
        "description": "dash",
        "isExtraImport": true,
        "detail": "dash",
        "documentation": {}
    },
    {
        "label": "Input",
        "importPath": "dash",
        "description": "dash",
        "isExtraImport": true,
        "detail": "dash",
        "documentation": {}
    },
    {
        "label": "Output",
        "importPath": "dash",
        "description": "dash",
        "isExtraImport": true,
        "detail": "dash",
        "documentation": {}
    },
    {
        "label": "State",
        "importPath": "dash",
        "description": "dash",
        "isExtraImport": true,
        "detail": "dash",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "Flask",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "send_from_directory",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "jsonify",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "request",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "render_template",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "PCA",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "PCA",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "PCA",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "PCA",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "FastICA",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "IncrementalPCA",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "KernelPCA",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "FactorAnalysis",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "TruncatedSVD",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "SparsePCA",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "MiniBatchSparsePCA",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "DictionaryLearning",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "MiniBatchDictionaryLearning",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "LatentDirichletAllocation",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "NMF",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "PCA",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "FastICA",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "IncrementalPCA",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "KernelPCA",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "FactorAnalysis",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "TruncatedSVD",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "SparsePCA",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "MiniBatchSparsePCA",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "DictionaryLearning",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "MiniBatchDictionaryLearning",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "LatentDirichletAllocation",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "NMF",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "LatentDirichletAllocation",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "PCA",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "colorsys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "colorsys",
        "description": "colorsys",
        "detail": "colorsys",
        "documentation": {}
    },
    {
        "label": "gaussian_filter1d",
        "importPath": "scipy.ndimage",
        "description": "scipy.ndimage",
        "isExtraImport": true,
        "detail": "scipy.ndimage",
        "documentation": {}
    },
    {
        "label": "gaussian_filter1d",
        "importPath": "scipy.ndimage",
        "description": "scipy.ndimage",
        "isExtraImport": true,
        "detail": "scipy.ndimage",
        "documentation": {}
    },
    {
        "label": "LineCollection",
        "importPath": "matplotlib.collections",
        "description": "matplotlib.collections",
        "isExtraImport": true,
        "detail": "matplotlib.collections",
        "documentation": {}
    },
    {
        "label": "LineCollection",
        "importPath": "matplotlib.collections",
        "description": "matplotlib.collections",
        "isExtraImport": true,
        "detail": "matplotlib.collections",
        "documentation": {}
    },
    {
        "label": "matplotlib.patches",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.patches",
        "description": "matplotlib.patches",
        "detail": "matplotlib.patches",
        "documentation": {}
    },
    {
        "label": "PathPatch",
        "importPath": "matplotlib.patches",
        "description": "matplotlib.patches",
        "isExtraImport": true,
        "detail": "matplotlib.patches",
        "documentation": {}
    },
    {
        "label": "PathPatch",
        "importPath": "matplotlib.patches",
        "description": "matplotlib.patches",
        "isExtraImport": true,
        "detail": "matplotlib.patches",
        "documentation": {}
    },
    {
        "label": "PathPatch",
        "importPath": "matplotlib.patches",
        "description": "matplotlib.patches",
        "isExtraImport": true,
        "detail": "matplotlib.patches",
        "documentation": {}
    },
    {
        "label": "PathPatch",
        "importPath": "matplotlib.patches",
        "description": "matplotlib.patches",
        "isExtraImport": true,
        "detail": "matplotlib.patches",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "matplotlib.path",
        "description": "matplotlib.path",
        "isExtraImport": true,
        "detail": "matplotlib.path",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "matplotlib.path",
        "description": "matplotlib.path",
        "isExtraImport": true,
        "detail": "matplotlib.path",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "matplotlib.path",
        "description": "matplotlib.path",
        "isExtraImport": true,
        "detail": "matplotlib.path",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "matplotlib.path",
        "description": "matplotlib.path",
        "isExtraImport": true,
        "detail": "matplotlib.path",
        "documentation": {}
    },
    {
        "label": "ScalarMappable",
        "importPath": "matplotlib.cm",
        "description": "matplotlib.cm",
        "isExtraImport": true,
        "detail": "matplotlib.cm",
        "documentation": {}
    },
    {
        "label": "make_subplots",
        "importPath": "plotly.subplots",
        "description": "plotly.subplots",
        "isExtraImport": true,
        "detail": "plotly.subplots",
        "documentation": {}
    },
    {
        "label": "make_subplots",
        "importPath": "plotly.subplots",
        "description": "plotly.subplots",
        "isExtraImport": true,
        "detail": "plotly.subplots",
        "documentation": {}
    },
    {
        "label": "networkx",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "networkx",
        "description": "networkx",
        "detail": "networkx",
        "documentation": {}
    },
    {
        "label": "scipy.signal",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "scipy.signal",
        "description": "scipy.signal",
        "detail": "scipy.signal",
        "documentation": {}
    },
    {
        "label": "NullFormatter",
        "importPath": "matplotlib.ticker",
        "description": "matplotlib.ticker",
        "isExtraImport": true,
        "detail": "matplotlib.ticker",
        "documentation": {}
    },
    {
        "label": "manifold",
        "importPath": "sklearn",
        "description": "sklearn",
        "isExtraImport": true,
        "detail": "sklearn",
        "documentation": {}
    },
    {
        "label": "datasets",
        "importPath": "sklearn",
        "description": "sklearn",
        "isExtraImport": true,
        "detail": "sklearn",
        "documentation": {}
    },
    {
        "label": "datasets",
        "importPath": "sklearn",
        "description": "sklearn",
        "isExtraImport": true,
        "detail": "sklearn",
        "documentation": {}
    },
    {
        "label": "datasets",
        "importPath": "sklearn",
        "description": "sklearn",
        "isExtraImport": true,
        "detail": "sklearn",
        "documentation": {}
    },
    {
        "label": "datasets",
        "importPath": "sklearn",
        "description": "sklearn",
        "isExtraImport": true,
        "detail": "sklearn",
        "documentation": {}
    },
    {
        "label": "datasets",
        "importPath": "sklearn",
        "description": "sklearn",
        "isExtraImport": true,
        "detail": "sklearn",
        "documentation": {}
    },
    {
        "label": "datasets",
        "importPath": "sklearn",
        "description": "sklearn",
        "isExtraImport": true,
        "detail": "sklearn",
        "documentation": {}
    },
    {
        "label": "datasets",
        "importPath": "sklearn",
        "description": "sklearn",
        "isExtraImport": true,
        "detail": "sklearn",
        "documentation": {}
    },
    {
        "label": "matplotlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib",
        "description": "matplotlib",
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "pyplot",
        "importPath": "matplotlib",
        "description": "matplotlib",
        "isExtraImport": true,
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "ShapeVisualizer",
        "importPath": "word_manifold.visualization.shape_visualizer",
        "description": "word_manifold.visualization.shape_visualizer",
        "isExtraImport": true,
        "detail": "word_manifold.visualization.shape_visualizer",
        "documentation": {}
    },
    {
        "label": "ShapeVisualizer",
        "importPath": "word_manifold.visualization.shape_visualizer",
        "description": "word_manifold.visualization.shape_visualizer",
        "isExtraImport": true,
        "detail": "word_manifold.visualization.shape_visualizer",
        "documentation": {}
    },
    {
        "label": "ShapeVisualizer",
        "importPath": "word_manifold.visualization.shape_visualizer",
        "description": "word_manifold.visualization.shape_visualizer",
        "isExtraImport": true,
        "detail": "word_manifold.visualization.shape_visualizer",
        "documentation": {}
    },
    {
        "label": "SemanticTreeVisualizer",
        "importPath": "word_manifold.visualization.semantic_tree_visualizer",
        "description": "word_manifold.visualization.semantic_tree_visualizer",
        "isExtraImport": true,
        "detail": "word_manifold.visualization.semantic_tree_visualizer",
        "documentation": {}
    },
    {
        "label": "SemanticNode",
        "importPath": "word_manifold.visualization.semantic_tree_visualizer",
        "description": "word_manifold.visualization.semantic_tree_visualizer",
        "isExtraImport": true,
        "detail": "word_manifold.visualization.semantic_tree_visualizer",
        "documentation": {}
    },
    {
        "label": "SemanticTreeVisualizer",
        "importPath": "word_manifold.visualization.semantic_tree_visualizer",
        "description": "word_manifold.visualization.semantic_tree_visualizer",
        "isExtraImport": true,
        "detail": "word_manifold.visualization.semantic_tree_visualizer",
        "documentation": {}
    },
    {
        "label": "PhraseEmbedder",
        "importPath": "word_manifold.embeddings.phrase_embeddings",
        "description": "word_manifold.embeddings.phrase_embeddings",
        "isExtraImport": true,
        "detail": "word_manifold.embeddings.phrase_embeddings",
        "documentation": {}
    },
    {
        "label": "orth",
        "importPath": "scipy.linalg",
        "description": "scipy.linalg",
        "isExtraImport": true,
        "detail": "scipy.linalg",
        "documentation": {}
    },
    {
        "label": "toeplitz",
        "importPath": "scipy.linalg",
        "description": "scipy.linalg",
        "isExtraImport": true,
        "detail": "scipy.linalg",
        "documentation": {}
    },
    {
        "label": "toeplitz",
        "importPath": "scipy.linalg",
        "description": "scipy.linalg",
        "isExtraImport": true,
        "detail": "scipy.linalg",
        "documentation": {}
    },
    {
        "label": "toeplitz",
        "importPath": "scipy.linalg",
        "description": "scipy.linalg",
        "isExtraImport": true,
        "detail": "scipy.linalg",
        "documentation": {}
    },
    {
        "label": "toeplitz",
        "importPath": "scipy.linalg",
        "description": "scipy.linalg",
        "isExtraImport": true,
        "detail": "scipy.linalg",
        "documentation": {}
    },
    {
        "label": "orth",
        "importPath": "scipy.linalg",
        "description": "scipy.linalg",
        "isExtraImport": true,
        "detail": "scipy.linalg",
        "documentation": {}
    },
    {
        "label": "BaseEstimator",
        "importPath": "sklearn.base",
        "description": "sklearn.base",
        "isExtraImport": true,
        "detail": "sklearn.base",
        "documentation": {}
    },
    {
        "label": "TransformerMixin",
        "importPath": "sklearn.base",
        "description": "sklearn.base",
        "isExtraImport": true,
        "detail": "sklearn.base",
        "documentation": {}
    },
    {
        "label": "BaseEstimator",
        "importPath": "sklearn.base",
        "description": "sklearn.base",
        "isExtraImport": true,
        "detail": "sklearn.base",
        "documentation": {}
    },
    {
        "label": "TransformerMixin",
        "importPath": "sklearn.base",
        "description": "sklearn.base",
        "isExtraImport": true,
        "detail": "sklearn.base",
        "documentation": {}
    },
    {
        "label": "assert_all_finite",
        "importPath": "sklearn.utils",
        "description": "sklearn.utils",
        "isExtraImport": true,
        "detail": "sklearn.utils",
        "documentation": {}
    },
    {
        "label": "assert_all_finite",
        "importPath": "sklearn.utils",
        "description": "sklearn.utils",
        "isExtraImport": true,
        "detail": "sklearn.utils",
        "documentation": {}
    },
    {
        "label": "NotFittedError",
        "importPath": "sklearn.utils.validation",
        "description": "sklearn.utils.validation",
        "isExtraImport": true,
        "detail": "sklearn.utils.validation",
        "documentation": {}
    },
    {
        "label": "check_is_fitted",
        "importPath": "sklearn.utils.validation",
        "description": "sklearn.utils.validation",
        "isExtraImport": true,
        "detail": "sklearn.utils.validation",
        "documentation": {}
    },
    {
        "label": "NotFittedError",
        "importPath": "sklearn.utils.validation",
        "description": "sklearn.utils.validation",
        "isExtraImport": true,
        "detail": "sklearn.utils.validation",
        "documentation": {}
    },
    {
        "label": "check_is_fitted",
        "importPath": "sklearn.utils.validation",
        "description": "sklearn.utils.validation",
        "isExtraImport": true,
        "detail": "sklearn.utils.validation",
        "documentation": {}
    },
    {
        "label": "copy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "copy",
        "description": "copy",
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "copy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "copy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "copy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "copy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "itertools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "itertools",
        "description": "itertools",
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "Line2D",
        "importPath": "matplotlib.lines",
        "description": "matplotlib.lines",
        "isExtraImport": true,
        "detail": "matplotlib.lines",
        "documentation": {}
    },
    {
        "label": "Line2D",
        "importPath": "matplotlib.lines",
        "description": "matplotlib.lines",
        "isExtraImport": true,
        "detail": "matplotlib.lines",
        "documentation": {}
    },
    {
        "label": "inspect",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "inspect",
        "description": "inspect",
        "detail": "inspect",
        "documentation": {}
    },
    {
        "label": "shlex",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shlex",
        "description": "shlex",
        "detail": "shlex",
        "documentation": {}
    },
    {
        "label": "traceback",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "traceback",
        "description": "traceback",
        "detail": "traceback",
        "documentation": {}
    },
    {
        "label": "contextmanager",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "redirect_stdout",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "contextmanager",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "redirect_stdout",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "getpreferredencoding",
        "importPath": "locale",
        "description": "locale",
        "isExtraImport": true,
        "detail": "locale",
        "documentation": {}
    },
    {
        "label": "getpreferredencoding",
        "importPath": "locale",
        "description": "locale",
        "isExtraImport": true,
        "detail": "locale",
        "documentation": {}
    },
    {
        "label": "subprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "subprocess",
        "description": "subprocess",
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "CalledProcessError",
        "importPath": "subprocess",
        "description": "subprocess",
        "isExtraImport": true,
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "check_output",
        "importPath": "subprocess",
        "description": "subprocess",
        "isExtraImport": true,
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "check_call",
        "importPath": "subprocess",
        "description": "subprocess",
        "isExtraImport": true,
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "CalledProcessError",
        "importPath": "subprocess",
        "description": "subprocess",
        "isExtraImport": true,
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "check_output",
        "importPath": "subprocess",
        "description": "subprocess",
        "isExtraImport": true,
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "pearsonr",
        "importPath": "scipy.stats.stats",
        "description": "scipy.stats.stats",
        "isExtraImport": true,
        "detail": "scipy.stats.stats",
        "documentation": {}
    },
    {
        "label": "pearsonr",
        "importPath": "scipy.stats.stats",
        "description": "scipy.stats.stats",
        "isExtraImport": true,
        "detail": "scipy.stats.stats",
        "documentation": {}
    },
    {
        "label": "expanduser",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "expandvars",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "expanduser",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "expandvars",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "CountVectorizer",
        "importPath": "sklearn.feature_extraction.text",
        "description": "sklearn.feature_extraction.text",
        "isExtraImport": true,
        "detail": "sklearn.feature_extraction.text",
        "documentation": {}
    },
    {
        "label": "TfidfVectorizer",
        "importPath": "sklearn.feature_extraction.text",
        "description": "sklearn.feature_extraction.text",
        "isExtraImport": true,
        "detail": "sklearn.feature_extraction.text",
        "documentation": {}
    },
    {
        "label": "CountVectorizer",
        "importPath": "sklearn.feature_extraction.text",
        "description": "sklearn.feature_extraction.text",
        "isExtraImport": true,
        "detail": "sklearn.feature_extraction.text",
        "documentation": {}
    },
    {
        "label": "TfidfVectorizer",
        "importPath": "sklearn.feature_extraction.text",
        "description": "sklearn.feature_extraction.text",
        "isExtraImport": true,
        "detail": "sklearn.feature_extraction.text",
        "documentation": {}
    },
    {
        "label": "NotFittedError",
        "importPath": "sklearn.exceptions",
        "description": "sklearn.exceptions",
        "isExtraImport": true,
        "detail": "sklearn.exceptions",
        "documentation": {}
    },
    {
        "label": "NotFittedError",
        "importPath": "sklearn.exceptions",
        "description": "sklearn.exceptions",
        "isExtraImport": true,
        "detail": "sklearn.exceptions",
        "documentation": {}
    },
    {
        "label": "Pipeline",
        "importPath": "sklearn.pipeline",
        "description": "sklearn.pipeline",
        "isExtraImport": true,
        "detail": "sklearn.pipeline",
        "documentation": {}
    },
    {
        "label": "Pipeline",
        "importPath": "sklearn.pipeline",
        "description": "sklearn.pipeline",
        "isExtraImport": true,
        "detail": "sklearn.pipeline",
        "documentation": {}
    },
    {
        "label": "get_distribution",
        "importPath": "pkg_resources",
        "description": "pkg_resources",
        "isExtraImport": true,
        "detail": "pkg_resources",
        "documentation": {}
    },
    {
        "label": "get_distribution",
        "importPath": "pkg_resources",
        "description": "pkg_resources",
        "isExtraImport": true,
        "detail": "pkg_resources",
        "documentation": {}
    },
    {
        "label": "multivariate_normal",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "multivariate_normal",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "sys,",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys.",
        "description": "sys.",
        "detail": "sys.",
        "documentation": {}
    },
    {
        "label": "sphinx_bootstrap_theme",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sphinx_bootstrap_theme",
        "description": "sphinx_bootstrap_theme",
        "detail": "sphinx_bootstrap_theme",
        "documentation": {}
    },
    {
        "label": "align",
        "importPath": "hypertools.tools.align",
        "description": "hypertools.tools.align",
        "isExtraImport": true,
        "detail": "hypertools.tools.align",
        "documentation": {}
    },
    {
        "label": "load",
        "importPath": "hypertools.tools.load",
        "description": "hypertools.tools.load",
        "isExtraImport": true,
        "detail": "hypertools.tools.load",
        "documentation": {}
    },
    {
        "label": "load",
        "importPath": "hypertools.tools.load",
        "description": "hypertools.tools.load",
        "isExtraImport": true,
        "detail": "hypertools.tools.load",
        "documentation": {}
    },
    {
        "label": "load",
        "importPath": "hypertools.tools.load",
        "description": "hypertools.tools.load",
        "isExtraImport": true,
        "detail": "hypertools.tools.load",
        "documentation": {}
    },
    {
        "label": "load",
        "importPath": "hypertools.tools.load",
        "description": "hypertools.tools.load",
        "isExtraImport": true,
        "detail": "hypertools.tools.load",
        "documentation": {}
    },
    {
        "label": "pytest",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pytest",
        "description": "pytest",
        "detail": "pytest",
        "documentation": {}
    },
    {
        "label": "cluster",
        "importPath": "hypertools.tools.cluster",
        "description": "hypertools.tools.cluster",
        "isExtraImport": true,
        "detail": "hypertools.tools.cluster",
        "documentation": {}
    },
    {
        "label": "plot",
        "importPath": "hypertools.plot.plot",
        "description": "hypertools.plot.plot",
        "isExtraImport": true,
        "detail": "hypertools.plot.plot",
        "documentation": {}
    },
    {
        "label": "plot",
        "importPath": "hypertools.plot.plot",
        "description": "hypertools.plot.plot",
        "isExtraImport": true,
        "detail": "hypertools.plot.plot",
        "documentation": {}
    },
    {
        "label": "plot",
        "importPath": "hypertools.plot.plot",
        "description": "hypertools.plot.plot",
        "isExtraImport": true,
        "detail": "hypertools.plot.plot",
        "documentation": {}
    },
    {
        "label": "plot",
        "importPath": "hypertools.plot.plot",
        "description": "hypertools.plot.plot",
        "isExtraImport": true,
        "detail": "hypertools.plot.plot",
        "documentation": {}
    },
    {
        "label": "plot",
        "importPath": "hypertools.plot.plot",
        "description": "hypertools.plot.plot",
        "isExtraImport": true,
        "detail": "hypertools.plot.plot",
        "documentation": {}
    },
    {
        "label": "plot",
        "importPath": "hypertools.plot.plot",
        "description": "hypertools.plot.plot",
        "isExtraImport": true,
        "detail": "hypertools.plot.plot",
        "documentation": {}
    },
    {
        "label": "describe",
        "importPath": "hypertools.tools.describe",
        "description": "hypertools.tools.describe",
        "isExtraImport": true,
        "detail": "hypertools.tools.describe",
        "documentation": {}
    },
    {
        "label": "format_data",
        "importPath": "hypertools.tools",
        "description": "hypertools.tools",
        "isExtraImport": true,
        "detail": "hypertools.tools",
        "documentation": {}
    },
    {
        "label": "text2mat",
        "importPath": "hypertools.tools",
        "description": "hypertools.tools",
        "isExtraImport": true,
        "detail": "hypertools.tools",
        "documentation": {}
    },
    {
        "label": "DataGeometry",
        "importPath": "hypertools.datageometry",
        "description": "hypertools.datageometry",
        "isExtraImport": true,
        "detail": "hypertools.datageometry",
        "documentation": {}
    },
    {
        "label": "DataGeometry",
        "importPath": "hypertools.datageometry",
        "description": "hypertools.datageometry",
        "isExtraImport": true,
        "detail": "hypertools.datageometry",
        "documentation": {}
    },
    {
        "label": "DataGeometry",
        "importPath": "hypertools.datageometry",
        "description": "hypertools.datageometry",
        "isExtraImport": true,
        "detail": "hypertools.datageometry",
        "documentation": {}
    },
    {
        "label": "hypertools._shared.helpers",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "hypertools._shared.helpers",
        "description": "hypertools._shared.helpers",
        "detail": "hypertools._shared.helpers",
        "documentation": {}
    },
    {
        "label": "normalize",
        "importPath": "hypertools.tools.normalize",
        "description": "hypertools.tools.normalize",
        "isExtraImport": true,
        "detail": "hypertools.tools.normalize",
        "documentation": {}
    },
    {
        "label": "df2mat",
        "importPath": "hypertools.tools.df2mat",
        "description": "hypertools.tools.df2mat",
        "isExtraImport": true,
        "detail": "hypertools.tools.df2mat",
        "documentation": {}
    },
    {
        "label": "plot",
        "importPath": "hypertools.plot",
        "description": "hypertools.plot",
        "isExtraImport": true,
        "detail": "hypertools.plot",
        "documentation": {}
    },
    {
        "label": "reduce",
        "importPath": "hypertools.tools.reduce",
        "description": "hypertools.tools.reduce",
        "isExtraImport": true,
        "detail": "hypertools.tools.reduce",
        "documentation": {}
    },
    {
        "label": "reduce",
        "importPath": "hypertools.tools.reduce",
        "description": "hypertools.tools.reduce",
        "isExtraImport": true,
        "detail": "hypertools.tools.reduce",
        "documentation": {}
    },
    {
        "label": "procrustes",
        "importPath": "hypertools.tools.procrustes",
        "description": "hypertools.tools.procrustes",
        "isExtraImport": true,
        "detail": "hypertools.tools.procrustes",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "find_packages",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "find_packages",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "SentenceTransformer",
        "importPath": "sentence_transformers",
        "description": "sentence_transformers",
        "isExtraImport": true,
        "detail": "sentence_transformers",
        "documentation": {}
    },
    {
        "label": "SentenceTransformer",
        "importPath": "sentence_transformers",
        "description": "sentence_transformers",
        "isExtraImport": true,
        "detail": "sentence_transformers",
        "documentation": {}
    },
    {
        "label": "SentenceTransformer",
        "importPath": "sentence_transformers",
        "description": "sentence_transformers",
        "isExtraImport": true,
        "detail": "sentence_transformers",
        "documentation": {}
    },
    {
        "label": "Poly3DCollection",
        "importPath": "mpl_toolkits.mplot3d.art3d",
        "description": "mpl_toolkits.mplot3d.art3d",
        "isExtraImport": true,
        "detail": "mpl_toolkits.mplot3d.art3d",
        "documentation": {}
    },
    {
        "label": "Mock",
        "importPath": "unittest.mock",
        "description": "unittest.mock",
        "isExtraImport": true,
        "detail": "unittest.mock",
        "documentation": {}
    },
    {
        "label": "MagicMock",
        "importPath": "unittest.mock",
        "description": "unittest.mock",
        "isExtraImport": true,
        "detail": "unittest.mock",
        "documentation": {}
    },
    {
        "label": "Mock",
        "importPath": "unittest.mock",
        "description": "unittest.mock",
        "isExtraImport": true,
        "detail": "unittest.mock",
        "documentation": {}
    },
    {
        "label": "MagicMock",
        "importPath": "unittest.mock",
        "description": "unittest.mock",
        "isExtraImport": true,
        "detail": "unittest.mock",
        "documentation": {}
    },
    {
        "label": "RitualVisualizer",
        "importPath": "word_manifold.visualization.ritual_visualizer",
        "description": "word_manifold.visualization.ritual_visualizer",
        "isExtraImport": true,
        "detail": "word_manifold.visualization.ritual_visualizer",
        "documentation": {}
    },
    {
        "label": "RitualPhase",
        "importPath": "word_manifold.visualization.ritual_visualizer",
        "description": "word_manifold.visualization.ritual_visualizer",
        "isExtraImport": true,
        "detail": "word_manifold.visualization.ritual_visualizer",
        "documentation": {}
    },
    {
        "label": "HermeticPrinciple",
        "importPath": "word_manifold.automata.hermetic_principles",
        "description": "word_manifold.automata.hermetic_principles",
        "isExtraImport": true,
        "detail": "word_manifold.automata.hermetic_principles",
        "documentation": {}
    },
    {
        "label": "Observer",
        "importPath": "watchdog.observers",
        "description": "watchdog.observers",
        "isExtraImport": true,
        "detail": "watchdog.observers",
        "documentation": {}
    },
    {
        "label": "FileSystemEventHandler",
        "importPath": "watchdog.events",
        "description": "watchdog.events",
        "isExtraImport": true,
        "detail": "watchdog.events",
        "documentation": {}
    },
    {
        "label": "create_celestial_rules",
        "kind": 2,
        "importPath": "build.lib.word_manifold.automata.additional_rules",
        "description": "build.lib.word_manifold.automata.additional_rules",
        "peekOfCode": "def create_celestial_rules() -> Dict[str, CellularRule]:\n    \"\"\"\n    Create rules based on celestial bodies and higher spiritual archetypes.\n    These rules complement the base rule set by adding transformations\n    related to cosmic forces and stellar/planetary influences.\n    Returns:\n        Dictionary mapping rule names to CellularRule objects\n    \"\"\"\n    rules = {}",
        "detail": "build.lib.word_manifold.automata.additional_rules",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "build.lib.word_manifold.automata.additional_rules",
        "description": "build.lib.word_manifold.automata.additional_rules",
        "peekOfCode": "logger = logging.getLogger(__name__)\ndef create_celestial_rules() -> Dict[str, CellularRule]:\n    \"\"\"\n    Create rules based on celestial bodies and higher spiritual archetypes.\n    These rules complement the base rule set by adding transformations\n    related to cosmic forces and stellar/planetary influences.\n    Returns:\n        Dictionary mapping rule names to CellularRule objects\n    \"\"\"\n    rules = {}",
        "detail": "build.lib.word_manifold.automata.additional_rules",
        "documentation": {}
    },
    {
        "label": "HermeticPrinciple",
        "kind": 6,
        "importPath": "build.lib.word_manifold.automata.cellular_rules",
        "description": "build.lib.word_manifold.automata.cellular_rules",
        "peekOfCode": "class HermeticPrinciple(Enum):\n    \"\"\"The seven Hermetic principles that govern transformation rules.\"\"\"\n    MENTALISM = auto()         # \"THE ALL is MIND; The Universe is Mental.\"\n    CORRESPONDENCE = auto()    # \"As above, so below; as below, so above.\"\n    VIBRATION = auto()         # \"Nothing rests; everything moves; everything vibrates.\"\n    POLARITY = auto()          # \"Everything is Dual; everything has poles.\"\n    RHYTHM = auto()            # \"Everything flows, out and in; everything has its tides.\"\n    CAUSE_EFFECT = auto()      # \"Every Cause has its Effect; Every Effect has its Cause.\"\n    GENDER = auto()            # \"Gender is in everything; everything has its Masculine and Feminine.\"\nclass ElementalForce(Enum):",
        "detail": "build.lib.word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "ElementalForce",
        "kind": 6,
        "importPath": "build.lib.word_manifold.automata.cellular_rules",
        "description": "build.lib.word_manifold.automata.cellular_rules",
        "peekOfCode": "class ElementalForce(Enum):\n    \"\"\"The four elemental forces that influence transformation.\"\"\"\n    EARTH = auto()  # Stability, materiality, resistance to change\n    AIR = auto()    # Intellect, communication, adaptability\n    FIRE = auto()   # Energy, transformation, creation/destruction\n    WATER = auto()  # Emotion, intuition, connection\nclass VibrationDirection(Enum):\n    \"\"\"Possible directions of vibrational change in the vector space.\"\"\"\n    ASCENDING = auto()  # Moving towards higher vibration (complexity, abstraction)\n    DESCENDING = auto() # Moving towards lower vibration (simplicity, concreteness)",
        "detail": "build.lib.word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "VibrationDirection",
        "kind": 6,
        "importPath": "build.lib.word_manifold.automata.cellular_rules",
        "description": "build.lib.word_manifold.automata.cellular_rules",
        "peekOfCode": "class VibrationDirection(Enum):\n    \"\"\"Possible directions of vibrational change in the vector space.\"\"\"\n    ASCENDING = auto()  # Moving towards higher vibration (complexity, abstraction)\n    DESCENDING = auto() # Moving towards lower vibration (simplicity, concreteness)\n    EXPANDING = auto()  # Increasing in scope or influence\n    CONTRACTING = auto() # Decreasing in scope or influence\n    HARMONIZING = auto() # Moving towards balance with neighbors\n    POLARIZING = auto()  # Moving away from neighbors, increasing distinction\n@dataclass\nclass RuleParameterSet:",
        "detail": "build.lib.word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "RuleParameterSet",
        "kind": 6,
        "importPath": "build.lib.word_manifold.automata.cellular_rules",
        "description": "build.lib.word_manifold.automata.cellular_rules",
        "peekOfCode": "class RuleParameterSet:\n    \"\"\"Parameters that define how a transformation rule behaves.\"\"\"\n    magnitude: float = 1.0                  # Base strength of transformation\n    principle: HermeticPrinciple = HermeticPrinciple.CORRESPONDENCE\n    elemental_influence: Dict[ElementalForce, float] = None  # Influence of each element\n    numerological_weights: Dict[int, float] = None  # Weights by numerological value\n    cell_type_weights: Dict[CellType, float] = None  # Weights by cell type\n    vibration_direction: VibrationDirection = VibrationDirection.HARMONIZING\n    def __init__(self, magnitude=1.0, principle=None, vibration_direction=None,\n                 numerological_weights=None, elemental_influence=None, cell_type_weights=None):",
        "detail": "build.lib.word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "CellularRule",
        "kind": 6,
        "importPath": "build.lib.word_manifold.automata.cellular_rules",
        "description": "build.lib.word_manifold.automata.cellular_rules",
        "peekOfCode": "class CellularRule:\n    \"\"\"\n    A rule that defines how cells transform in the vector space.\n    Each rule embodies one or more hermetic principles and governs \n    the evolution of the cellular automata system.\n    \"\"\"\n    def __init__(\n        self, \n        name: str, \n        description: str,",
        "detail": "build.lib.word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "RuleSequence",
        "kind": 6,
        "importPath": "build.lib.word_manifold.automata.cellular_rules",
        "description": "build.lib.word_manifold.automata.cellular_rules",
        "peekOfCode": "class RuleSequence:\n    \"\"\"\n    A sequence of cellular automata rules to be applied in a specific order.\n    The sequence can be applied in different ways:\n    - Sequentially (default): Rules are applied in order\n    - Conditionally: Rules are applied based on conditions\n    - With branching: Different paths can be taken based on state\n    The sequence also supports:\n    - Dependencies between rules\n    - Conditions for rule application",
        "detail": "build.lib.word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "create_predefined_rules",
        "kind": 2,
        "importPath": "build.lib.word_manifold.automata.cellular_rules",
        "description": "build.lib.word_manifold.automata.cellular_rules",
        "peekOfCode": "def create_predefined_rules() -> Dict[str, CellularRule]:\n    \"\"\"\n    Create a set of predefined cellular automata rules based on\n    hermetic principles and occult correspondences.\n    Returns:\n        Dictionary mapping rule names to CellularRule objects\n    \"\"\"\n    rules = {}\n    # The Great Work Rule - Based on alchemical transformation\n    great_work_params = RuleParameterSet(",
        "detail": "build.lib.word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "create_predefined_sequences",
        "kind": 2,
        "importPath": "build.lib.word_manifold.automata.cellular_rules",
        "description": "build.lib.word_manifold.automata.cellular_rules",
        "peekOfCode": "def create_predefined_sequences() -> Dict[str, RuleSequence]:\n    \"\"\"\n    Create a set of predefined rule sequences based on\n    magical rituals and occult correspondences.\n    Returns:\n        Dictionary mapping sequence names to RuleSequence objects\n    \"\"\"\n    rules = create_predefined_rules()\n    sequences = {}\n    # The Great Work Sequence - Alchemical transformation from base to divine",
        "detail": "build.lib.word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "build.lib.word_manifold.automata.cellular_rules",
        "description": "build.lib.word_manifold.automata.cellular_rules",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass HermeticPrinciple(Enum):\n    \"\"\"The seven Hermetic principles that govern transformation rules.\"\"\"\n    MENTALISM = auto()         # \"THE ALL is MIND; The Universe is Mental.\"\n    CORRESPONDENCE = auto()    # \"As above, so below; as below, so above.\"\n    VIBRATION = auto()         # \"Nothing rests; everything moves; everything vibrates.\"\n    POLARITY = auto()          # \"Everything is Dual; everything has poles.\"\n    RHYTHM = auto()            # \"Everything flows, out and in; everything has its tides.\"\n    CAUSE_EFFECT = auto()      # \"Every Cause has its Effect; Every Effect has its Cause.\"\n    GENDER = auto()            # \"Gender is in everything; everything has its Masculine and Feminine.\"",
        "detail": "build.lib.word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "EvolutionPattern",
        "kind": 6,
        "importPath": "build.lib.word_manifold.automata.system",
        "description": "build.lib.word_manifold.automata.system",
        "peekOfCode": "class EvolutionPattern(Enum):\n    \"\"\"Patterns of evolution that the automata system can follow.\"\"\"\n    LINEAR = auto()      # Sequential application of rules\n    CYCLIC = auto()      # Repeated application of rules in a cycle\n    SPIRAL = auto()      # Cyclic with increasing intensity\n    CHAOTIC = auto()     # Random selection of rules\n    THELEMIC = auto()    # Rules selected based on True Will principle\n    KABBALISTIC = auto() # Rules follow Tree of Life pattern\n@dataclass\nclass SystemState:",
        "detail": "build.lib.word_manifold.automata.system",
        "documentation": {}
    },
    {
        "label": "SystemState",
        "kind": 6,
        "importPath": "build.lib.word_manifold.automata.system",
        "description": "build.lib.word_manifold.automata.system",
        "peekOfCode": "class SystemState:\n    \"\"\"State of the automata system at a point in time.\"\"\"\n    generation: int                # Current generation number\n    active_rules: List[str]        # Names of rules currently active\n    manifold_state: Dict[str, Any] # State snapshot of the manifold\n    timestamp: float               # Unix timestamp when state was captured\n    metrics: Dict[str, float]      # Metrics about the system's state\nclass AutomataSystem:\n    \"\"\"\n    A system that orchestrates the application of cellular automata rules",
        "detail": "build.lib.word_manifold.automata.system",
        "documentation": {}
    },
    {
        "label": "AutomataSystem",
        "kind": 6,
        "importPath": "build.lib.word_manifold.automata.system",
        "description": "build.lib.word_manifold.automata.system",
        "peekOfCode": "class AutomataSystem:\n    \"\"\"\n    A system that orchestrates the application of cellular automata rules\n    to a word vector manifold according to hermetic principles.\n    This class manages the evolution of the manifold through generations,\n    applying rules according to specified patterns and tracking the system's\n    state over time.\n    \"\"\"\n    def __init__(\n        self,",
        "detail": "build.lib.word_manifold.automata.system",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "build.lib.word_manifold.automata.system",
        "description": "build.lib.word_manifold.automata.system",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass EvolutionPattern(Enum):\n    \"\"\"Patterns of evolution that the automata system can follow.\"\"\"\n    LINEAR = auto()      # Sequential application of rules\n    CYCLIC = auto()      # Repeated application of rules in a cycle\n    SPIRAL = auto()      # Cyclic with increasing intensity\n    CHAOTIC = auto()     # Random selection of rules\n    THELEMIC = auto()    # Rules selected based on True Will principle\n    KABBALISTIC = auto() # Rules follow Tree of Life pattern\n@dataclass",
        "detail": "build.lib.word_manifold.automata.system",
        "documentation": {}
    },
    {
        "label": "PhraseEmbedding",
        "kind": 6,
        "importPath": "build.lib.word_manifold.embeddings.phrase_embeddings",
        "description": "build.lib.word_manifold.embeddings.phrase_embeddings",
        "peekOfCode": "class PhraseEmbedding:\n    \"\"\"\n    A class representing the embedding of a phrase or sentence,\n    including both its semantic content and structural shape.\n    \"\"\"\n    def __init__(self, text: str, embedding: np.ndarray, shape_params: Dict):\n        self.text = text\n        self.embedding = embedding\n        self.shape_params = shape_params\nclass PhraseEmbedder:",
        "detail": "build.lib.word_manifold.embeddings.phrase_embeddings",
        "documentation": {}
    },
    {
        "label": "PhraseEmbedder",
        "kind": 6,
        "importPath": "build.lib.word_manifold.embeddings.phrase_embeddings",
        "description": "build.lib.word_manifold.embeddings.phrase_embeddings",
        "peekOfCode": "class PhraseEmbedder:\n    \"\"\"\n    A class for embedding phrases and sentences into a semantic manifold,\n    extracting both meaning and structural patterns.\n    \"\"\"\n    def __init__(\n        self,\n        model_name: str = \"Snowflake/snowflake-arctic-embed-l\",  # Updated to use Arctic-embed\n        use_gpu: bool = True\n    ):",
        "detail": "build.lib.word_manifold.embeddings.phrase_embeddings",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "build.lib.word_manifold.embeddings.phrase_embeddings",
        "description": "build.lib.word_manifold.embeddings.phrase_embeddings",
        "peekOfCode": "logger = logging.getLogger(__name__)\nlogger.setLevel(logging.DEBUG)\n# Create formatters and handlers if they don't exist\nif not logger.handlers:\n    # Create console handler with formatting\n    console_handler = logging.StreamHandler()\n    console_handler.setLevel(logging.INFO)\n    console_formatter = logging.Formatter(\n        '%(asctime)s - %(name)s - [%(levelname)s] - %(message)s'\n    )",
        "detail": "build.lib.word_manifold.embeddings.phrase_embeddings",
        "documentation": {}
    },
    {
        "label": "EMOTION_ANCHORS",
        "kind": 5,
        "importPath": "build.lib.word_manifold.embeddings.phrase_embeddings",
        "description": "build.lib.word_manifold.embeddings.phrase_embeddings",
        "peekOfCode": "EMOTION_ANCHORS = {\n    'joy': nlp(' '.join(['happy', 'joyful', 'delighted', 'elated'])).vector.mean(axis=0),\n    'sadness': nlp(' '.join(['sad', 'depressed', 'gloomy', 'melancholy'])).vector.mean(axis=0),\n    'anger': nlp(' '.join(['angry', 'furious', 'enraged', 'hostile'])).vector.mean(axis=0),\n    'fear': nlp(' '.join(['afraid', 'scared', 'terrified', 'anxious'])).vector.mean(axis=0),\n    'surprise': nlp(' '.join(['surprised', 'amazed', 'astonished', 'shocked'])).vector.mean(axis=0),\n    'disgust': nlp(' '.join(['disgusted', 'repulsed', 'revolted', 'appalled'])).vector.mean(axis=0),\n    'trust': nlp(' '.join(['trusting', 'confident', 'secure', 'reliable'])).vector.mean(axis=0),\n    'anticipation': nlp(' '.join(['expectant', 'eager', 'excited', 'hopeful'])).vector.mean(axis=0)\n}",
        "detail": "build.lib.word_manifold.embeddings.phrase_embeddings",
        "documentation": {}
    },
    {
        "label": "EMOTION_ANCHORS",
        "kind": 5,
        "importPath": "build.lib.word_manifold.embeddings.phrase_embeddings",
        "description": "build.lib.word_manifold.embeddings.phrase_embeddings",
        "peekOfCode": "EMOTION_ANCHORS = {\n    emotion: vector / np.linalg.norm(vector)\n    for emotion, vector in EMOTION_ANCHORS.items()\n}\nclass PhraseEmbedding:\n    \"\"\"\n    A class representing the embedding of a phrase or sentence,\n    including both its semantic content and structural shape.\n    \"\"\"\n    def __init__(self, text: str, embedding: np.ndarray, shape_params: Dict):",
        "detail": "build.lib.word_manifold.embeddings.phrase_embeddings",
        "documentation": {}
    },
    {
        "label": "WordEmbeddings",
        "kind": 6,
        "importPath": "build.lib.word_manifold.embeddings.word_embeddings",
        "description": "build.lib.word_manifold.embeddings.word_embeddings",
        "peekOfCode": "class WordEmbeddings:\n    \"\"\"\n    A class to manage word embeddings from various sources.\n    Supports:\n    - spaCy models (e.g., 'en_core_web_sm', 'en_core_web_md', 'en_core_web_lg')\n    - HuggingFace models (e.g., 'bert-base-uncased', 'gpt2', etc.)\n    - Custom embedding spaces\n    \"\"\"\n    def __init__(\n        self,",
        "detail": "build.lib.word_manifold.embeddings.word_embeddings",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "build.lib.word_manifold.embeddings.word_embeddings",
        "description": "build.lib.word_manifold.embeddings.word_embeddings",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass WordEmbeddings:\n    \"\"\"\n    A class to manage word embeddings from various sources.\n    Supports:\n    - spaCy models (e.g., 'en_core_web_sm', 'en_core_web_md', 'en_core_web_lg')\n    - HuggingFace models (e.g., 'bert-base-uncased', 'gpt2', etc.)\n    - Custom embedding spaces\n    \"\"\"\n    def __init__(",
        "detail": "build.lib.word_manifold.embeddings.word_embeddings",
        "documentation": {}
    },
    {
        "label": "ForceFieldDemo",
        "kind": 6,
        "importPath": "build.lib.word_manifold.examples.force_field_demo",
        "description": "build.lib.word_manifold.examples.force_field_demo",
        "peekOfCode": "class ForceFieldDemo:\n    def __init__(self, n_dimensions=3):\n        \"\"\"Initialize the force field demonstration.\n        Args:\n            n_dimensions (int): Number of dimensions for the semantic space\n        \"\"\"\n        self.n_dimensions = n_dimensions\n        self.embeddings = None\n        self.manifold = None\n        self.visualizer = None",
        "detail": "build.lib.word_manifold.examples.force_field_demo",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "build.lib.word_manifold.examples.force_field_demo",
        "description": "build.lib.word_manifold.examples.force_field_demo",
        "peekOfCode": "def main():\n    \"\"\"Run the force field visualization demo.\"\"\"\n    # Create and run simulation\n    demo = ForceFieldDemo(n_dimensions=3)\n    demo.prepare_components()\n    viz_path = demo.simulate_force_field()\n    logger.info(f\"\"\"\n    Force field visualization complete!\n    This demonstration shows how concepts move through a semantic force field:\n    - Red points are attractors (positive concepts)",
        "detail": "build.lib.word_manifold.examples.force_field_demo",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "build.lib.word_manifold.examples.force_field_demo",
        "description": "build.lib.word_manifold.examples.force_field_demo",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass ForceFieldDemo:\n    def __init__(self, n_dimensions=3):\n        \"\"\"Initialize the force field demonstration.\n        Args:\n            n_dimensions (int): Number of dimensions for the semantic space\n        \"\"\"\n        self.n_dimensions = n_dimensions\n        self.embeddings = None\n        self.manifold = None",
        "detail": "build.lib.word_manifold.examples.force_field_demo",
        "documentation": {}
    },
    {
        "label": "HyperdimensionalRitual",
        "kind": 6,
        "importPath": "build.lib.word_manifold.examples.hyperdimensional_ritual",
        "description": "build.lib.word_manifold.examples.hyperdimensional_ritual",
        "peekOfCode": "class HyperdimensionalRitual:\n    \"\"\"\n    A class demonstrating hyperdimensional visualization of Thelemic rituals.\n    \"\"\"\n    def __init__(\n        self,\n        n_dimensions: int = 5,  # We'll use 5D for richer semantic representation\n        output_dir: str = \"visualizations/hyperdimensional\"\n    ):\n        self.n_dimensions = n_dimensions",
        "detail": "build.lib.word_manifold.examples.hyperdimensional_ritual",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "build.lib.word_manifold.examples.hyperdimensional_ritual",
        "description": "build.lib.word_manifold.examples.hyperdimensional_ritual",
        "peekOfCode": "def main():\n    \"\"\"Run the hyperdimensional ritual visualization example.\"\"\"\n    # Create and prepare the ritual\n    ritual = HyperdimensionalRitual(n_dimensions=5)\n    ritual.prepare_components()\n    # Create visualization\n    viz_path = ritual.visualize_ritual_transformation()\n    logger.info(f\"\"\"\n    Hyperdimensional ritual visualization complete!\n    The visualization shows the evolution of Thelemic concepts through a 5-dimensional",
        "detail": "build.lib.word_manifold.examples.hyperdimensional_ritual",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "build.lib.word_manifold.examples.hyperdimensional_ritual",
        "description": "build.lib.word_manifold.examples.hyperdimensional_ritual",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass HyperdimensionalRitual:\n    \"\"\"\n    A class demonstrating hyperdimensional visualization of Thelemic rituals.\n    \"\"\"\n    def __init__(\n        self,\n        n_dimensions: int = 5,  # We'll use 5D for richer semantic representation\n        output_dir: str = \"visualizations/hyperdimensional\"\n    ):",
        "detail": "build.lib.word_manifold.examples.hyperdimensional_ritual",
        "documentation": {}
    },
    {
        "label": "RitualWorking",
        "kind": 6,
        "importPath": "build.lib.word_manifold.examples.ritual_evolution",
        "description": "build.lib.word_manifold.examples.ritual_evolution",
        "peekOfCode": "class RitualWorking:\n    \"\"\"\n    A class that implements a complete magical working in word vector space.\n    \"\"\"\n    def _create_evolution_animation(self, key_terms):\n        \"\"\"\n        Create an animation of the evolution of machinic desires using fluid visual transformations and emergent patterns.\n        Args:\n            key_terms: List of key terms to highlight in the animation description\n        Returns:",
        "detail": "build.lib.word_manifold.examples.ritual_evolution",
        "documentation": {}
    },
    {
        "label": "memoize",
        "kind": 2,
        "importPath": "build.lib.word_manifold.examples.ritual_evolution",
        "description": "build.lib.word_manifold.examples.ritual_evolution",
        "peekOfCode": "def memoize(func):\n    \"\"\"\n    Decorator for memoizing function results.\n    Results are cached in memory and on disk for persistence between runs.\n    \"\"\"\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        # Create a unique key based on function name and arguments\n        key_parts = [func.__name__]\n        # Add class name if it's a method",
        "detail": "build.lib.word_manifold.examples.ritual_evolution",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "build.lib.word_manifold.examples.ritual_evolution",
        "description": "build.lib.word_manifold.examples.ritual_evolution",
        "peekOfCode": "def main():\n    \"\"\" Demonstrate the ritual evolution process. \"\"\"\n    ritual = RitualWorking(\n        ritual_name=\"True Will Discovery\",\n        ritual_intent=\"To discover and align with one's True Will through semantic transformation\"\n    )\n    # Prepare components\n    ritual.prepare_components()\n    # Perform the ritual\n    ritual.perform_ritual()",
        "detail": "build.lib.word_manifold.examples.ritual_evolution",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "build.lib.word_manifold.examples.ritual_evolution",
        "description": "build.lib.word_manifold.examples.ritual_evolution",
        "peekOfCode": "logger = logging.getLogger(\"ritual_evolution\")\n# Directory for saving outputs\nOUTPUT_DIR = Path(\"ritual_outputs\")\nCACHE_DIR = Path(\".ritual_cache\")\n# Create cache directory if it doesn't exist\nCACHE_DIR.mkdir(exist_ok=True)\n# Function cache decorator with key based on function arguments\ndef memoize(func):\n    \"\"\"\n    Decorator for memoizing function results.",
        "detail": "build.lib.word_manifold.examples.ritual_evolution",
        "documentation": {}
    },
    {
        "label": "OUTPUT_DIR",
        "kind": 5,
        "importPath": "build.lib.word_manifold.examples.ritual_evolution",
        "description": "build.lib.word_manifold.examples.ritual_evolution",
        "peekOfCode": "OUTPUT_DIR = Path(\"ritual_outputs\")\nCACHE_DIR = Path(\".ritual_cache\")\n# Create cache directory if it doesn't exist\nCACHE_DIR.mkdir(exist_ok=True)\n# Function cache decorator with key based on function arguments\ndef memoize(func):\n    \"\"\"\n    Decorator for memoizing function results.\n    Results are cached in memory and on disk for persistence between runs.\n    \"\"\"",
        "detail": "build.lib.word_manifold.examples.ritual_evolution",
        "documentation": {}
    },
    {
        "label": "CACHE_DIR",
        "kind": 5,
        "importPath": "build.lib.word_manifold.examples.ritual_evolution",
        "description": "build.lib.word_manifold.examples.ritual_evolution",
        "peekOfCode": "CACHE_DIR = Path(\".ritual_cache\")\n# Create cache directory if it doesn't exist\nCACHE_DIR.mkdir(exist_ok=True)\n# Function cache decorator with key based on function arguments\ndef memoize(func):\n    \"\"\"\n    Decorator for memoizing function results.\n    Results are cached in memory and on disk for persistence between runs.\n    \"\"\"\n    @functools.wraps(func)",
        "detail": "build.lib.word_manifold.examples.ritual_evolution",
        "documentation": {}
    },
    {
        "label": "ReadingStep",
        "kind": 6,
        "importPath": "build.lib.word_manifold.examples.semantic_crystallization",
        "description": "build.lib.word_manifold.examples.semantic_crystallization",
        "peekOfCode": "class ReadingStep:\n    \"\"\"Represents a single step in the reading sequence.\"\"\"\n    card: str  # The card or concept being integrated\n    keywords: List[str]  # Associated keywords/meanings\n    position: str  # Position or aspect in the reading (e.g., \"past\", \"present\", \"future\")\n    influence: float = 1.0  # Relative influence of this step (0-1)\nterms=[\n                # Major Arcana\n                \"fool\", \"magician\", \"priestess\", \"empress\", \"emperor\",\n                \"hierophant\", \"lovers\", \"chariot\", \"strength\", \"hermit\",",
        "detail": "build.lib.word_manifold.examples.semantic_crystallization",
        "documentation": {}
    },
    {
        "label": "SemanticCrystallization",
        "kind": 6,
        "importPath": "build.lib.word_manifold.examples.semantic_crystallization",
        "description": "build.lib.word_manifold.examples.semantic_crystallization",
        "peekOfCode": "class SemanticCrystallization:\n    \"\"\"\n    Visualizes the crystallization of meaning during a reading sequence.\n    This class tracks how semantic space transforms as each new card or concept\n    is integrated, showing the accumulation and crystallization of meaning over time.\n    \"\"\"\n    def __init__(\n        self,\n        n_dimensions: int = 5,\n        output_dir: str = \"visualizations/crystallization\",",
        "detail": "build.lib.word_manifold.examples.semantic_crystallization",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "build.lib.word_manifold.examples.semantic_crystallization",
        "description": "build.lib.word_manifold.examples.semantic_crystallization",
        "peekOfCode": "def main():\n    \"\"\"Run the semantic crystallization example.\"\"\"\n    # Create and prepare crystallization viewer\n    crystal = SemanticCrystallization(n_dimensions=5)\n    crystal.prepare_components()\n    # Example Celtic Cross reading sequence\n    reading_sequence = [\n        # Central cross\n        (\"present\", \"tower\", [\"disruption\", \"awakening\", \"revelation\"]),\n        (\"challenge\", \"death\", [\"transformation\", \"ending\", \"rebirth\"]),",
        "detail": "build.lib.word_manifold.examples.semantic_crystallization",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "build.lib.word_manifold.examples.semantic_crystallization",
        "description": "build.lib.word_manifold.examples.semantic_crystallization",
        "peekOfCode": "logger = logging.getLogger(__name__)\n@dataclass\nclass ReadingStep:\n    \"\"\"Represents a single step in the reading sequence.\"\"\"\n    card: str  # The card or concept being integrated\n    keywords: List[str]  # Associated keywords/meanings\n    position: str  # Position or aspect in the reading (e.g., \"past\", \"present\", \"future\")\n    influence: float = 1.0  # Relative influence of this step (0-1)\nterms=[\n                # Major Arcana",
        "detail": "build.lib.word_manifold.examples.semantic_crystallization",
        "documentation": {}
    },
    {
        "label": "ThelemaMetrics",
        "kind": 6,
        "importPath": "build.lib.word_manifold.examples.thelemic_evolution",
        "description": "build.lib.word_manifold.examples.thelemic_evolution",
        "peekOfCode": "class ThelemaMetrics:\n    \"\"\"\n    A class to calculate and track metrics for the Thelemic evolution of a word manifold.\n    Metrics include:\n    - Semantic entropy: Measure of semantic diversity\n    - Numerological alignment: Correspondence between numerological values\n    - Will manifestation: How closely the system follows its \"True Will\"\n    - Transmutation index: Degree of alchemical transformation\n    \"\"\"\n    def __init__(self):",
        "detail": "build.lib.word_manifold.examples.thelemic_evolution",
        "documentation": {}
    },
    {
        "label": "BasicVisualizer",
        "kind": 6,
        "importPath": "build.lib.word_manifold.examples.thelemic_evolution",
        "description": "build.lib.word_manifold.examples.thelemic_evolution",
        "peekOfCode": "class BasicVisualizer:\n    \"\"\"\n    A basic visualization class for when the full visualizer is not available.\n    This creates simple 2D plots of the manifold's reduced representation.\n    \"\"\"\n    def __init__(self, manifold: VectorManifold, save_path: str):\n        \"\"\"\n        Initialize the basic visualizer.\n        Args:\n            manifold: The vector manifold to visualize",
        "detail": "build.lib.word_manifold.examples.thelemic_evolution",
        "documentation": {}
    },
    {
        "label": "run_thelemic_evolution",
        "kind": 2,
        "importPath": "build.lib.word_manifold.examples.thelemic_evolution",
        "description": "build.lib.word_manifold.examples.thelemic_evolution",
        "peekOfCode": "def run_thelemic_evolution(\n    generations: int = 22,  # One for each Major Arcana\n    save_path: str = None,\n    model_name: str = \"bert-base-uncased\",\n    n_cells: int = 22,\n    random_state: int = 93  # Significant in Thelema/Crowley's work\n):\n    \"\"\"\n    Run the Thelemic evolution of the word manifold.\n    Args:",
        "detail": "build.lib.word_manifold.examples.thelemic_evolution",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "build.lib.word_manifold.examples.thelemic_evolution",
        "description": "build.lib.word_manifold.examples.thelemic_evolution",
        "peekOfCode": "logger = logging.getLogger(__name__)\n# Add the project root to the Python path if running as a script\nif __name__ == \"__main__\":\n    project_root = str(Path(__file__).resolve().parents[3])\n    sys.path.insert(0, project_root)\n# Import Word Manifold components\nfrom word_manifold.embeddings.word_embeddings import WordEmbeddings\nfrom word_manifold.manifold.vector_manifold import VectorManifold, CellType\nfrom word_manifold.automata.cellular_rules import create_predefined_rules\nfrom word_manifold.automata.system import AutomataSystem, EvolutionPattern, SystemState",
        "detail": "build.lib.word_manifold.examples.thelemic_evolution",
        "documentation": {}
    },
    {
        "label": "ShapePoint",
        "kind": 6,
        "importPath": "build.lib.word_manifold.manifold.semantic_shape",
        "description": "build.lib.word_manifold.manifold.semantic_shape",
        "peekOfCode": "class ShapePoint:\n    \"\"\"A point in the semantic shape with its associated properties.\"\"\"\n    position: np.ndarray\n    intensity: float  # Emotional/semantic intensity\n    direction: np.ndarray  # Flow direction\n    properties: Dict  # Additional shape properties\nclass SemanticShape:\n    \"\"\"\n    A class representing the shape of meaning in semantic space.\n    This captures both the geometric form and the dynamic properties",
        "detail": "build.lib.word_manifold.manifold.semantic_shape",
        "documentation": {}
    },
    {
        "label": "SemanticShape",
        "kind": 6,
        "importPath": "build.lib.word_manifold.manifold.semantic_shape",
        "description": "build.lib.word_manifold.manifold.semantic_shape",
        "peekOfCode": "class SemanticShape:\n    \"\"\"\n    A class representing the shape of meaning in semantic space.\n    This captures both the geometric form and the dynamic properties\n    of a semantic expression (phrase, sentence, or text chunk).\n    \"\"\"\n    def __init__(\n        self,\n        phrase_embedding: PhraseEmbedding,\n        n_control_points: int = 10",
        "detail": "build.lib.word_manifold.manifold.semantic_shape",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "build.lib.word_manifold.manifold.semantic_shape",
        "description": "build.lib.word_manifold.manifold.semantic_shape",
        "peekOfCode": "logger = logging.getLogger(__name__)\n@dataclass\nclass ShapePoint:\n    \"\"\"A point in the semantic shape with its associated properties.\"\"\"\n    position: np.ndarray\n    intensity: float  # Emotional/semantic intensity\n    direction: np.ndarray  # Flow direction\n    properties: Dict  # Additional shape properties\nclass SemanticShape:\n    \"\"\"",
        "detail": "build.lib.word_manifold.manifold.semantic_shape",
        "documentation": {}
    },
    {
        "label": "Cell",
        "kind": 6,
        "importPath": "build.lib.word_manifold.manifold.vector_manifold",
        "description": "build.lib.word_manifold.manifold.vector_manifold",
        "peekOfCode": "class Cell:\n    \"\"\"\n    A cell in the manifold representing a region in the vector space.\n    \"\"\"\n    id: int\n    terms: List[str]  # Words that belong to this cell\n    centroid: np.ndarray  # Center point of the cell in embedding space\n    type: CellType  # Type of cell with occult significance\n    numerological_value: int  # Numerological value of the cell\n    boundary_points: Optional[np.ndarray] = None  # Points defining the boundary (if available)",
        "detail": "build.lib.word_manifold.manifold.vector_manifold",
        "documentation": {}
    },
    {
        "label": "ManifoldReducedState",
        "kind": 6,
        "importPath": "build.lib.word_manifold.manifold.vector_manifold",
        "description": "build.lib.word_manifold.manifold.vector_manifold",
        "peekOfCode": "class ManifoldReducedState(NamedTuple):\n    \"\"\"State of the reduced manifold for visualization and cellular operations.\"\"\"\n    points: np.ndarray         # 2D or 3D points\n    labels: List[int]          # Cell labels for each point\n    cell_centroids: np.ndarray # Reduced centroids\n    boundaries: Any            # Boundary representations (e.g., Voronoi)\nclass VectorManifold:\n    \"\"\"\n    A class representing a manifold in vector space for word embeddings.\n    This class handles the geometric relationships between word embeddings,",
        "detail": "build.lib.word_manifold.manifold.vector_manifold",
        "documentation": {}
    },
    {
        "label": "VectorManifold",
        "kind": 6,
        "importPath": "build.lib.word_manifold.manifold.vector_manifold",
        "description": "build.lib.word_manifold.manifold.vector_manifold",
        "peekOfCode": "class VectorManifold:\n    \"\"\"\n    A class representing a manifold in vector space for word embeddings.\n    This class handles the geometric relationships between word embeddings,\n    including Voronoi tessellation and neighborhood calculations.\n    \"\"\"\n    def __init__(\n        self,\n        word_embeddings: WordEmbeddings,\n        n_cells: int = 22,  # Default to 22 cells (major arcana)",
        "detail": "build.lib.word_manifold.manifold.vector_manifold",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "build.lib.word_manifold.manifold.vector_manifold",
        "description": "build.lib.word_manifold.manifold.vector_manifold",
        "peekOfCode": "logger = logging.getLogger(__name__)\n@dataclass\nclass Cell:\n    \"\"\"\n    A cell in the manifold representing a region in the vector space.\n    \"\"\"\n    id: int\n    terms: List[str]  # Words that belong to this cell\n    centroid: np.ndarray  # Center point of the cell in embedding space\n    type: CellType  # Type of cell with occult significance",
        "detail": "build.lib.word_manifold.manifold.vector_manifold",
        "documentation": {}
    },
    {
        "label": "AudioFeatures",
        "kind": 6,
        "importPath": "build.lib.word_manifold.visualization.audio_visualizer",
        "description": "build.lib.word_manifold.visualization.audio_visualizer",
        "peekOfCode": "class AudioFeatures:\n    \"\"\"Container for extracted audio features.\"\"\"\n    mfcc: np.ndarray\n    chroma: np.ndarray\n    spectral_contrast: np.ndarray\n    tonnetz: np.ndarray\n    onset_strength: np.ndarray\n    tempogram: np.ndarray\nclass AudioEncoder(nn.Module):\n    \"\"\"Neural network for encoding audio features into semantic space.\"\"\"",
        "detail": "build.lib.word_manifold.visualization.audio_visualizer",
        "documentation": {}
    },
    {
        "label": "AudioEncoder",
        "kind": 6,
        "importPath": "build.lib.word_manifold.visualization.audio_visualizer",
        "description": "build.lib.word_manifold.visualization.audio_visualizer",
        "peekOfCode": "class AudioEncoder(nn.Module):\n    \"\"\"Neural network for encoding audio features into semantic space.\"\"\"\n    def __init__(\n        self,\n        input_dim: int,\n        embedding_dim: int,\n        hidden_dim: int = 256,\n        n_layers: int = 3\n    ):\n        \"\"\"",
        "detail": "build.lib.word_manifold.visualization.audio_visualizer",
        "documentation": {}
    },
    {
        "label": "AudioVisualizer",
        "kind": 6,
        "importPath": "build.lib.word_manifold.visualization.audio_visualizer",
        "description": "build.lib.word_manifold.visualization.audio_visualizer",
        "peekOfCode": "class AudioVisualizer:\n    \"\"\"Main class for audio visualization in semantic space.\"\"\"\n    def __init__(\n        self,\n        embedding_dim: int,\n        sample_rate: int = 22050,\n        hop_length: int = 512,\n        device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    ):\n        \"\"\"",
        "detail": "build.lib.word_manifold.visualization.audio_visualizer",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "build.lib.word_manifold.visualization.audio_visualizer",
        "description": "build.lib.word_manifold.visualization.audio_visualizer",
        "peekOfCode": "logger = logging.getLogger(__name__)\n@dataclass\nclass AudioFeatures:\n    \"\"\"Container for extracted audio features.\"\"\"\n    mfcc: np.ndarray\n    chroma: np.ndarray\n    spectral_contrast: np.ndarray\n    tonnetz: np.ndarray\n    onset_strength: np.ndarray\n    tempogram: np.ndarray",
        "detail": "build.lib.word_manifold.visualization.audio_visualizer",
        "documentation": {}
    },
    {
        "label": "cli",
        "kind": 2,
        "importPath": "build.lib.word_manifold.visualization.cli",
        "description": "build.lib.word_manifold.visualization.cli",
        "peekOfCode": "def cli():\n    \"\"\"Word Manifold Visualization Tools\"\"\"\n    pass\n@cli.command()\n@click.option('--model', default='en_core_web_sm', help='Spacy model to use')\n@click.option('--terms', '-t', multiple=True, help='Terms to visualize')\n@click.option('--terms-file', type=click.Path(exists=True), help='File containing terms (one per line)')\n@click.option('--output-dir', default='visualizations', help='Output directory for visualizations')\n@click.option('--dimensions', default=4, help='Number of dimensions for visualization')\n@click.option('--interactive/--no-interactive', default=True, help='Enable/disable interactive mode')",
        "detail": "build.lib.word_manifold.visualization.cli",
        "documentation": {}
    },
    {
        "label": "visualize",
        "kind": 2,
        "importPath": "build.lib.word_manifold.visualization.cli",
        "description": "build.lib.word_manifold.visualization.cli",
        "peekOfCode": "def visualize(model: str, terms: List[str], terms_file: Optional[str], output_dir: str,\n             dimensions: int, interactive: bool, auto_rotate: bool, show_trails: bool,\n             show_force_field: bool, color_palette: str, save_format: str):\n    \"\"\"Create an interactive visualization of word vectors.\"\"\"\n    # Load terms from file if provided\n    if terms_file:\n        with open(terms_file) as f:\n            file_terms = [line.strip() for line in f if line.strip()]\n        terms = list(terms) + file_terms\n    if not terms:",
        "detail": "build.lib.word_manifold.visualization.cli",
        "documentation": {}
    },
    {
        "label": "animate_ritual",
        "kind": 2,
        "importPath": "build.lib.word_manifold.visualization.cli",
        "description": "build.lib.word_manifold.visualization.cli",
        "peekOfCode": "def animate_ritual(model: str, ritual_file: str, output_dir: str,\n                  duration: float, fps: int, add_trails: bool):\n    \"\"\"Create an animated visualization of a ritual sequence.\"\"\"\n    import json\n    # Load ritual sequence\n    with open(ritual_file) as f:\n        ritual_data = json.load(f)\n    # Initialize embeddings and manifold\n    embeddings = WordEmbeddings(model)\n    terms = set()",
        "detail": "build.lib.word_manifold.visualization.cli",
        "documentation": {}
    },
    {
        "label": "serve",
        "kind": 2,
        "importPath": "build.lib.word_manifold.visualization.cli",
        "description": "build.lib.word_manifold.visualization.cli",
        "peekOfCode": "def serve(host: str, port: int, debug: bool):\n    \"\"\"Start the visualization server.\"\"\"\n    from .server import VisualizationServer\n    server = VisualizationServer()\n    server.run(host=host, port=port, debug=debug)\nif __name__ == '__main__':\n    cli()",
        "detail": "build.lib.word_manifold.visualization.cli",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "build.lib.word_manifold.visualization.cli",
        "description": "build.lib.word_manifold.visualization.cli",
        "peekOfCode": "logger = logging.getLogger(__name__)\n@click.group()\ndef cli():\n    \"\"\"Word Manifold Visualization Tools\"\"\"\n    pass\n@cli.command()\n@click.option('--model', default='en_core_web_sm', help='Spacy model to use')\n@click.option('--terms', '-t', multiple=True, help='Terms to visualize')\n@click.option('--terms-file', type=click.Path(exists=True), help='File containing terms (one per line)')\n@click.option('--output-dir', default='visualizations', help='Output directory for visualizations')",
        "detail": "build.lib.word_manifold.visualization.cli",
        "documentation": {}
    },
    {
        "label": "HyperToolsVisualizer",
        "kind": 6,
        "importPath": "build.lib.word_manifold.visualization.hypertools_visualizer",
        "description": "build.lib.word_manifold.visualization.hypertools_visualizer",
        "peekOfCode": "class HyperToolsVisualizer:\n    \"\"\"\n    Advanced high-dimensional visualization class using HyperTools.\n    This visualizer provides fluid, interactive visualizations of semantic\n    transformations in high-dimensional spaces, with advanced animation\n    capabilities for ritual evolution processes and 4D+ rotations.\n    \"\"\"\n    def __init__(\n        self,\n        output_dir: str = \"visualizations/hypertools\",",
        "detail": "build.lib.word_manifold.visualization.hypertools_visualizer",
        "documentation": {}
    },
    {
        "label": "is_string_like",
        "kind": 2,
        "importPath": "build.lib.word_manifold.visualization.hypertools_visualizer",
        "description": "build.lib.word_manifold.visualization.hypertools_visualizer",
        "peekOfCode": "def is_string_like(obj):\n    \"\"\"Check if the object is a string-like object (str or bytes)\"\"\"\n    return isinstance(obj, (str, bytes))\n# Apply the patch to hypertools\ntry:\n    # Get the reduce function from hypertools.tools\n    if hasattr(hyp.tools, 'reduce'):\n        original_reduce = hyp.tools.reduce\n    else:\n        # If reduce isn't directly accessible, try to get it from the module",
        "detail": "build.lib.word_manifold.visualization.hypertools_visualizer",
        "documentation": {}
    },
    {
        "label": "hypertools_path",
        "kind": 5,
        "importPath": "build.lib.word_manifold.visualization.hypertools_visualizer",
        "description": "build.lib.word_manifold.visualization.hypertools_visualizer",
        "peekOfCode": "hypertools_path = Path(__file__).parent.parent.parent.parent / 'hypertools'\nsys.path.insert(0, str(hypertools_path))\nimport hypertools as hyp\nimport warnings\nimport datetime\nfrom typing import List, Dict, Optional, Tuple, Union, Any\nimport logging\nfrom matplotlib.animation import FuncAnimation\nimport matplotlib.colors as mcolors\nfrom mpl_toolkits.mplot3d import Axes3D",
        "detail": "build.lib.word_manifold.visualization.hypertools_visualizer",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "build.lib.word_manifold.visualization.hypertools_visualizer",
        "description": "build.lib.word_manifold.visualization.hypertools_visualizer",
        "peekOfCode": "logger = logging.getLogger(__name__)\n# Monkey patch for NumPy 2.0 compatibility\ndef is_string_like(obj):\n    \"\"\"Check if the object is a string-like object (str or bytes)\"\"\"\n    return isinstance(obj, (str, bytes))\n# Apply the patch to hypertools\ntry:\n    # Get the reduce function from hypertools.tools\n    if hasattr(hyp.tools, 'reduce'):\n        original_reduce = hyp.tools.reduce",
        "detail": "build.lib.word_manifold.visualization.hypertools_visualizer",
        "documentation": {}
    },
    {
        "label": "InteractiveVisualizer",
        "kind": 6,
        "importPath": "build.lib.word_manifold.visualization.interactive_visualizer",
        "description": "build.lib.word_manifold.visualization.interactive_visualizer",
        "peekOfCode": "class InteractiveVisualizer:\n    \"\"\"\n    Interactive visualization class for exploring semantic spaces.\n    This class provides real-time visualization of word embeddings and\n    semantic transformations, with support for:\n    - Dynamic embedding projection\n    - Interactive exploration of semantic neighborhoods\n    - Real-time visualization of transformations\n    - Multiple visualization modes (2D/3D)\n    \"\"\"",
        "detail": "build.lib.word_manifold.visualization.interactive_visualizer",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "build.lib.word_manifold.visualization.interactive_visualizer",
        "description": "build.lib.word_manifold.visualization.interactive_visualizer",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass InteractiveVisualizer:\n    \"\"\"\n    Interactive visualization class for exploring semantic spaces.\n    This class provides real-time visualization of word embeddings and\n    semantic transformations, with support for:\n    - Dynamic embedding projection\n    - Interactive exploration of semantic neighborhoods\n    - Real-time visualization of transformations\n    - Multiple visualization modes (2D/3D)",
        "detail": "build.lib.word_manifold.visualization.interactive_visualizer",
        "documentation": {}
    },
    {
        "label": "SemanticNeRF",
        "kind": 6,
        "importPath": "build.lib.word_manifold.visualization.nerf_renderer",
        "description": "build.lib.word_manifold.visualization.nerf_renderer",
        "peekOfCode": "class SemanticNeRF(nn.Module):\n    \"\"\"Neural network for semantic radiance fields.\"\"\"\n    def __init__(\n        self,\n        embedding_dim: int,\n        hidden_dim: int = 256,\n        n_layers: int = 8,\n        activation: nn.Module = nn.ReLU()\n    ):\n        \"\"\"",
        "detail": "build.lib.word_manifold.visualization.nerf_renderer",
        "documentation": {}
    },
    {
        "label": "PositionalEncoding",
        "kind": 6,
        "importPath": "build.lib.word_manifold.visualization.nerf_renderer",
        "description": "build.lib.word_manifold.visualization.nerf_renderer",
        "peekOfCode": "class PositionalEncoding(nn.Module):\n    \"\"\"Positional encoding for continuous input coordinates.\"\"\"\n    def __init__(self, input_dim: int, n_freqs: int = 10):\n        \"\"\"\n        Initialize positional encoding.\n        Args:\n            input_dim: Dimension of input coordinates\n            n_freqs: Number of frequency bands to use\n        \"\"\"\n        super().__init__()",
        "detail": "build.lib.word_manifold.visualization.nerf_renderer",
        "documentation": {}
    },
    {
        "label": "SemanticAttention",
        "kind": 6,
        "importPath": "build.lib.word_manifold.visualization.nerf_renderer",
        "description": "build.lib.word_manifold.visualization.nerf_renderer",
        "peekOfCode": "class SemanticAttention(nn.Module):\n    \"\"\"Attention mechanism for semantic feature refinement.\"\"\"\n    def __init__(self, embedding_dim: int, hidden_dim: int):\n        \"\"\"\n        Initialize semantic attention module.\n        Args:\n            embedding_dim: Dimension of semantic embeddings\n            hidden_dim: Size of hidden layer\n        \"\"\"\n        super().__init__()",
        "detail": "build.lib.word_manifold.visualization.nerf_renderer",
        "documentation": {}
    },
    {
        "label": "NeRFRenderer",
        "kind": 6,
        "importPath": "build.lib.word_manifold.visualization.nerf_renderer",
        "description": "build.lib.word_manifold.visualization.nerf_renderer",
        "peekOfCode": "class NeRFRenderer:\n    \"\"\"Main renderer class for semantic NeRF visualization.\"\"\"\n    def __init__(\n        self,\n        embedding_dim: int,\n        device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n        **nerf_kwargs\n    ):\n        \"\"\"\n        Initialize the NeRF renderer.",
        "detail": "build.lib.word_manifold.visualization.nerf_renderer",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "build.lib.word_manifold.visualization.nerf_renderer",
        "description": "build.lib.word_manifold.visualization.nerf_renderer",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass SemanticNeRF(nn.Module):\n    \"\"\"Neural network for semantic radiance fields.\"\"\"\n    def __init__(\n        self,\n        embedding_dim: int,\n        hidden_dim: int = 256,\n        n_layers: int = 8,\n        activation: nn.Module = nn.ReLU()\n    ):",
        "detail": "build.lib.word_manifold.visualization.nerf_renderer",
        "documentation": {}
    },
    {
        "label": "VisualizationServer",
        "kind": 6,
        "importPath": "build.lib.word_manifold.visualization.server",
        "description": "build.lib.word_manifold.visualization.server",
        "peekOfCode": "class VisualizationServer:\n    \"\"\"Server for interactive visualization of word embeddings and semantic analysis.\"\"\"\n    def __init__(\n        self,\n        embeddings: np.ndarray,\n        labels: List[str],\n        host: str = \"localhost\",\n        port: int = 5000,\n        debug: bool = False\n    ):",
        "detail": "build.lib.word_manifold.visualization.server",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "build.lib.word_manifold.visualization.server",
        "description": "build.lib.word_manifold.visualization.server",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass VisualizationServer:\n    \"\"\"Server for interactive visualization of word embeddings and semantic analysis.\"\"\"\n    def __init__(\n        self,\n        embeddings: np.ndarray,\n        labels: List[str],\n        host: str = \"localhost\",\n        port: int = 5000,\n        debug: bool = False",
        "detail": "build.lib.word_manifold.visualization.server",
        "documentation": {}
    },
    {
        "label": "ExportConfig",
        "kind": 6,
        "importPath": "build.lib.word_manifold.visualization.shape_visualizer",
        "description": "build.lib.word_manifold.visualization.shape_visualizer",
        "peekOfCode": "class ExportConfig:\n    \"\"\"Configuration for exporting visualizations.\"\"\"\n    def __init__(\n        self,\n        format: str = \"mp4\",\n        dpi: int = 300,\n        fps: int = 60,\n        bitrate: int = 2000,\n        save_frames: bool = True,\n        output_dir: Optional[str] = None",
        "detail": "build.lib.word_manifold.visualization.shape_visualizer",
        "documentation": {}
    },
    {
        "label": "ShapeVisualizer",
        "kind": 6,
        "importPath": "build.lib.word_manifold.visualization.shape_visualizer",
        "description": "build.lib.word_manifold.visualization.shape_visualizer",
        "peekOfCode": "class ShapeVisualizer:\n    \"\"\"\n    Advanced visualization class for semantic shapes with enhanced visual encoding.\n    \"\"\"\n    def __init__(\n        self,\n        color_scheme: str = \"semantic\",\n        use_textures: bool = True,\n        export_config: Optional[ExportConfig] = None\n    ):",
        "detail": "build.lib.word_manifold.visualization.shape_visualizer",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "build.lib.word_manifold.visualization.shape_visualizer",
        "description": "build.lib.word_manifold.visualization.shape_visualizer",
        "peekOfCode": "logger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)  # Default to INFO level\n# Create formatters and handlers if they don't exist\nif not logger.handlers:\n    # Create console handler with formatting\n    console_handler = logging.StreamHandler()\n    console_handler.setLevel(logging.INFO)\n    console_formatter = logging.Formatter(\n        '%(asctime)s - %(name)s - [%(levelname)s] - %(message)s'\n    )",
        "detail": "build.lib.word_manifold.visualization.shape_visualizer",
        "documentation": {}
    },
    {
        "label": "Simple3DVisualizer",
        "kind": 6,
        "importPath": "build.lib.word_manifold.visualization.simple_3d_visualizer",
        "description": "build.lib.word_manifold.visualization.simple_3d_visualizer",
        "peekOfCode": "class Simple3DVisualizer:\n    \"\"\"\n    Basic 3D visualization class as an alternative to HyperTools.\n    This visualizer provides 3D visualizations using matplotlib\n    to avoid compatibility issues with HyperTools and NumPy 2.0.\n    \"\"\"\n    def __init__(\n        self,\n        output_dir: str = \"visualizations/3d\",\n        color_palette: str = \"viridis\",",
        "detail": "build.lib.word_manifold.visualization.simple_3d_visualizer",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "build.lib.word_manifold.visualization.simple_3d_visualizer",
        "description": "build.lib.word_manifold.visualization.simple_3d_visualizer",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass Simple3DVisualizer:\n    \"\"\"\n    Basic 3D visualization class as an alternative to HyperTools.\n    This visualizer provides 3D visualizations using matplotlib\n    to avoid compatibility issues with HyperTools and NumPy 2.0.\n    \"\"\"\n    def __init__(\n        self,\n        output_dir: str = \"visualizations/3d\",",
        "detail": "build.lib.word_manifold.visualization.simple_3d_visualizer",
        "documentation": {}
    },
    {
        "label": "ManifoldVisualizer",
        "kind": 6,
        "importPath": "build.lib.word_manifold.visualization.visualizer",
        "description": "build.lib.word_manifold.visualization.visualizer",
        "peekOfCode": "class ManifoldVisualizer:\n    \"\"\"\n    Advanced visualization class for exploring word manifolds.\n    Features:\n    - Interactive 3D visualization with plotly\n    - Dynamic term relationships\n    - Sonic feedback for term distances\n    - Color encoding of semantic properties\n    - Animated transitions\n    - Multi-scale visualization",
        "detail": "build.lib.word_manifold.visualization.visualizer",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "build.lib.word_manifold.visualization.visualizer",
        "description": "build.lib.word_manifold.visualization.visualizer",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass ManifoldVisualizer:\n    \"\"\"\n    Advanced visualization class for exploring word manifolds.\n    Features:\n    - Interactive 3D visualization with plotly\n    - Dynamic term relationships\n    - Sonic feedback for term distances\n    - Color encoding of semantic properties\n    - Animated transitions",
        "detail": "build.lib.word_manifold.visualization.visualizer",
        "documentation": {}
    },
    {
        "label": "CellType",
        "kind": 6,
        "importPath": "build.lib.word_manifold.types",
        "description": "build.lib.word_manifold.types",
        "peekOfCode": "class CellType(Enum):\n    \"\"\"Types of cells with occult correspondences.\"\"\"\n    ELEMENTAL = auto()   # Corresponds to the four elements\n    PLANETARY = auto()   # Corresponds to planetary influences\n    ZODIACAL = auto()    # Corresponds to zodiac signs\n    TAROT = auto()       # Corresponds to tarot archetypes\n    SEPHIROTIC = auto()  # Corresponds to Kabbalistic sephiroth\n    OTHER = auto()       # Default/unclassified\nclass DistanceType(Enum):\n    \"\"\"Types of distance metrics for cell relationships.\"\"\"",
        "detail": "build.lib.word_manifold.types",
        "documentation": {}
    },
    {
        "label": "DistanceType",
        "kind": 6,
        "importPath": "build.lib.word_manifold.types",
        "description": "build.lib.word_manifold.types",
        "peekOfCode": "class DistanceType(Enum):\n    \"\"\"Types of distance metrics for cell relationships.\"\"\"\n    EUCLIDEAN = auto()      # Standard Euclidean distance\n    COSINE = auto()         # Cosine distance (semantic similarity)\n    NUMEROLOGICAL = auto()  # Distance weighted by numerological values\n    HYBRID = auto()         # Combination of semantic and numerological",
        "detail": "build.lib.word_manifold.types",
        "documentation": {}
    },
    {
        "label": "setup_system",
        "kind": 2,
        "importPath": "examples.automata.evolution_demo",
        "description": "examples.automata.evolution_demo",
        "peekOfCode": "def setup_system():\n    \"\"\"Set up the automata system with initial terms and rules.\"\"\"\n    # Initialize embeddings with occult terms\n    embeddings = WordEmbeddings()\n    terms = {\n        \"thelema\", \"will\", \"love\", \"magick\", \"ritual\",\n        \"knowledge\", \"wisdom\", \"power\", \"light\", \"dark\",\n        \"earth\", \"air\", \"fire\", \"water\", \"spirit\",\n        \"sun\", \"moon\", \"mercury\", \"venus\", \"mars\"\n    }",
        "detail": "examples.automata.evolution_demo",
        "documentation": {}
    },
    {
        "label": "demonstrate_evolution",
        "kind": 2,
        "importPath": "examples.automata.evolution_demo",
        "description": "examples.automata.evolution_demo",
        "peekOfCode": "def demonstrate_evolution(system: AutomataSystem):\n    \"\"\"Demonstrate different evolution patterns.\"\"\"\n    # Individual rule evolution\n    logger.info(\"\\nApplying individual rules:\")\n    for rule_name in [\"great_work\", \"equilibrium\", \"tower\"]:\n        rule = system.rules[rule_name]\n        logger.info(\"Applying rule: %s\" % rule.name)\n        logger.info(\"Description: %s\" % rule.description)\n        rule.apply(system.manifold, system.generation)\n        state = system.manifold.get_manifold_state()",
        "detail": "examples.automata.evolution_demo",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "examples.automata.evolution_demo",
        "description": "examples.automata.evolution_demo",
        "peekOfCode": "def main():\n    # Set up system\n    system = setup_system()\n    logger.info(\"Initialized automata system\")\n    # Demonstrate evolution\n    demonstrate_evolution(system)\n    logger.info(\"\\nEvolution demonstration complete\")\nif __name__ == \"__main__\":\n    main()",
        "detail": "examples.automata.evolution_demo",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "examples.automata.evolution_demo",
        "description": "examples.automata.evolution_demo",
        "peekOfCode": "logger = logging.getLogger(__name__)\ndef setup_system():\n    \"\"\"Set up the automata system with initial terms and rules.\"\"\"\n    # Initialize embeddings with occult terms\n    embeddings = WordEmbeddings()\n    terms = {\n        \"thelema\", \"will\", \"love\", \"magick\", \"ritual\",\n        \"knowledge\", \"wisdom\", \"power\", \"light\", \"dark\",\n        \"earth\", \"air\", \"fire\", \"water\", \"spirit\",\n        \"sun\", \"moon\", \"mercury\", \"venus\", \"mars\"",
        "detail": "examples.automata.evolution_demo",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "examples.embeddings.word_embeddings_demo",
        "description": "examples.embeddings.word_embeddings_demo",
        "peekOfCode": "def main():\n    # Initialize embeddings\n    embeddings = WordEmbeddings()\n    logger.info(\"Initialized word embeddings model\")\n    # Load standard occult terms\n    embeddings.load_terms(OCCULT_TERMS)\n    logger.info(f\"Loaded {len(OCCULT_TERMS)} occult terms\")\n    # Demonstrate similarity search\n    query_terms = [\"magic\", \"thelema\", \"ritual\"]\n    k = 5  # Number of similar terms to find",
        "detail": "examples.embeddings.word_embeddings_demo",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "examples.embeddings.word_embeddings_demo",
        "description": "examples.embeddings.word_embeddings_demo",
        "peekOfCode": "logger = logging.getLogger(__name__)\ndef main():\n    # Initialize embeddings\n    embeddings = WordEmbeddings()\n    logger.info(\"Initialized word embeddings model\")\n    # Load standard occult terms\n    embeddings.load_terms(OCCULT_TERMS)\n    logger.info(f\"Loaded {len(OCCULT_TERMS)} occult terms\")\n    # Demonstrate similarity search\n    query_terms = [\"magic\", \"thelema\", \"ritual\"]",
        "detail": "examples.embeddings.word_embeddings_demo",
        "documentation": {}
    },
    {
        "label": "n_points",
        "kind": 5,
        "importPath": "examples.manifold.manifold_learning",
        "description": "examples.manifold.manifold_learning",
        "peekOfCode": "n_points = 1000\nX, color = datasets.make_swiss_roll(n_points, random_state=0)\nn_neighbors = 10\nn_components = 2\n# Creating the plot\nfig = plt.figure(figsize=(15, 8))\nfig.suptitle(\"Manifold Learning with %i points, %i neighbors\"\n             % (1000, n_neighbors), fontsize=14)\n# Adding 3d scatter plot\nax = fig.add_subplot(231, projection='3d')",
        "detail": "examples.manifold.manifold_learning",
        "documentation": {}
    },
    {
        "label": "n_neighbors",
        "kind": 5,
        "importPath": "examples.manifold.manifold_learning",
        "description": "examples.manifold.manifold_learning",
        "peekOfCode": "n_neighbors = 10\nn_components = 2\n# Creating the plot\nfig = plt.figure(figsize=(15, 8))\nfig.suptitle(\"Manifold Learning with %i points, %i neighbors\"\n             % (1000, n_neighbors), fontsize=14)\n# Adding 3d scatter plot\nax = fig.add_subplot(231, projection='3d')\nax.scatter(X[:, 0], X[:, 1], X[:, 2], c=color, cmap=plt.cm.Spectral)\nax.view_init(4, -72)",
        "detail": "examples.manifold.manifold_learning",
        "documentation": {}
    },
    {
        "label": "n_components",
        "kind": 5,
        "importPath": "examples.manifold.manifold_learning",
        "description": "examples.manifold.manifold_learning",
        "peekOfCode": "n_components = 2\n# Creating the plot\nfig = plt.figure(figsize=(15, 8))\nfig.suptitle(\"Manifold Learning with %i points, %i neighbors\"\n             % (1000, n_neighbors), fontsize=14)\n# Adding 3d scatter plot\nax = fig.add_subplot(231, projection='3d')\nax.scatter(X[:, 0], X[:, 1], X[:, 2], c=color, cmap=plt.cm.Spectral)\nax.view_init(4, -72)\n# Making a dictionary 'methods' containing LLE, t-SNE and PCA",
        "detail": "examples.manifold.manifold_learning",
        "documentation": {}
    },
    {
        "label": "fig",
        "kind": 5,
        "importPath": "examples.manifold.manifold_learning",
        "description": "examples.manifold.manifold_learning",
        "peekOfCode": "fig = plt.figure(figsize=(15, 8))\nfig.suptitle(\"Manifold Learning with %i points, %i neighbors\"\n             % (1000, n_neighbors), fontsize=14)\n# Adding 3d scatter plot\nax = fig.add_subplot(231, projection='3d')\nax.scatter(X[:, 0], X[:, 1], X[:, 2], c=color, cmap=plt.cm.Spectral)\nax.view_init(4, -72)\n# Making a dictionary 'methods' containing LLE, t-SNE and PCA\nLLE = partial(manifold.LocallyLinearEmbedding,\n              n_neighbors, n_components, eigen_solver='auto')",
        "detail": "examples.manifold.manifold_learning",
        "documentation": {}
    },
    {
        "label": "ax",
        "kind": 5,
        "importPath": "examples.manifold.manifold_learning",
        "description": "examples.manifold.manifold_learning",
        "peekOfCode": "ax = fig.add_subplot(231, projection='3d')\nax.scatter(X[:, 0], X[:, 1], X[:, 2], c=color, cmap=plt.cm.Spectral)\nax.view_init(4, -72)\n# Making a dictionary 'methods' containing LLE, t-SNE and PCA\nLLE = partial(manifold.LocallyLinearEmbedding,\n              n_neighbors, n_components, eigen_solver='auto')\nmethods = OrderedDict()\nmethods['LLE'] = LLE(method='standard')\nmethods['t-SNE'] = manifold.TSNE(n_components=n_components, init='pca',\n                                 random_state=0)",
        "detail": "examples.manifold.manifold_learning",
        "documentation": {}
    },
    {
        "label": "LLE",
        "kind": 5,
        "importPath": "examples.manifold.manifold_learning",
        "description": "examples.manifold.manifold_learning",
        "peekOfCode": "LLE = partial(manifold.LocallyLinearEmbedding,\n              n_neighbors, n_components, eigen_solver='auto')\nmethods = OrderedDict()\nmethods['LLE'] = LLE(method='standard')\nmethods['t-SNE'] = manifold.TSNE(n_components=n_components, init='pca',\n                                 random_state=0)\nmethods['PCA']=PCA(n_components=2)\n# Plotting the results\nfor i, (label, method) in enumerate(methods.items()):\n    t0 = time()",
        "detail": "examples.manifold.manifold_learning",
        "documentation": {}
    },
    {
        "label": "methods",
        "kind": 5,
        "importPath": "examples.manifold.manifold_learning",
        "description": "examples.manifold.manifold_learning",
        "peekOfCode": "methods = OrderedDict()\nmethods['LLE'] = LLE(method='standard')\nmethods['t-SNE'] = manifold.TSNE(n_components=n_components, init='pca',\n                                 random_state=0)\nmethods['PCA']=PCA(n_components=2)\n# Plotting the results\nfor i, (label, method) in enumerate(methods.items()):\n    t0 = time()\n    Y = method.fit_transform(X)\n    t1 = time()",
        "detail": "examples.manifold.manifold_learning",
        "documentation": {}
    },
    {
        "label": "methods['LLE']",
        "kind": 5,
        "importPath": "examples.manifold.manifold_learning",
        "description": "examples.manifold.manifold_learning",
        "peekOfCode": "methods['LLE'] = LLE(method='standard')\nmethods['t-SNE'] = manifold.TSNE(n_components=n_components, init='pca',\n                                 random_state=0)\nmethods['PCA']=PCA(n_components=2)\n# Plotting the results\nfor i, (label, method) in enumerate(methods.items()):\n    t0 = time()\n    Y = method.fit_transform(X)\n    t1 = time()\n    print(\"%s: %.2g sec\" % (label, t1 - t0))",
        "detail": "examples.manifold.manifold_learning",
        "documentation": {}
    },
    {
        "label": "methods['t-SNE']",
        "kind": 5,
        "importPath": "examples.manifold.manifold_learning",
        "description": "examples.manifold.manifold_learning",
        "peekOfCode": "methods['t-SNE'] = manifold.TSNE(n_components=n_components, init='pca',\n                                 random_state=0)\nmethods['PCA']=PCA(n_components=2)\n# Plotting the results\nfor i, (label, method) in enumerate(methods.items()):\n    t0 = time()\n    Y = method.fit_transform(X)\n    t1 = time()\n    print(\"%s: %.2g sec\" % (label, t1 - t0))\n    ax = fig.add_subplot(2, 3, 2 + i+(i>1))",
        "detail": "examples.manifold.manifold_learning",
        "documentation": {}
    },
    {
        "label": "VisualizationResult",
        "kind": 6,
        "importPath": "examples.visualization.example_visualizations",
        "description": "examples.visualization.example_visualizations",
        "peekOfCode": "class VisualizationResult:\n    \"\"\"Track the success and outputs of visualization operations.\"\"\"\n    def __init__(self):\n        self.ritual_evolution_success = False\n        self.shape_field_success = False\n        self.comparative_success = False\n        self.saved_files: List[str] = []\n    def add_saved_file(self, filepath: str):\n        \"\"\"Record a successfully saved visualization file.\"\"\"\n        self.saved_files.append(filepath)",
        "detail": "examples.visualization.example_visualizations",
        "documentation": {}
    },
    {
        "label": "ritual_evolution_example",
        "kind": 2,
        "importPath": "examples.visualization.example_visualizations",
        "description": "examples.visualization.example_visualizations",
        "peekOfCode": "def ritual_evolution_example(result: VisualizationResult):\n    \"\"\"Demonstrate ritual evolution visualization.\"\"\"\n    try:\n        # Initialize embeddings and manifold\n        embeddings = WordEmbeddings(model_name='en_core_web_sm')\n        # Define ritual sequence with key terms\n        terms = [\n            \"light\", \"darkness\", \"wisdom\", \"understanding\",\n            \"beauty\", \"strength\", \"mercy\", \"severity\"\n        ]",
        "detail": "examples.visualization.example_visualizations",
        "documentation": {}
    },
    {
        "label": "semantic_shape_example",
        "kind": 2,
        "importPath": "examples.visualization.example_visualizations",
        "description": "examples.visualization.example_visualizations",
        "peekOfCode": "def semantic_shape_example(result: VisualizationResult):\n    \"\"\"Demonstrate semantic shape visualization.\"\"\"\n    try:\n        # Initialize visualizer\n        visualizer = ShapeVisualizer()\n        # Example 1: Ritual text visualization\n        ritual_text = \"\"\"\n        I am the flame that burns in every heart of man,\n        and in the core of every star.\n        I am Life, and the giver of Life,",
        "detail": "examples.visualization.example_visualizations",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "examples.visualization.example_visualizations",
        "description": "examples.visualization.example_visualizations",
        "peekOfCode": "def main():\n    \"\"\"Run visualization examples.\"\"\"\n    # Set environment variable for tokenizers\n    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n    # Initialize result tracking\n    result = VisualizationResult()\n    try:\n        ritual_evolution_example(result)\n        semantic_shape_example(result)\n    except Exception as e:",
        "detail": "examples.visualization.example_visualizations",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "examples.visualization.example_visualizations",
        "description": "examples.visualization.example_visualizations",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass VisualizationResult:\n    \"\"\"Track the success and outputs of visualization operations.\"\"\"\n    def __init__(self):\n        self.ritual_evolution_success = False\n        self.shape_field_success = False\n        self.comparative_success = False\n        self.saved_files: List[str] = []\n    def add_saved_file(self, filepath: str):\n        \"\"\"Record a successfully saved visualization file.\"\"\"",
        "detail": "examples.visualization.example_visualizations",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "examples.visualization.semantic_tree_example",
        "description": "examples.visualization.semantic_tree_example",
        "peekOfCode": "def main():\n    # Initialize visualizer\n    visualizer = SemanticTreeVisualizer(\n        output_dir=\"visualizations/semantic_trees\",\n        node_size_base=800,\n        min_similarity=0.3\n    )\n    # Example 1: Simple concept hierarchy\n    root = \"consciousness\"\n    related_terms = set([",
        "detail": "examples.visualization.semantic_tree_example",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "examples.visualization.shape_visualization",
        "description": "examples.visualization.shape_visualization",
        "peekOfCode": "def main():\n    \"\"\"Run semantic shape visualization examples.\"\"\"\n    # Create visualizer\n    visualizer = ShapeVisualizer()\n    # Example 1: Visualize evolution of a poetic text\n    print(\"Creating visualization of poetic evolution...\")\n    poetic_text = \"\"\"\n    The stars move still, time runs, the clock will strike,\n    The devil will come, and Faustus must be damned.\n    O, I'll leap up to my God! Who pulls me down?",
        "detail": "examples.visualization.shape_visualization",
        "documentation": {}
    },
    {
        "label": "os.environ[\"TOKENIZERS_PARALLELISM\"]",
        "kind": 5,
        "importPath": "examples.visualization.shape_visualization",
        "description": "examples.visualization.shape_visualization",
        "peekOfCode": "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\ndef main():\n    \"\"\"Run semantic shape visualization examples.\"\"\"\n    # Create visualizer\n    visualizer = ShapeVisualizer()\n    # Example 1: Visualize evolution of a poetic text\n    print(\"Creating visualization of poetic evolution...\")\n    poetic_text = \"\"\"\n    The stars move still, time runs, the clock will strike,\n    The devil will come, and Faustus must be damned.",
        "detail": "examples.visualization.shape_visualization",
        "documentation": {}
    },
    {
        "label": "PPCA",
        "kind": 6,
        "importPath": "hypertools.build.lib.hypertools._externals.ppca",
        "description": "hypertools.build.lib.hypertools._externals.ppca",
        "peekOfCode": "class PPCA(object):\n    def __init__(self):\n        self.raw = None\n        self.data = None\n        self.C = None\n        self.means = None\n        self.stds = None\n    def _standardize(self, X):\n        if self.means is None or self.stds is None:\n            raise RuntimeError(\"Fit model first\")",
        "detail": "hypertools.build.lib.hypertools._externals.ppca",
        "documentation": {}
    },
    {
        "label": "SRM",
        "kind": 6,
        "importPath": "hypertools.build.lib.hypertools._externals.srm",
        "description": "hypertools.build.lib.hypertools._externals.srm",
        "peekOfCode": "class SRM(BaseEstimator, TransformerMixin):\n    \"\"\"Probabilistic Shared Response Model (SRM)\n    Given multi-subject data, factorize it as a shared response S among all\n    subjects and an orthogonal transform W per subject:\n    .. math:: X_i \\\\approx W_i S, \\\\forall i=1 \\\\dots N\n    Parameters\n    ----------\n    n_iter : int, default: 10\n        Number of iterations to run the algorithm.\n    features : int, default: 50",
        "detail": "hypertools.build.lib.hypertools._externals.srm",
        "documentation": {}
    },
    {
        "label": "DetSRM",
        "kind": 6,
        "importPath": "hypertools.build.lib.hypertools._externals.srm",
        "description": "hypertools.build.lib.hypertools._externals.srm",
        "peekOfCode": "class DetSRM(BaseEstimator, TransformerMixin):\n    \"\"\"Deterministic Shared Response Model (DetSRM)\n    Given multi-subject data, factorize it as a shared response S among all\n    subjects and an orthogonal transform W per subject:\n    .. math:: X_i \\\\approx W_i S, \\\\forall i=1 \\\\dots N\n    Parameters\n    ----------\n    n_iter : int, default: 10\n        Number of iterations to run the algorithm.\n    features : int, default: 50",
        "detail": "hypertools.build.lib.hypertools._externals.srm",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "hypertools.build.lib.hypertools._externals.srm",
        "description": "hypertools.build.lib.hypertools._externals.srm",
        "peekOfCode": "__all__ = [\n    \"SRM\", \"DetSRM\"\n]\nlogger = logging.getLogger(__name__)\ndef _init_w_transforms(data, features):\n    \"\"\"Initialize the mappings (Wi) for the SRM with random orthogonal matrices.\n    Parameters\n    ----------\n    data : list of 2D arrays, element i has shape=[voxels_i, samples]\n        Each element in the list contains the fMRI data of one subject.",
        "detail": "hypertools.build.lib.hypertools._externals.srm",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "hypertools.build.lib.hypertools._externals.srm",
        "description": "hypertools.build.lib.hypertools._externals.srm",
        "peekOfCode": "logger = logging.getLogger(__name__)\ndef _init_w_transforms(data, features):\n    \"\"\"Initialize the mappings (Wi) for the SRM with random orthogonal matrices.\n    Parameters\n    ----------\n    data : list of 2D arrays, element i has shape=[voxels_i, samples]\n        Each element in the list contains the fMRI data of one subject.\n    features : int\n        The number of features in the model.\n    Returns",
        "detail": "hypertools.build.lib.hypertools._externals.srm",
        "documentation": {}
    },
    {
        "label": "HypertoolsError",
        "kind": 6,
        "importPath": "hypertools.build.lib.hypertools._shared.exceptions",
        "description": "hypertools.build.lib.hypertools._shared.exceptions",
        "peekOfCode": "class HypertoolsError(Exception):\n    pass\nclass HypertoolsBackendError(HypertoolsError):\n    def __init__(self, message):\n        super().__init__(message)\n        self.message = message\nclass HypertoolsIOError(HypertoolsError, OSError):\n    def __init__(self, message):\n        super().__init__(message)\n        self.message = message",
        "detail": "hypertools.build.lib.hypertools._shared.exceptions",
        "documentation": {}
    },
    {
        "label": "HypertoolsBackendError",
        "kind": 6,
        "importPath": "hypertools.build.lib.hypertools._shared.exceptions",
        "description": "hypertools.build.lib.hypertools._shared.exceptions",
        "peekOfCode": "class HypertoolsBackendError(HypertoolsError):\n    def __init__(self, message):\n        super().__init__(message)\n        self.message = message\nclass HypertoolsIOError(HypertoolsError, OSError):\n    def __init__(self, message):\n        super().__init__(message)\n        self.message = message",
        "detail": "hypertools.build.lib.hypertools._shared.exceptions",
        "documentation": {}
    },
    {
        "label": "HypertoolsIOError",
        "kind": 6,
        "importPath": "hypertools.build.lib.hypertools._shared.exceptions",
        "description": "hypertools.build.lib.hypertools._shared.exceptions",
        "peekOfCode": "class HypertoolsIOError(HypertoolsError, OSError):\n    def __init__(self, message):\n        super().__init__(message)\n        self.message = message",
        "detail": "hypertools.build.lib.hypertools._shared.exceptions",
        "documentation": {}
    },
    {
        "label": "center",
        "kind": 2,
        "importPath": "hypertools.build.lib.hypertools._shared.helpers",
        "description": "hypertools.build.lib.hypertools._shared.helpers",
        "peekOfCode": "def center(x):\n    assert type(x) is list, \"Input data to center must be list\"\n    x_stacked = np.vstack(x)\n    return [i - np.mean(x_stacked, 0) for i in x]\ndef scale(x):\n    assert type(x) is list, \"Input data to scale must be list\"\n    x_stacked = np.vstack(x)\n    m1 = np.min(x_stacked)\n    m2 = np.max(x_stacked - m1)\n    f = lambda x: 2*(np.divide(x - m1, m2)) - 1",
        "detail": "hypertools.build.lib.hypertools._shared.helpers",
        "documentation": {}
    },
    {
        "label": "scale",
        "kind": 2,
        "importPath": "hypertools.build.lib.hypertools._shared.helpers",
        "description": "hypertools.build.lib.hypertools._shared.helpers",
        "peekOfCode": "def scale(x):\n    assert type(x) is list, \"Input data to scale must be list\"\n    x_stacked = np.vstack(x)\n    m1 = np.min(x_stacked)\n    m2 = np.max(x_stacked - m1)\n    f = lambda x: 2*(np.divide(x - m1, m2)) - 1\n    return [f(i) for i in x]\ndef group_by_category(vals):\n    if any(isinstance(el, list) for el in vals):\n        vals = list(itertools.chain(*vals))",
        "detail": "hypertools.build.lib.hypertools._shared.helpers",
        "documentation": {}
    },
    {
        "label": "group_by_category",
        "kind": 2,
        "importPath": "hypertools.build.lib.hypertools._shared.helpers",
        "description": "hypertools.build.lib.hypertools._shared.helpers",
        "peekOfCode": "def group_by_category(vals):\n    if any(isinstance(el, list) for el in vals):\n        vals = list(itertools.chain(*vals))\n    val_set = list(sorted(set(vals), key=list(vals).index))\n    return [val_set.index(val) for val in vals]\ndef vals2colors(vals, cmap='GnBu',res=100):\n    \"\"\"Maps values to colors\n    Args:\n    values (list or list of lists) - list of values to map to colors\n    cmap (str) - color map (default is 'GnBu')",
        "detail": "hypertools.build.lib.hypertools._shared.helpers",
        "documentation": {}
    },
    {
        "label": "vals2colors",
        "kind": 2,
        "importPath": "hypertools.build.lib.hypertools._shared.helpers",
        "description": "hypertools.build.lib.hypertools._shared.helpers",
        "peekOfCode": "def vals2colors(vals, cmap='GnBu',res=100):\n    \"\"\"Maps values to colors\n    Args:\n    values (list or list of lists) - list of values to map to colors\n    cmap (str) - color map (default is 'GnBu')\n    res (int) - resolution of the color map (default: 100)\n    Returns:\n    list of rgb tuples\n    \"\"\"\n    # flatten if list of lists",
        "detail": "hypertools.build.lib.hypertools._shared.helpers",
        "documentation": {}
    },
    {
        "label": "vals2bins",
        "kind": 2,
        "importPath": "hypertools.build.lib.hypertools._shared.helpers",
        "description": "hypertools.build.lib.hypertools._shared.helpers",
        "peekOfCode": "def vals2bins(vals,res=100):\n    \"\"\"Maps values to bins\n    Args:\n    values (list or list of lists) - list of values to map to colors\n    res (int) - resolution of the color map (default: 100)\n    Returns:\n    list of numbers representing bins\n    \"\"\"\n    # flatten if list of lists\n    if any(isinstance(el, list) for el in vals):",
        "detail": "hypertools.build.lib.hypertools._shared.helpers",
        "documentation": {}
    },
    {
        "label": "interp_array",
        "kind": 2,
        "importPath": "hypertools.build.lib.hypertools._shared.helpers",
        "description": "hypertools.build.lib.hypertools._shared.helpers",
        "peekOfCode": "def interp_array(arr,interp_val=10):\n    x=np.arange(0, len(arr), 1)\n    xx=np.arange(0, len(arr)-1, 1/interp_val)\n    q=pchip(x,arr)\n    return q(xx)\ndef interp_array_list(arr_list,interp_val=10):\n    smoothed= [np.zeros(arr_list[0].shape) for item in arr_list]\n    for idx,arr in enumerate(arr_list):\n        smoothed[idx] = interp_array(arr,interp_val)\n    return smoothed",
        "detail": "hypertools.build.lib.hypertools._shared.helpers",
        "documentation": {}
    },
    {
        "label": "interp_array_list",
        "kind": 2,
        "importPath": "hypertools.build.lib.hypertools._shared.helpers",
        "description": "hypertools.build.lib.hypertools._shared.helpers",
        "peekOfCode": "def interp_array_list(arr_list,interp_val=10):\n    smoothed= [np.zeros(arr_list[0].shape) for item in arr_list]\n    for idx,arr in enumerate(arr_list):\n        smoothed[idx] = interp_array(arr,interp_val)\n    return smoothed\ndef parse_args(x,args):\n    args_list = []\n    for i,item in enumerate(x):\n        tmp = []\n        for ii, arg in enumerate(args):",
        "detail": "hypertools.build.lib.hypertools._shared.helpers",
        "documentation": {}
    },
    {
        "label": "parse_args",
        "kind": 2,
        "importPath": "hypertools.build.lib.hypertools._shared.helpers",
        "description": "hypertools.build.lib.hypertools._shared.helpers",
        "peekOfCode": "def parse_args(x,args):\n    args_list = []\n    for i,item in enumerate(x):\n        tmp = []\n        for ii, arg in enumerate(args):\n            if isinstance(arg, (tuple, list)):\n                if len(arg) == len(x):\n                    tmp.append(arg[i])\n                else:\n                    print('Error: arguments must be a list of the same length as x')",
        "detail": "hypertools.build.lib.hypertools._shared.helpers",
        "documentation": {}
    },
    {
        "label": "parse_kwargs",
        "kind": 2,
        "importPath": "hypertools.build.lib.hypertools._shared.helpers",
        "description": "hypertools.build.lib.hypertools._shared.helpers",
        "peekOfCode": "def parse_kwargs(x, kwargs):\n    kwargs_list = []\n    for i,item in enumerate(x):\n        tmp = {}\n        for kwarg in kwargs:\n            if isinstance(kwargs[kwarg], (tuple, list)):\n                if len(kwargs[kwarg]) == len(x):\n                    tmp[kwarg]=kwargs[kwarg][i]\n                else:\n                    tmp[kwarg] = None",
        "detail": "hypertools.build.lib.hypertools._shared.helpers",
        "documentation": {}
    },
    {
        "label": "reshape_data",
        "kind": 2,
        "importPath": "hypertools.build.lib.hypertools._shared.helpers",
        "description": "hypertools.build.lib.hypertools._shared.helpers",
        "peekOfCode": "def reshape_data(x, hue, labels):\n    categories = list(sorted(set(hue), key=list(hue).index))\n    x_stacked = np.vstack(x)\n    x_reshaped = [[] for _ in categories]\n    labels_reshaped = [[] for _ in categories]\n    if labels is None:\n        labels = [None]*len(hue)\n    for idx, (point, label) in enumerate(zip(hue, labels)):\n        x_reshaped[categories.index(point)].append(x_stacked[idx])\n        labels_reshaped[categories.index(point)].append(labels[idx])",
        "detail": "hypertools.build.lib.hypertools._shared.helpers",
        "documentation": {}
    },
    {
        "label": "patch_lines",
        "kind": 2,
        "importPath": "hypertools.build.lib.hypertools._shared.helpers",
        "description": "hypertools.build.lib.hypertools._shared.helpers",
        "peekOfCode": "def patch_lines(x):\n    \"\"\"\n    Draw lines between groups\n    \"\"\"\n    for idx in range(len(x)-1):\n        x[idx] = np.vstack([x[idx], x[idx+1][0,:]])\n    return x\ndef is_line(format_str):\n    if isinstance(format_str, np.bytes_):\n        format_str = format_str.decode('utf-8')",
        "detail": "hypertools.build.lib.hypertools._shared.helpers",
        "documentation": {}
    },
    {
        "label": "is_line",
        "kind": 2,
        "importPath": "hypertools.build.lib.hypertools._shared.helpers",
        "description": "hypertools.build.lib.hypertools._shared.helpers",
        "peekOfCode": "def is_line(format_str):\n    if isinstance(format_str, np.bytes_):\n        format_str = format_str.decode('utf-8')\n    markers = list(map(lambda x: str(x), Line2D.markers.keys()))\n    return (format_str is None) or (all([str(symbol) not in format_str for symbol in markers]))\ndef memoize(obj):\n    cache = obj.cache = {}\n    @functools.wraps(obj)\n    def memoizer(*args, **kwargs):\n        key = str(args) + str(kwargs)",
        "detail": "hypertools.build.lib.hypertools._shared.helpers",
        "documentation": {}
    },
    {
        "label": "memoize",
        "kind": 2,
        "importPath": "hypertools.build.lib.hypertools._shared.helpers",
        "description": "hypertools.build.lib.hypertools._shared.helpers",
        "peekOfCode": "def memoize(obj):\n    cache = obj.cache = {}\n    @functools.wraps(obj)\n    def memoizer(*args, **kwargs):\n        key = str(args) + str(kwargs)\n        if key not in cache:\n            cache[key] = obj(*args, **kwargs)\n        return cache[key]\n    return memoizer\ndef get_type(data):",
        "detail": "hypertools.build.lib.hypertools._shared.helpers",
        "documentation": {}
    },
    {
        "label": "get_type",
        "kind": 2,
        "importPath": "hypertools.build.lib.hypertools._shared.helpers",
        "description": "hypertools.build.lib.hypertools._shared.helpers",
        "peekOfCode": "def get_type(data):\n    \"\"\"\n    Checks what the data type is and returns it as a string label\n    \"\"\"\n    from ..datageometry import DataGeometry\n    if isinstance(data, list):\n        if isinstance(data[0], (str, bytes)):\n            return 'list_str'\n        elif isinstance(data[0], (int, float)):\n            return 'list_num'",
        "detail": "hypertools.build.lib.hypertools._shared.helpers",
        "documentation": {}
    },
    {
        "label": "convert_text",
        "kind": 2,
        "importPath": "hypertools.build.lib.hypertools._shared.helpers",
        "description": "hypertools.build.lib.hypertools._shared.helpers",
        "peekOfCode": "def convert_text(data):\n    dtype = get_type(data)\n    if dtype in ['list_str', 'str']:\n        data = np.array(data).reshape(-1, 1)\n    return data\ndef check_geo(geo):\n    \"\"\" Checks a geo and makes sure the text fields are not binary \"\"\"\n    geo = copy.copy(geo)\n    def fix_item(item):\n        if isinstance(item, bytes):",
        "detail": "hypertools.build.lib.hypertools._shared.helpers",
        "documentation": {}
    },
    {
        "label": "check_geo",
        "kind": 2,
        "importPath": "hypertools.build.lib.hypertools._shared.helpers",
        "description": "hypertools.build.lib.hypertools._shared.helpers",
        "peekOfCode": "def check_geo(geo):\n    \"\"\" Checks a geo and makes sure the text fields are not binary \"\"\"\n    geo = copy.copy(geo)\n    def fix_item(item):\n        if isinstance(item, bytes):\n            return item.decode()\n        return item\n    def fix_list(lst):\n        return [fix_item(i) for i in lst]\n    if isinstance(geo.reduce, bytes):",
        "detail": "hypertools.build.lib.hypertools._shared.helpers",
        "documentation": {}
    },
    {
        "label": "get_dtype",
        "kind": 2,
        "importPath": "hypertools.build.lib.hypertools._shared.helpers",
        "description": "hypertools.build.lib.hypertools._shared.helpers",
        "peekOfCode": "def get_dtype(data):\n    \"\"\"\n    Checks what the data type is and returns it as a string label\n    \"\"\"\n    from ..datageometry import DataGeometry\n    if isinstance(data, list):\n        return 'list'\n    elif isinstance(data, np.ndarray):\n        return 'arr'\n    elif isinstance(data, pd.DataFrame):",
        "detail": "hypertools.build.lib.hypertools._shared.helpers",
        "documentation": {}
    },
    {
        "label": "default_params",
        "kind": 2,
        "importPath": "hypertools.build.lib.hypertools._shared.params",
        "description": "hypertools.build.lib.hypertools._shared.params",
        "peekOfCode": "def default_params(model, update_dict=None):\n    \"\"\"\n    Loads and updates default model parameters\n    Parameters\n    ----------\n    model : str\n        The name of a model\n    update_dict : dict\n        A dict to update default parameters\n    Returns",
        "detail": "hypertools.build.lib.hypertools._shared.params",
        "documentation": {}
    },
    {
        "label": "parameters",
        "kind": 5,
        "importPath": "hypertools.build.lib.hypertools._shared.params",
        "description": "hypertools.build.lib.hypertools._shared.params",
        "peekOfCode": "parameters = {\n    'KMeans': {'n_clusters': 5},\n    'MiniBatchKMeans': {'n_clusters': 5},\n    'SpectralClustering': {'n_clusters': 5,\n                           'affinity': 'nearest_neighbors',\n                           'n_neighbors': 10},\n    'AgglomerativeClustering': {'n_clusters': 5, 'linkage' : 'ward'},\n    'FeatureAgglomeration': {'n_clusters': 5},\n    'Birch': {'n_clusters': 5},\n    'HDBSCAN': {'min_samples': 5, 'min_cluster_size': 15},",
        "detail": "hypertools.build.lib.hypertools._shared.params",
        "documentation": {}
    },
    {
        "label": "ParrotDict",
        "kind": 6,
        "importPath": "hypertools.build.lib.hypertools.plot.backend",
        "description": "hypertools.build.lib.hypertools.plot.backend",
        "peekOfCode": "class ParrotDict(dict):\n    \"\"\"\n    Dictionary subclass with a few changes in behavior:\n      1. all keys and values are stored and indexed as\n         `HypertoolsBackend` instances\n      2. indexing a `ParrotDict` with a key that doesn't exist returns\n         the key (it's \"parroted\" back to you). The key is converted to\n         a `HypertoolsBackend` instance if it is not already. Similar\n         to `collections.defaultdict`, but does *not* add missing keys\n         on indexing.",
        "detail": "hypertools.build.lib.hypertools.plot.backend",
        "documentation": {}
    },
    {
        "label": "BackendMapping",
        "kind": 6,
        "importPath": "hypertools.build.lib.hypertools.plot.backend",
        "description": "hypertools.build.lib.hypertools.plot.backend",
        "peekOfCode": "class BackendMapping:\n    \"\"\"\n    A two-way, non-unique dict-like mapping between keys used to set\n    the matplotlib plotting backend in Python and IPython environments.\n    Primarily used by `as_python()` and `as_ipython()` methods of\n    `HypertoolsBackend`.  Funnels multiple equivalent keys within the\n    same interpreter (Python vs. IPython) to a \"default\", then maps\n    between that and the analog from the other interpreter type. At\n    either step, a key with no corresponding value returns the key (see\n    `ParrotDict` docstring for more info).",
        "detail": "hypertools.build.lib.hypertools.plot.backend",
        "documentation": {}
    },
    {
        "label": "HypertoolsBackend",
        "kind": 6,
        "importPath": "hypertools.build.lib.hypertools.plot.backend",
        "description": "hypertools.build.lib.hypertools.plot.backend",
        "peekOfCode": "class HypertoolsBackend(str):\n    \"\"\"\n    A subclass of the `str` built-in, intended for easy(ish...)\n    conversion between the different valid matplotlib backend keys in\n    Python vs IPython and equality/membership checks.\n    Notes\n    -----\n    Normally, a lot of this could be simplified and a lot of grief saved\n    by subclassing `collections.UserString` rather than `str` directly.\n    The issue is that these objects get passed to a ton of different",
        "detail": "hypertools.build.lib.hypertools.plot.backend",
        "documentation": {}
    },
    {
        "label": "set_interactive_backend",
        "kind": 6,
        "importPath": "hypertools.build.lib.hypertools.plot.backend",
        "description": "hypertools.build.lib.hypertools.plot.backend",
        "peekOfCode": "class set_interactive_backend:\n    \"\"\"\n    Manually set the `matplotlib` backend used for generating\n    interactive plots.\n    Whereas `hypertools.plot`'s `mpl_backend` keyword argument can be\n    used to specify the backend for a single plot,\n    `hypertools.set_interactive_backend` is useful for doing so for\n    multiple (or all) interactive plots at once, and can be in two\n    different ways:\n    1. directly, to change the backend for all subsequent interactive",
        "detail": "hypertools.build.lib.hypertools.plot.backend",
        "documentation": {}
    },
    {
        "label": "manage_backend",
        "kind": 2,
        "importPath": "hypertools.build.lib.hypertools.plot.backend",
        "description": "hypertools.build.lib.hypertools.plot.backend",
        "peekOfCode": "def manage_backend(plot_func):\n    \"\"\"\n    Decorator for hypertools.plot that prevents unexpected changes to\n    matplotlib rcParams (https://github.com/ContextLab/hypertools/issues/243)\n    and handles temporarily changing the matplotlib backend for\n    interactive and animated plots, as necessary.\n    Parameters\n    ----------\n    plot_func : function\n        Function around which to set/reset the plotting backend and",
        "detail": "hypertools.build.lib.hypertools.plot.backend",
        "documentation": {}
    },
    {
        "label": "BACKEND_KEYS",
        "kind": 5,
        "importPath": "hypertools.build.lib.hypertools.plot.backend",
        "description": "hypertools.build.lib.hypertools.plot.backend",
        "peekOfCode": "BACKEND_KEYS = {\n    'TkAgg': 'tk',\n    'GTK3Agg': ['gtk3', 'gtk'],\n    'WXAgg': 'wx',\n    'Qt4Agg': 'qt4',\n    'Qt5Agg': ['qt5', 'qt'],\n    'MacOSX': 'osx',\n    'nbAgg': ['notebook', 'nbagg'],\n    'module://ipykernel.pylab.backend_inline': 'inline',\n    'module://matplotlib_inline.backend_inline': 'inline',",
        "detail": "hypertools.build.lib.hypertools.plot.backend",
        "documentation": {}
    },
    {
        "label": "BACKEND_MAPPING",
        "kind": 5,
        "importPath": "hypertools.build.lib.hypertools.plot.backend",
        "description": "hypertools.build.lib.hypertools.plot.backend",
        "peekOfCode": "BACKEND_MAPPING = None\nBACKEND_WARNING = None\nHYPERTOOLS_BACKEND = None\nIN_SET_CONTEXT = False\nIPYTHON_INSTANCE = None\nIS_NOTEBOOK = None\nreset_backend = None\nswitch_backend = None\nclass ParrotDict(dict):\n    \"\"\"",
        "detail": "hypertools.build.lib.hypertools.plot.backend",
        "documentation": {}
    },
    {
        "label": "BACKEND_WARNING",
        "kind": 5,
        "importPath": "hypertools.build.lib.hypertools.plot.backend",
        "description": "hypertools.build.lib.hypertools.plot.backend",
        "peekOfCode": "BACKEND_WARNING = None\nHYPERTOOLS_BACKEND = None\nIN_SET_CONTEXT = False\nIPYTHON_INSTANCE = None\nIS_NOTEBOOK = None\nreset_backend = None\nswitch_backend = None\nclass ParrotDict(dict):\n    \"\"\"\n    Dictionary subclass with a few changes in behavior:",
        "detail": "hypertools.build.lib.hypertools.plot.backend",
        "documentation": {}
    },
    {
        "label": "HYPERTOOLS_BACKEND",
        "kind": 5,
        "importPath": "hypertools.build.lib.hypertools.plot.backend",
        "description": "hypertools.build.lib.hypertools.plot.backend",
        "peekOfCode": "HYPERTOOLS_BACKEND = None\nIN_SET_CONTEXT = False\nIPYTHON_INSTANCE = None\nIS_NOTEBOOK = None\nreset_backend = None\nswitch_backend = None\nclass ParrotDict(dict):\n    \"\"\"\n    Dictionary subclass with a few changes in behavior:\n      1. all keys and values are stored and indexed as",
        "detail": "hypertools.build.lib.hypertools.plot.backend",
        "documentation": {}
    },
    {
        "label": "IN_SET_CONTEXT",
        "kind": 5,
        "importPath": "hypertools.build.lib.hypertools.plot.backend",
        "description": "hypertools.build.lib.hypertools.plot.backend",
        "peekOfCode": "IN_SET_CONTEXT = False\nIPYTHON_INSTANCE = None\nIS_NOTEBOOK = None\nreset_backend = None\nswitch_backend = None\nclass ParrotDict(dict):\n    \"\"\"\n    Dictionary subclass with a few changes in behavior:\n      1. all keys and values are stored and indexed as\n         `HypertoolsBackend` instances",
        "detail": "hypertools.build.lib.hypertools.plot.backend",
        "documentation": {}
    },
    {
        "label": "IPYTHON_INSTANCE",
        "kind": 5,
        "importPath": "hypertools.build.lib.hypertools.plot.backend",
        "description": "hypertools.build.lib.hypertools.plot.backend",
        "peekOfCode": "IPYTHON_INSTANCE = None\nIS_NOTEBOOK = None\nreset_backend = None\nswitch_backend = None\nclass ParrotDict(dict):\n    \"\"\"\n    Dictionary subclass with a few changes in behavior:\n      1. all keys and values are stored and indexed as\n         `HypertoolsBackend` instances\n      2. indexing a `ParrotDict` with a key that doesn't exist returns",
        "detail": "hypertools.build.lib.hypertools.plot.backend",
        "documentation": {}
    },
    {
        "label": "IS_NOTEBOOK",
        "kind": 5,
        "importPath": "hypertools.build.lib.hypertools.plot.backend",
        "description": "hypertools.build.lib.hypertools.plot.backend",
        "peekOfCode": "IS_NOTEBOOK = None\nreset_backend = None\nswitch_backend = None\nclass ParrotDict(dict):\n    \"\"\"\n    Dictionary subclass with a few changes in behavior:\n      1. all keys and values are stored and indexed as\n         `HypertoolsBackend` instances\n      2. indexing a `ParrotDict` with a key that doesn't exist returns\n         the key (it's \"parroted\" back to you). The key is converted to",
        "detail": "hypertools.build.lib.hypertools.plot.backend",
        "documentation": {}
    },
    {
        "label": "reset_backend",
        "kind": 5,
        "importPath": "hypertools.build.lib.hypertools.plot.backend",
        "description": "hypertools.build.lib.hypertools.plot.backend",
        "peekOfCode": "reset_backend = None\nswitch_backend = None\nclass ParrotDict(dict):\n    \"\"\"\n    Dictionary subclass with a few changes in behavior:\n      1. all keys and values are stored and indexed as\n         `HypertoolsBackend` instances\n      2. indexing a `ParrotDict` with a key that doesn't exist returns\n         the key (it's \"parroted\" back to you). The key is converted to\n         a `HypertoolsBackend` instance if it is not already. Similar",
        "detail": "hypertools.build.lib.hypertools.plot.backend",
        "documentation": {}
    },
    {
        "label": "switch_backend",
        "kind": 5,
        "importPath": "hypertools.build.lib.hypertools.plot.backend",
        "description": "hypertools.build.lib.hypertools.plot.backend",
        "peekOfCode": "switch_backend = None\nclass ParrotDict(dict):\n    \"\"\"\n    Dictionary subclass with a few changes in behavior:\n      1. all keys and values are stored and indexed as\n         `HypertoolsBackend` instances\n      2. indexing a `ParrotDict` with a key that doesn't exist returns\n         the key (it's \"parroted\" back to you). The key is converted to\n         a `HypertoolsBackend` instance if it is not already. Similar\n         to `collections.defaultdict`, but does *not* add missing keys",
        "detail": "hypertools.build.lib.hypertools.plot.backend",
        "documentation": {}
    },
    {
        "label": "matplotlib.rcParams[\"pdf.fonttype\"]",
        "kind": 5,
        "importPath": "hypertools.build.lib.hypertools.plot.draw",
        "description": "hypertools.build.lib.hypertools.plot.draw",
        "peekOfCode": "matplotlib.rcParams[\"pdf.fonttype\"] = 42\ndef _draw(\n    x,\n    legend=None,\n    title=None,\n    labels=False,\n    show=True,\n    kwargs_list=None,\n    fmt=None,\n    animate=False,",
        "detail": "hypertools.build.lib.hypertools.plot.draw",
        "documentation": {}
    },
    {
        "label": "plot",
        "kind": 2,
        "importPath": "hypertools.build.lib.hypertools.plot.plot",
        "description": "hypertools.build.lib.hypertools.plot.plot",
        "peekOfCode": "def plot(\n    x,\n    fmt=\"-\",\n    marker=None,\n    markers=None,\n    linestyle=None,\n    linestyles=None,\n    color=None,\n    colors=None,\n    palette=\"hls\",",
        "detail": "hypertools.build.lib.hypertools.plot.plot",
        "documentation": {}
    },
    {
        "label": "align",
        "kind": 2,
        "importPath": "hypertools.build.lib.hypertools.tools.align",
        "description": "hypertools.build.lib.hypertools.tools.align",
        "peekOfCode": "def align(data, align='hyper', normalize=None, ndims=None, method=None,\n          format_data=True):\n    \"\"\"\n    Aligns a list of arrays\n    This function takes a list of high dimensional arrays and 'hyperaligns' them\n    to a 'common' space, or coordinate system following the approach outlined by\n    Haxby et al, 2011. Hyperalignment uses linear transformations (rotation,\n    reflection, translation, scaling) to register a group of arrays to a common\n    space. This can be useful when two or more datasets describe an identical\n    or similar system, but may not be in same coordinate system. For example,",
        "detail": "hypertools.build.lib.hypertools.tools.align",
        "documentation": {}
    },
    {
        "label": "analyze",
        "kind": 2,
        "importPath": "hypertools.build.lib.hypertools.tools.analyze",
        "description": "hypertools.build.lib.hypertools.tools.analyze",
        "peekOfCode": "def analyze(data, normalize=None, reduce=None, ndims=None, align=None, internal=False):\n    \"\"\"\n    Wrapper function for normalize -> reduce -> align transformations.\n    Parameters\n    ----------\n    data : numpy array, pandas df, or list of arrays/dfs\n        The data to analyze\n    normalize : str or False or None\n        If set to 'across', the columns of the input data will be z-scored\n        across lists (default). That is, the z-scores will be computed with",
        "detail": "hypertools.build.lib.hypertools.tools.analyze",
        "documentation": {}
    },
    {
        "label": "cluster",
        "kind": 2,
        "importPath": "hypertools.build.lib.hypertools.tools.cluster",
        "description": "hypertools.build.lib.hypertools.tools.cluster",
        "peekOfCode": "def cluster(x, cluster='KMeans', n_clusters=3, ndims=None, format_data=True):\n    \"\"\"\n    Performs clustering analysis and returns a list of cluster labels\n    Parameters\n    ----------\n    x : A Numpy array, Pandas Dataframe or list of arrays/dfs\n        The data to be clustered.  You can pass a single array/df or a list.\n        If a list is passed, the arrays will be stacked and the clustering\n        will be performed across all lists (i.e. not within each list).\n    cluster : str or dict",
        "detail": "hypertools.build.lib.hypertools.tools.cluster",
        "documentation": {}
    },
    {
        "label": "models",
        "kind": 5,
        "importPath": "hypertools.build.lib.hypertools.tools.cluster",
        "description": "hypertools.build.lib.hypertools.tools.cluster",
        "peekOfCode": "models = {\n    'KMeans': KMeans,\n    'MiniBatchKMeans': MiniBatchKMeans,\n    'AgglomerativeClustering': AgglomerativeClustering,\n    'FeatureAgglomeration': FeatureAgglomeration,\n    'Birch': Birch,\n    'SpectralClustering': SpectralClustering,\n}\ntry:\n    from hdbscan import HDBSCAN",
        "detail": "hypertools.build.lib.hypertools.tools.cluster",
        "documentation": {}
    },
    {
        "label": "describe",
        "kind": 2,
        "importPath": "hypertools.build.lib.hypertools.tools.describe",
        "description": "hypertools.build.lib.hypertools.tools.describe",
        "peekOfCode": "def describe(x, reduce='IncrementalPCA', max_dims=None, show=True,\n             format_data=True):\n    \"\"\"\n    Create plot describing covariance with as a function of number of dimensions\n    This function correlates the raw data with reduced data to get a sense\n    for how well the data can be summarized with n dimensions.  Useful for\n    evaluating quality of dimensionality reduced plots.\n    Parameters\n    ----------\n    x : Numpy array, DataFrame or list of arrays/dfs",
        "detail": "hypertools.build.lib.hypertools.tools.describe",
        "documentation": {}
    },
    {
        "label": "get_corr",
        "kind": 2,
        "importPath": "hypertools.build.lib.hypertools.tools.describe",
        "description": "hypertools.build.lib.hypertools.tools.describe",
        "peekOfCode": "def get_corr(reduced, alldims):\n    return pearsonr(alldims.ravel(), reduced.ravel())[0]\n@memoize\ndef get_cdist(x):\n    return cdist(x, x)",
        "detail": "hypertools.build.lib.hypertools.tools.describe",
        "documentation": {}
    },
    {
        "label": "get_cdist",
        "kind": 2,
        "importPath": "hypertools.build.lib.hypertools.tools.describe",
        "description": "hypertools.build.lib.hypertools.tools.describe",
        "peekOfCode": "def get_cdist(x):\n    return cdist(x, x)",
        "detail": "hypertools.build.lib.hypertools.tools.describe",
        "documentation": {}
    },
    {
        "label": "df2mat",
        "kind": 2,
        "importPath": "hypertools.build.lib.hypertools.tools.df2mat",
        "description": "hypertools.build.lib.hypertools.tools.df2mat",
        "peekOfCode": "def df2mat(data, return_labels=False):\n    \"\"\"\n    Transforms a Pandas DataFrame into a Numpy array with binarized text columns\n    This function transforms single-level df to an array so it can be plotted\n    with HyperTools.  Additionally, it uses the Pandas.Dataframe.get_dummies\n    function to transform text columns into binary vectors, or\n    'dummy variables'.\n    Parameters\n    ----------\n    data : A single-level Pandas DataFrame",
        "detail": "hypertools.build.lib.hypertools.tools.df2mat",
        "documentation": {}
    },
    {
        "label": "format_data",
        "kind": 2,
        "importPath": "hypertools.build.lib.hypertools.tools.format_data",
        "description": "hypertools.build.lib.hypertools.tools.format_data",
        "peekOfCode": "def format_data(x, vectorizer='CountVectorizer',\n                semantic='LatentDirichletAllocation', corpus='wiki', ppca=True, text_align='hyper'):\n    \"\"\"\n    Formats data into a list of numpy arrays\n    This function is useful to identify rows of your array that contain missing\n    data or nans.  The returned indices can be used to remove the rows with\n    missing data, or label the missing data points that are interpolated\n    using PPCA.\n    Parameters\n    ----------",
        "detail": "hypertools.build.lib.hypertools.tools.format_data",
        "documentation": {}
    },
    {
        "label": "fill_missing",
        "kind": 2,
        "importPath": "hypertools.build.lib.hypertools.tools.format_data",
        "description": "hypertools.build.lib.hypertools.tools.format_data",
        "peekOfCode": "def fill_missing(x):\n    \"\"\"Fill missing values using PPCA\"\"\"\n    # ppca if missing data\n    m = PPCA()\n    x_stacked = np.vstack(x)\n    m.fit(data=x_stacked)\n    x_pca = m.transform()\n    # if the whole row is missing, return nans\n    all_missing = [idx for idx, a in enumerate(x_stacked) if np.all(np.isnan(a))]\n    if len(all_missing)>0:",
        "detail": "hypertools.build.lib.hypertools.tools.format_data",
        "documentation": {}
    },
    {
        "label": "load",
        "kind": 2,
        "importPath": "hypertools.build.lib.hypertools.tools.load",
        "description": "hypertools.build.lib.hypertools.tools.load",
        "peekOfCode": "def load(\n        dataset,\n        reduce=None,\n        ndims=None,\n        align=None,\n        normalize=None,\n        *,\n        legacy=False\n):\n    \"\"\"",
        "detail": "hypertools.build.lib.hypertools.tools.load",
        "documentation": {}
    },
    {
        "label": "BASE_URL",
        "kind": 5,
        "importPath": "hypertools.build.lib.hypertools.tools.load",
        "description": "hypertools.build.lib.hypertools.tools.load",
        "peekOfCode": "BASE_URL = 'https://docs.google.com/uc?export=download'\nDATA_DIR = Path.home().joinpath('hypertools_data')\nEXAMPLE_DATA = {\n    'weights': '1ZXLao5Rxkr45KUMkv08Y1eAedTkpivsd',\n    'weights_avg': '1gfI1WB7QqogdYgdclqznhUfxsrhobueO',\n    'weights_sample': '1ub-xlYW1D_ASzbLcALcPJuhHUxRwHdIs',\n    'spiral': '1nHAusn2VsQinJk35xvJSd7CtWPC1uOwK',\n    'mushrooms': '12hmCIZp1tyUoPRHwpiAsm1GDBxiJS8ji',\n    'wiki': '1NUqm3svfu2rrFH04xmLbOh0u5WyTe9mh',\n    'sotus': '1J0MBhpRwdT2WChfWJ4HXYq6jU4XpyJPm',",
        "detail": "hypertools.build.lib.hypertools.tools.load",
        "documentation": {}
    },
    {
        "label": "DATA_DIR",
        "kind": 5,
        "importPath": "hypertools.build.lib.hypertools.tools.load",
        "description": "hypertools.build.lib.hypertools.tools.load",
        "peekOfCode": "DATA_DIR = Path.home().joinpath('hypertools_data')\nEXAMPLE_DATA = {\n    'weights': '1ZXLao5Rxkr45KUMkv08Y1eAedTkpivsd',\n    'weights_avg': '1gfI1WB7QqogdYgdclqznhUfxsrhobueO',\n    'weights_sample': '1ub-xlYW1D_ASzbLcALcPJuhHUxRwHdIs',\n    'spiral': '1nHAusn2VsQinJk35xvJSd7CtWPC1uOwK',\n    'mushrooms': '12hmCIZp1tyUoPRHwpiAsm1GDBxiJS8ji',\n    'wiki': '1NUqm3svfu2rrFH04xmLbOh0u5WyTe9mh',\n    'sotus': '1J0MBhpRwdT2WChfWJ4HXYq6jU4XpyJPm',\n    'nips': '1FV7xT2hVgZ1sXfMvAdP1jRsK_dWhp49I',",
        "detail": "hypertools.build.lib.hypertools.tools.load",
        "documentation": {}
    },
    {
        "label": "EXAMPLE_DATA",
        "kind": 5,
        "importPath": "hypertools.build.lib.hypertools.tools.load",
        "description": "hypertools.build.lib.hypertools.tools.load",
        "peekOfCode": "EXAMPLE_DATA = {\n    'weights': '1ZXLao5Rxkr45KUMkv08Y1eAedTkpivsd',\n    'weights_avg': '1gfI1WB7QqogdYgdclqznhUfxsrhobueO',\n    'weights_sample': '1ub-xlYW1D_ASzbLcALcPJuhHUxRwHdIs',\n    'spiral': '1nHAusn2VsQinJk35xvJSd7CtWPC1uOwK',\n    'mushrooms': '12hmCIZp1tyUoPRHwpiAsm1GDBxiJS8ji',\n    'wiki': '1NUqm3svfu2rrFH04xmLbOh0u5WyTe9mh',\n    'sotus': '1J0MBhpRwdT2WChfWJ4HXYq6jU4XpyJPm',\n    'nips': '1FV7xT2hVgZ1sXfMvAdP1jRsK_dWhp49I',\n    'wiki_model': '1T-UAU-6KVGUBcUWqz7yG59vXnThu9T0H',",
        "detail": "hypertools.build.lib.hypertools.tools.load",
        "documentation": {}
    },
    {
        "label": "missing_inds",
        "kind": 2,
        "importPath": "hypertools.build.lib.hypertools.tools.missing_inds",
        "description": "hypertools.build.lib.hypertools.tools.missing_inds",
        "peekOfCode": "def missing_inds(x, format_data=True):\n    \"\"\"\n    Returns indices of missing data\n    This function is useful to identify rows of your array that contain missing\n    data or nans.  The returned indices can be used to remove the rows with\n    missing data, or label the missing data points that are interpolated\n    using PPCA.\n    Parameters\n    ----------\n    x : array or list of arrays",
        "detail": "hypertools.build.lib.hypertools.tools.missing_inds",
        "documentation": {}
    },
    {
        "label": "normalize",
        "kind": 2,
        "importPath": "hypertools.build.lib.hypertools.tools.normalize",
        "description": "hypertools.build.lib.hypertools.tools.normalize",
        "peekOfCode": "def normalize(x, normalize='across', internal=False, format_data=True):\n    \"\"\"\n    Z-transform the columns or rows of an array, or list of arrays\n    This function normalizes the rows or columns of the input array(s).  This\n    can be useful because data reduction and machine learning techniques are\n    sensitive to scaling differences between features. By default, the function\n    is set to normalize 'across' the columns of all lists, but it can also\n    normalize the columns 'within' each individual list, or alternatively, for\n    each row in the array.\n    Parameters",
        "detail": "hypertools.build.lib.hypertools.tools.normalize",
        "documentation": {}
    },
    {
        "label": "procrustes",
        "kind": 2,
        "importPath": "hypertools.build.lib.hypertools.tools.procrustes",
        "description": "hypertools.build.lib.hypertools.tools.procrustes",
        "peekOfCode": "def procrustes(source, target, scaling=True, reflection=True, reduction=False,\n               oblique=False, oblique_rcond=-1, format_data=True):\n    \"\"\"\n    Function to project from one space to another using Procrustean\n    transformation (shift + scaling + rotation + reflection).\n    The implementation of this function was based on the ProcrusteanMapper in\n    pyMVPA: https://github.com/PyMVPA/PyMVPA\n    See also: http://en.wikipedia.org/wiki/Procrustes_transformation\n    Parameters\n    ----------",
        "detail": "hypertools.build.lib.hypertools.tools.procrustes",
        "documentation": {}
    },
    {
        "label": "reduce",
        "kind": 2,
        "importPath": "hypertools.build.lib.hypertools.tools.reduce",
        "description": "hypertools.build.lib.hypertools.tools.reduce",
        "peekOfCode": "def reduce(x, reduce='IncrementalPCA', ndims=None, normalize=None, align=None,\n           model=None, model_params=None, internal=False, format_data=True):\n    \"\"\"\n    Reduces dimensionality of an array, or list of arrays\n    Parameters\n    ----------\n    x : Numpy array or list of arrays\n        Dimensionality reduction using PCA is performed on this array.\n    reduce : str or dict\n        Decomposition/manifold learning model to use.  Models supported: PCA,",
        "detail": "hypertools.build.lib.hypertools.tools.reduce",
        "documentation": {}
    },
    {
        "label": "reduce_list",
        "kind": 2,
        "importPath": "hypertools.build.lib.hypertools.tools.reduce",
        "description": "hypertools.build.lib.hypertools.tools.reduce",
        "peekOfCode": "def reduce_list(x, model):\n    \"\"\"Helper function to reduce a list of arrays\"\"\"\n    # Ensure all arrays are float64 for consistent handling\n    x = [np.asarray(arr, dtype=np.float64) for arr in x]\n    split = np.cumsum([len(xi) for xi in x])[:-1]\n    stacked = np.vstack(x)\n    # Handle potential NaN values\n    if np.any(np.isnan(stacked)):\n        warnings.warn('NaN values detected in input data. These may affect the reduction results.')\n    x_r = np.vsplit(model.fit_transform(stacked), split)",
        "detail": "hypertools.build.lib.hypertools.tools.reduce",
        "documentation": {}
    },
    {
        "label": "models",
        "kind": 5,
        "importPath": "hypertools.build.lib.hypertools.tools.reduce",
        "description": "hypertools.build.lib.hypertools.tools.reduce",
        "peekOfCode": "models = {\n    'PCA': PCA,\n    'IncrementalPCA': IncrementalPCA,\n    'SparsePCA': SparsePCA,\n    'MiniBatchSparsePCA': MiniBatchSparsePCA,\n    'KernelPCA': KernelPCA,\n    'FastICA': FastICA,\n    'FactorAnalysis': FactorAnalysis,\n    'TruncatedSVD': TruncatedSVD,\n    'DictionaryLearning': DictionaryLearning,",
        "detail": "hypertools.build.lib.hypertools.tools.reduce",
        "documentation": {}
    },
    {
        "label": "text2mat",
        "kind": 2,
        "importPath": "hypertools.build.lib.hypertools.tools.text2mat",
        "description": "hypertools.build.lib.hypertools.tools.text2mat",
        "peekOfCode": "def text2mat(data, vectorizer='CountVectorizer',\n             semantic='LatentDirichletAllocation', corpus='wiki'):\n    \"\"\"\n    Turns a list of text samples into a matrix using a vectorizer and a text model\n    Parameters\n    ----------\n    data : list (or list of lists) of text samples\n        The text data to transform\n    vectorizer : str, dict, class or class instance\n        The vectorizer to use. Built-in options are 'CountVectorizer' or",
        "detail": "hypertools.build.lib.hypertools.tools.text2mat",
        "documentation": {}
    },
    {
        "label": "vectorizer_models",
        "kind": 5,
        "importPath": "hypertools.build.lib.hypertools.tools.text2mat",
        "description": "hypertools.build.lib.hypertools.tools.text2mat",
        "peekOfCode": "vectorizer_models = {\n    'CountVectorizer' : CountVectorizer,\n    'TfidfVectorizer' : TfidfVectorizer\n}\n# text models\ntexts = {\n    'LatentDirichletAllocation' : LatentDirichletAllocation,\n    'NMF' : NMF,\n}\n@memoize",
        "detail": "hypertools.build.lib.hypertools.tools.text2mat",
        "documentation": {}
    },
    {
        "label": "texts",
        "kind": 5,
        "importPath": "hypertools.build.lib.hypertools.tools.text2mat",
        "description": "hypertools.build.lib.hypertools.tools.text2mat",
        "peekOfCode": "texts = {\n    'LatentDirichletAllocation' : LatentDirichletAllocation,\n    'NMF' : NMF,\n}\n@memoize\ndef text2mat(data, vectorizer='CountVectorizer',\n             semantic='LatentDirichletAllocation', corpus='wiki'):\n    \"\"\"\n    Turns a list of text samples into a matrix using a vectorizer and a text model\n    Parameters",
        "detail": "hypertools.build.lib.hypertools.tools.text2mat",
        "documentation": {}
    },
    {
        "label": "__version__",
        "kind": 5,
        "importPath": "hypertools.build.lib.hypertools.config",
        "description": "hypertools.build.lib.hypertools.config",
        "peekOfCode": "__version__ = get_distribution('hypertools').version",
        "detail": "hypertools.build.lib.hypertools.config",
        "documentation": {}
    },
    {
        "label": "DataGeometry",
        "kind": 6,
        "importPath": "hypertools.build.lib.hypertools.datageometry",
        "description": "hypertools.build.lib.hypertools.datageometry",
        "peekOfCode": "class DataGeometry(object):\n    \"\"\"\n    Hypertools data object class\n    A DataGeometry object contains the data, figure handles and transform\n    functions used to create a plot.  Note: this class should not be called\n    directly, but is used by the `hyp.plot` function to create a plot object.\n    Parameters\n    ----------\n    fig : matplotlib.Figure\n        The matplotlib figure handle for the plot",
        "detail": "hypertools.build.lib.hypertools.datageometry",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.analyze",
        "description": "hypertools.docs.auto_examples.analyze",
        "peekOfCode": "geo = hyp.load('weights')\ndata = geo.get_data()\n# process the data\ndata = hyp.analyze(data, normalize='within', reduce='PCA', ndims=10,\n                align='hyper')\n# plot it\nhyp.plot(data)",
        "detail": "hypertools.docs.auto_examples.analyze",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.analyze",
        "description": "hypertools.docs.auto_examples.analyze",
        "peekOfCode": "data = geo.get_data()\n# process the data\ndata = hyp.analyze(data, normalize='within', reduce='PCA', ndims=10,\n                align='hyper')\n# plot it\nhyp.plot(data)",
        "detail": "hypertools.docs.auto_examples.analyze",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.analyze",
        "description": "hypertools.docs.auto_examples.analyze",
        "peekOfCode": "data = hyp.analyze(data, normalize='within', reduce='PCA', ndims=10,\n                align='hyper')\n# plot it\nhyp.plot(data)",
        "detail": "hypertools.docs.auto_examples.analyze",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.animate",
        "description": "hypertools.docs.auto_examples.animate",
        "peekOfCode": "geo = hyp.load('weights_avg')\n# plot\ngeo.plot(animate=True, legend=['first', 'second'])",
        "detail": "hypertools.docs.auto_examples.animate",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.animate_MDS",
        "description": "hypertools.docs.auto_examples.animate_MDS",
        "peekOfCode": "geo = hyp.load('weights_avg')\n# plot\ngeo.plot(animate=True, reduce='MDS')",
        "detail": "hypertools.docs.auto_examples.animate_MDS",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.animate_spin",
        "description": "hypertools.docs.auto_examples.animate_spin",
        "peekOfCode": "geo = hyp.load('weights_sample')\n# plot\ngeo.plot(fmt='.', animate='spin')",
        "detail": "hypertools.docs.auto_examples.animate_spin",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.chemtrails",
        "description": "hypertools.docs.auto_examples.chemtrails",
        "peekOfCode": "geo = hyp.load('weights_avg')\n# plot\ngeo.plot(animate=True, chemtrails=True)",
        "detail": "hypertools.docs.auto_examples.chemtrails",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.explore",
        "description": "hypertools.docs.auto_examples.explore",
        "peekOfCode": "geo = hyp.load('weights_sample')\n# plot\ngeo.plot(fmt='.', explore=True)",
        "detail": "hypertools.docs.auto_examples.explore",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_2D",
        "description": "hypertools.docs.auto_examples.plot_2D",
        "peekOfCode": "geo = hyp.load('weights_sample')\n# plot\ngeo.plot(fmt='.', ndims=2)",
        "detail": "hypertools.docs.auto_examples.plot_2D",
        "documentation": {}
    },
    {
        "label": "K",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_PPCA",
        "description": "hypertools.docs.auto_examples.plot_PPCA",
        "peekOfCode": "K = 10 - toeplitz(np.arange(10))\ndata1 = np.cumsum(np.random.multivariate_normal(np.zeros(10), K, 250), axis=0)\ndata2 = copy(data1)\n# simulate missing data\nmissing = .1\ninds = [(i,j) for i in range(data2.shape[0]) for j in range(data2.shape[1])]\nmissing_data = [inds[i] for i in np.random.choice(int(len(inds)), int(len(inds)*missing))]\nfor i,j in missing_data:\n    data2[i,j]=np.nan\n# plot",
        "detail": "hypertools.docs.auto_examples.plot_PPCA",
        "documentation": {}
    },
    {
        "label": "data1",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_PPCA",
        "description": "hypertools.docs.auto_examples.plot_PPCA",
        "peekOfCode": "data1 = np.cumsum(np.random.multivariate_normal(np.zeros(10), K, 250), axis=0)\ndata2 = copy(data1)\n# simulate missing data\nmissing = .1\ninds = [(i,j) for i in range(data2.shape[0]) for j in range(data2.shape[1])]\nmissing_data = [inds[i] for i in np.random.choice(int(len(inds)), int(len(inds)*missing))]\nfor i,j in missing_data:\n    data2[i,j]=np.nan\n# plot\nhyp.plot([data1, data2], linestyle=['-',':'], legend=['Original', 'PPCA'])",
        "detail": "hypertools.docs.auto_examples.plot_PPCA",
        "documentation": {}
    },
    {
        "label": "data2",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_PPCA",
        "description": "hypertools.docs.auto_examples.plot_PPCA",
        "peekOfCode": "data2 = copy(data1)\n# simulate missing data\nmissing = .1\ninds = [(i,j) for i in range(data2.shape[0]) for j in range(data2.shape[1])]\nmissing_data = [inds[i] for i in np.random.choice(int(len(inds)), int(len(inds)*missing))]\nfor i,j in missing_data:\n    data2[i,j]=np.nan\n# plot\nhyp.plot([data1, data2], linestyle=['-',':'], legend=['Original', 'PPCA'])",
        "detail": "hypertools.docs.auto_examples.plot_PPCA",
        "documentation": {}
    },
    {
        "label": "missing",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_PPCA",
        "description": "hypertools.docs.auto_examples.plot_PPCA",
        "peekOfCode": "missing = .1\ninds = [(i,j) for i in range(data2.shape[0]) for j in range(data2.shape[1])]\nmissing_data = [inds[i] for i in np.random.choice(int(len(inds)), int(len(inds)*missing))]\nfor i,j in missing_data:\n    data2[i,j]=np.nan\n# plot\nhyp.plot([data1, data2], linestyle=['-',':'], legend=['Original', 'PPCA'])",
        "detail": "hypertools.docs.auto_examples.plot_PPCA",
        "documentation": {}
    },
    {
        "label": "inds",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_PPCA",
        "description": "hypertools.docs.auto_examples.plot_PPCA",
        "peekOfCode": "inds = [(i,j) for i in range(data2.shape[0]) for j in range(data2.shape[1])]\nmissing_data = [inds[i] for i in np.random.choice(int(len(inds)), int(len(inds)*missing))]\nfor i,j in missing_data:\n    data2[i,j]=np.nan\n# plot\nhyp.plot([data1, data2], linestyle=['-',':'], legend=['Original', 'PPCA'])",
        "detail": "hypertools.docs.auto_examples.plot_PPCA",
        "documentation": {}
    },
    {
        "label": "missing_data",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_PPCA",
        "description": "hypertools.docs.auto_examples.plot_PPCA",
        "peekOfCode": "missing_data = [inds[i] for i in np.random.choice(int(len(inds)), int(len(inds)*missing))]\nfor i,j in missing_data:\n    data2[i,j]=np.nan\n# plot\nhyp.plot([data1, data2], linestyle=['-',':'], legend=['Original', 'PPCA'])",
        "detail": "hypertools.docs.auto_examples.plot_PPCA",
        "documentation": {}
    },
    {
        "label": "digits",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_TSNE",
        "description": "hypertools.docs.auto_examples.plot_TSNE",
        "peekOfCode": "digits = datasets.load_digits(n_class=6)\ndata = digits.data\nhue = digits.target.astype('str')\nhyp.plot(data, '.', reduce='TSNE', hue=hue, ndims=2)",
        "detail": "hypertools.docs.auto_examples.plot_TSNE",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_TSNE",
        "description": "hypertools.docs.auto_examples.plot_TSNE",
        "peekOfCode": "data = digits.data\nhue = digits.target.astype('str')\nhyp.plot(data, '.', reduce='TSNE', hue=hue, ndims=2)",
        "detail": "hypertools.docs.auto_examples.plot_TSNE",
        "documentation": {}
    },
    {
        "label": "hue",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_TSNE",
        "description": "hypertools.docs.auto_examples.plot_TSNE",
        "peekOfCode": "hue = digits.target.astype('str')\nhyp.plot(data, '.', reduce='TSNE', hue=hue, ndims=2)",
        "detail": "hypertools.docs.auto_examples.plot_TSNE",
        "documentation": {}
    },
    {
        "label": "digits",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_UMAP",
        "description": "hypertools.docs.auto_examples.plot_UMAP",
        "peekOfCode": "digits = datasets.load_digits(n_class=6)\ndata = digits.data\nhue = digits.target.astype('str')\nhyp.plot(data, '.', reduce='UMAP', hue=hue, ndims=2)",
        "detail": "hypertools.docs.auto_examples.plot_UMAP",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_UMAP",
        "description": "hypertools.docs.auto_examples.plot_UMAP",
        "peekOfCode": "data = digits.data\nhue = digits.target.astype('str')\nhyp.plot(data, '.', reduce='UMAP', hue=hue, ndims=2)",
        "detail": "hypertools.docs.auto_examples.plot_UMAP",
        "documentation": {}
    },
    {
        "label": "hue",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_UMAP",
        "description": "hypertools.docs.auto_examples.plot_UMAP",
        "peekOfCode": "hue = digits.target.astype('str')\nhyp.plot(data, '.', reduce='UMAP', hue=hue, ndims=2)",
        "detail": "hypertools.docs.auto_examples.plot_UMAP",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_align",
        "description": "hypertools.docs.auto_examples.plot_align",
        "peekOfCode": "data = hyp.load('weights').get_data()\ndata = hyp.align(data, align='hyper')\n# average into two groups\ngroup1 = np.mean(data[:17], 0)\ngroup2 = np.mean(data[18:], 0)\n# plot\nhyp.plot([group1[:100, :], group2[:100, :]])",
        "detail": "hypertools.docs.auto_examples.plot_align",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_align",
        "description": "hypertools.docs.auto_examples.plot_align",
        "peekOfCode": "data = hyp.align(data, align='hyper')\n# average into two groups\ngroup1 = np.mean(data[:17], 0)\ngroup2 = np.mean(data[18:], 0)\n# plot\nhyp.plot([group1[:100, :], group2[:100, :]])",
        "detail": "hypertools.docs.auto_examples.plot_align",
        "documentation": {}
    },
    {
        "label": "group1",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_align",
        "description": "hypertools.docs.auto_examples.plot_align",
        "peekOfCode": "group1 = np.mean(data[:17], 0)\ngroup2 = np.mean(data[18:], 0)\n# plot\nhyp.plot([group1[:100, :], group2[:100, :]])",
        "detail": "hypertools.docs.auto_examples.plot_align",
        "documentation": {}
    },
    {
        "label": "group2",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_align",
        "description": "hypertools.docs.auto_examples.plot_align",
        "peekOfCode": "group2 = np.mean(data[18:], 0)\n# plot\nhyp.plot([group1[:100, :], group2[:100, :]])",
        "detail": "hypertools.docs.auto_examples.plot_align",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_basic",
        "description": "hypertools.docs.auto_examples.plot_basic",
        "peekOfCode": "geo = hyp.load('weights_sample')\n# plot\ngeo.plot(fmt='.')",
        "detail": "hypertools.docs.auto_examples.plot_basic",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_clusters",
        "description": "hypertools.docs.auto_examples.plot_clusters",
        "peekOfCode": "geo = hyp.load('mushrooms')\n# plot\ngeo.plot(n_clusters=10)",
        "detail": "hypertools.docs.auto_examples.plot_clusters",
        "documentation": {}
    },
    {
        "label": "cluster1",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_clusters2",
        "description": "hypertools.docs.auto_examples.plot_clusters2",
        "peekOfCode": "cluster1 = np.random.multivariate_normal(np.zeros(3), np.eye(3), size=100)\ncluster2 = np.random.multivariate_normal(np.zeros(3)+3, np.eye(3), size=100)\ndata = np.vstack([cluster1, cluster2])\n# get cluster labels\ncluster_labels = hyp.cluster(data, n_clusters=2)\n# plot\nhyp.plot(data, '.', hue=cluster_labels)",
        "detail": "hypertools.docs.auto_examples.plot_clusters2",
        "documentation": {}
    },
    {
        "label": "cluster2",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_clusters2",
        "description": "hypertools.docs.auto_examples.plot_clusters2",
        "peekOfCode": "cluster2 = np.random.multivariate_normal(np.zeros(3)+3, np.eye(3), size=100)\ndata = np.vstack([cluster1, cluster2])\n# get cluster labels\ncluster_labels = hyp.cluster(data, n_clusters=2)\n# plot\nhyp.plot(data, '.', hue=cluster_labels)",
        "detail": "hypertools.docs.auto_examples.plot_clusters2",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_clusters2",
        "description": "hypertools.docs.auto_examples.plot_clusters2",
        "peekOfCode": "data = np.vstack([cluster1, cluster2])\n# get cluster labels\ncluster_labels = hyp.cluster(data, n_clusters=2)\n# plot\nhyp.plot(data, '.', hue=cluster_labels)",
        "detail": "hypertools.docs.auto_examples.plot_clusters2",
        "documentation": {}
    },
    {
        "label": "cluster_labels",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_clusters2",
        "description": "hypertools.docs.auto_examples.plot_clusters2",
        "peekOfCode": "cluster_labels = hyp.cluster(data, n_clusters=2)\n# plot\nhyp.plot(data, '.', hue=cluster_labels)",
        "detail": "hypertools.docs.auto_examples.plot_clusters2",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_clusters3",
        "description": "hypertools.docs.auto_examples.plot_clusters3",
        "peekOfCode": "geo = hyp.load('mushrooms')\n# plot\ngeo.plot(cluster={'model':'HDBSCAN',\n                             'params': {'min_samples':5,\n                                        'min_cluster_size':30}})",
        "detail": "hypertools.docs.auto_examples.plot_clusters3",
        "documentation": {}
    },
    {
        "label": "text_samples",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_corpus",
        "description": "hypertools.docs.auto_examples.plot_corpus",
        "peekOfCode": "text_samples = ['i like cats alot', 'cats r pretty cool', 'cats are better than dogs',\n        'dogs rule the haus', 'dogs are my jam', 'dogs are a mans best friend',\n        'i haz a cheezeburger?']\n# plot it\nhyp.plot(text_samples, 'o', corpus=text_samples)",
        "detail": "hypertools.docs.auto_examples.plot_corpus",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_dataframe",
        "description": "hypertools.docs.auto_examples.plot_dataframe",
        "peekOfCode": "geo = hyp.load('mushrooms')\nprint(geo.get_data().head())\n# plot\ngeo.plot()",
        "detail": "hypertools.docs.auto_examples.plot_dataframe",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_describe",
        "description": "hypertools.docs.auto_examples.plot_describe",
        "peekOfCode": "geo = hyp.load('weights_sample')\ndata = geo.get_data()\n# plot\nhyp.describe(data)",
        "detail": "hypertools.docs.auto_examples.plot_describe",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_describe",
        "description": "hypertools.docs.auto_examples.plot_describe",
        "peekOfCode": "data = geo.get_data()\n# plot\nhyp.describe(data)",
        "detail": "hypertools.docs.auto_examples.plot_describe",
        "documentation": {}
    },
    {
        "label": "digits",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_digits",
        "description": "hypertools.docs.auto_examples.plot_digits",
        "peekOfCode": "digits = datasets.load_digits(n_class=6)\ndata = digits.data\nhue = digits.target\n# plot\nhyp.plot(data, '.', hue=hue)",
        "detail": "hypertools.docs.auto_examples.plot_digits",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_digits",
        "description": "hypertools.docs.auto_examples.plot_digits",
        "peekOfCode": "data = digits.data\nhue = digits.target\n# plot\nhyp.plot(data, '.', hue=hue)",
        "detail": "hypertools.docs.auto_examples.plot_digits",
        "documentation": {}
    },
    {
        "label": "hue",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_digits",
        "description": "hypertools.docs.auto_examples.plot_digits",
        "peekOfCode": "hue = digits.target\n# plot\nhyp.plot(data, '.', hue=hue)",
        "detail": "hypertools.docs.auto_examples.plot_digits",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_geo",
        "description": "hypertools.docs.auto_examples.plot_geo",
        "peekOfCode": "geo = hyp.load('mushrooms')\n# plot\nt = geo.plot()\n# replot with new parameters\ngeo.plot(normalize='within', color='green')\n# save the object\n# geo.save('test')\n# load it back in\n# geo = hyp.load('test.geo')\n# transform some new data",
        "detail": "hypertools.docs.auto_examples.plot_geo",
        "documentation": {}
    },
    {
        "label": "t",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_geo",
        "description": "hypertools.docs.auto_examples.plot_geo",
        "peekOfCode": "t = geo.plot()\n# replot with new parameters\ngeo.plot(normalize='within', color='green')\n# save the object\n# geo.save('test')\n# load it back in\n# geo = hyp.load('test.geo')\n# transform some new data\n# transformed_data = geo.transform(data)\n# transform some 'new' data and plot it",
        "detail": "hypertools.docs.auto_examples.plot_geo",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_hue",
        "description": "hypertools.docs.auto_examples.plot_hue",
        "peekOfCode": "geo = hyp.load('weights_sample')\ndata = geo.get_data()\n# simulate random groups\nhue=[]\nfor idx,i in enumerate(data):\n    tmp=[]\n    for iidx,ii in enumerate(i):\n            tmp.append(int(np.random.randint(1000, size=1)))\n    hue.append(tmp)\n# plot",
        "detail": "hypertools.docs.auto_examples.plot_hue",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_hue",
        "description": "hypertools.docs.auto_examples.plot_hue",
        "peekOfCode": "data = geo.get_data()\n# simulate random groups\nhue=[]\nfor idx,i in enumerate(data):\n    tmp=[]\n    for iidx,ii in enumerate(i):\n            tmp.append(int(np.random.randint(1000, size=1)))\n    hue.append(tmp)\n# plot\ngeo.plot(fmt='.', hue=hue)",
        "detail": "hypertools.docs.auto_examples.plot_hue",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_labels",
        "description": "hypertools.docs.auto_examples.plot_labels",
        "peekOfCode": "geo = hyp.load('weights_sample')\ndata = geo.get_data()\n# simulate labels\nlabels=[]\nfor idx,i in enumerate(data):\n    tmp=[]\n    for iidx,ii in enumerate(i):\n        if iidx==0:\n            tmp.append('Subject ' + str(idx))\n        else:",
        "detail": "hypertools.docs.auto_examples.plot_labels",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_labels",
        "description": "hypertools.docs.auto_examples.plot_labels",
        "peekOfCode": "data = geo.get_data()\n# simulate labels\nlabels=[]\nfor idx,i in enumerate(data):\n    tmp=[]\n    for iidx,ii in enumerate(i):\n        if iidx==0:\n            tmp.append('Subject ' + str(idx))\n        else:\n            tmp.append(None)",
        "detail": "hypertools.docs.auto_examples.plot_labels",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_legend",
        "description": "hypertools.docs.auto_examples.plot_legend",
        "peekOfCode": "geo = hyp.load('weights_sample')\n# plot\ngeo.plot(fmt='.', legend=['Group A', 'Group B', 'Group C'])",
        "detail": "hypertools.docs.auto_examples.plot_legend",
        "documentation": {}
    },
    {
        "label": "K",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_missing_data",
        "description": "hypertools.docs.auto_examples.plot_missing_data",
        "peekOfCode": "K = 10 - toeplitz(np.arange(10))\ndata1 = np.cumsum(np.random.multivariate_normal(np.zeros(10), K, 250), axis=0)\ndata2 = copy(data1)\n# randomly remove 5% of the data\nmissing = .01\ninds = [(i,j) for i in range(data1.shape[0]) for j in range(data1.shape[1])]\nmissing_data = [inds[i] for i in np.random.choice(int(len(inds)), int(len(inds)*missing))]\nfor i,j in missing_data:\n    data2[i,j]=np.nan\n# reduce the data",
        "detail": "hypertools.docs.auto_examples.plot_missing_data",
        "documentation": {}
    },
    {
        "label": "data1",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_missing_data",
        "description": "hypertools.docs.auto_examples.plot_missing_data",
        "peekOfCode": "data1 = np.cumsum(np.random.multivariate_normal(np.zeros(10), K, 250), axis=0)\ndata2 = copy(data1)\n# randomly remove 5% of the data\nmissing = .01\ninds = [(i,j) for i in range(data1.shape[0]) for j in range(data1.shape[1])]\nmissing_data = [inds[i] for i in np.random.choice(int(len(inds)), int(len(inds)*missing))]\nfor i,j in missing_data:\n    data2[i,j]=np.nan\n# reduce the data\ndata1_r,data2_r = hyp.reduce([data1, data2], ndims=3)",
        "detail": "hypertools.docs.auto_examples.plot_missing_data",
        "documentation": {}
    },
    {
        "label": "data2",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_missing_data",
        "description": "hypertools.docs.auto_examples.plot_missing_data",
        "peekOfCode": "data2 = copy(data1)\n# randomly remove 5% of the data\nmissing = .01\ninds = [(i,j) for i in range(data1.shape[0]) for j in range(data1.shape[1])]\nmissing_data = [inds[i] for i in np.random.choice(int(len(inds)), int(len(inds)*missing))]\nfor i,j in missing_data:\n    data2[i,j]=np.nan\n# reduce the data\ndata1_r,data2_r = hyp.reduce([data1, data2], ndims=3)\n# pull out missing inds",
        "detail": "hypertools.docs.auto_examples.plot_missing_data",
        "documentation": {}
    },
    {
        "label": "missing",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_missing_data",
        "description": "hypertools.docs.auto_examples.plot_missing_data",
        "peekOfCode": "missing = .01\ninds = [(i,j) for i in range(data1.shape[0]) for j in range(data1.shape[1])]\nmissing_data = [inds[i] for i in np.random.choice(int(len(inds)), int(len(inds)*missing))]\nfor i,j in missing_data:\n    data2[i,j]=np.nan\n# reduce the data\ndata1_r,data2_r = hyp.reduce([data1, data2], ndims=3)\n# pull out missing inds\nmissing_inds = hyp.tools.missing_inds(data2)\nmissing_data = data2_r[missing_inds, :]",
        "detail": "hypertools.docs.auto_examples.plot_missing_data",
        "documentation": {}
    },
    {
        "label": "inds",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_missing_data",
        "description": "hypertools.docs.auto_examples.plot_missing_data",
        "peekOfCode": "inds = [(i,j) for i in range(data1.shape[0]) for j in range(data1.shape[1])]\nmissing_data = [inds[i] for i in np.random.choice(int(len(inds)), int(len(inds)*missing))]\nfor i,j in missing_data:\n    data2[i,j]=np.nan\n# reduce the data\ndata1_r,data2_r = hyp.reduce([data1, data2], ndims=3)\n# pull out missing inds\nmissing_inds = hyp.tools.missing_inds(data2)\nmissing_data = data2_r[missing_inds, :]\n# plot",
        "detail": "hypertools.docs.auto_examples.plot_missing_data",
        "documentation": {}
    },
    {
        "label": "missing_data",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_missing_data",
        "description": "hypertools.docs.auto_examples.plot_missing_data",
        "peekOfCode": "missing_data = [inds[i] for i in np.random.choice(int(len(inds)), int(len(inds)*missing))]\nfor i,j in missing_data:\n    data2[i,j]=np.nan\n# reduce the data\ndata1_r,data2_r = hyp.reduce([data1, data2], ndims=3)\n# pull out missing inds\nmissing_inds = hyp.tools.missing_inds(data2)\nmissing_data = data2_r[missing_inds, :]\n# plot\nhyp.plot([data1_r, data2_r, missing_data], ['-', '--', '*'],",
        "detail": "hypertools.docs.auto_examples.plot_missing_data",
        "documentation": {}
    },
    {
        "label": "data1_r,data2_r",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_missing_data",
        "description": "hypertools.docs.auto_examples.plot_missing_data",
        "peekOfCode": "data1_r,data2_r = hyp.reduce([data1, data2], ndims=3)\n# pull out missing inds\nmissing_inds = hyp.tools.missing_inds(data2)\nmissing_data = data2_r[missing_inds, :]\n# plot\nhyp.plot([data1_r, data2_r, missing_data], ['-', '--', '*'],\n         legend=['Full', 'Missing', 'Missing Points'])",
        "detail": "hypertools.docs.auto_examples.plot_missing_data",
        "documentation": {}
    },
    {
        "label": "missing_inds",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_missing_data",
        "description": "hypertools.docs.auto_examples.plot_missing_data",
        "peekOfCode": "missing_inds = hyp.tools.missing_inds(data2)\nmissing_data = data2_r[missing_inds, :]\n# plot\nhyp.plot([data1_r, data2_r, missing_data], ['-', '--', '*'],\n         legend=['Full', 'Missing', 'Missing Points'])",
        "detail": "hypertools.docs.auto_examples.plot_missing_data",
        "documentation": {}
    },
    {
        "label": "missing_data",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_missing_data",
        "description": "hypertools.docs.auto_examples.plot_missing_data",
        "peekOfCode": "missing_data = data2_r[missing_inds, :]\n# plot\nhyp.plot([data1_r, data2_r, missing_data], ['-', '--', '*'],\n         legend=['Full', 'Missing', 'Missing Points'])",
        "detail": "hypertools.docs.auto_examples.plot_missing_data",
        "documentation": {}
    },
    {
        "label": "cluster1",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_normalize",
        "description": "hypertools.docs.auto_examples.plot_normalize",
        "peekOfCode": "cluster1 = np.random.multivariate_normal(np.zeros(3), np.eye(3), size=100)\ncluster2 = np.random.multivariate_normal(np.zeros(3)+10, np.eye(3), size=100)\ndata = [cluster1, cluster2]\n# plot normalized across lists\nhyp.plot(data, '.', normalize='across', title='Normalized across datasets')\n# plot normalized within list\nhyp.plot(data, '.', normalize='within', title='Normalized within dataset')\n# normalize by row\nnormalized_row = hyp.normalize(data, normalize='row')\n# plot normalized by row",
        "detail": "hypertools.docs.auto_examples.plot_normalize",
        "documentation": {}
    },
    {
        "label": "cluster2",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_normalize",
        "description": "hypertools.docs.auto_examples.plot_normalize",
        "peekOfCode": "cluster2 = np.random.multivariate_normal(np.zeros(3)+10, np.eye(3), size=100)\ndata = [cluster1, cluster2]\n# plot normalized across lists\nhyp.plot(data, '.', normalize='across', title='Normalized across datasets')\n# plot normalized within list\nhyp.plot(data, '.', normalize='within', title='Normalized within dataset')\n# normalize by row\nnormalized_row = hyp.normalize(data, normalize='row')\n# plot normalized by row\nhyp.plot(normalized_row, '.', title='Normalized across row')",
        "detail": "hypertools.docs.auto_examples.plot_normalize",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_normalize",
        "description": "hypertools.docs.auto_examples.plot_normalize",
        "peekOfCode": "data = [cluster1, cluster2]\n# plot normalized across lists\nhyp.plot(data, '.', normalize='across', title='Normalized across datasets')\n# plot normalized within list\nhyp.plot(data, '.', normalize='within', title='Normalized within dataset')\n# normalize by row\nnormalized_row = hyp.normalize(data, normalize='row')\n# plot normalized by row\nhyp.plot(normalized_row, '.', title='Normalized across row')",
        "detail": "hypertools.docs.auto_examples.plot_normalize",
        "documentation": {}
    },
    {
        "label": "normalized_row",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_normalize",
        "description": "hypertools.docs.auto_examples.plot_normalize",
        "peekOfCode": "normalized_row = hyp.normalize(data, normalize='row')\n# plot normalized by row\nhyp.plot(normalized_row, '.', title='Normalized across row')",
        "detail": "hypertools.docs.auto_examples.plot_normalize",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_procrustes",
        "description": "hypertools.docs.auto_examples.plot_procrustes",
        "peekOfCode": "geo = hyp.load('spiral')\ngeo.plot(title='Before Alignment')\n# use procrusted to align the data\nsource, target = geo.get_data()\naligned = [hyp.tools.procrustes(source, target), target]\n# after alignment\nhyp.plot(aligned, ['-','--'], title='After alignment')",
        "detail": "hypertools.docs.auto_examples.plot_procrustes",
        "documentation": {}
    },
    {
        "label": "aligned",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_procrustes",
        "description": "hypertools.docs.auto_examples.plot_procrustes",
        "peekOfCode": "aligned = [hyp.tools.procrustes(source, target), target]\n# after alignment\nhyp.plot(aligned, ['-','--'], title='After alignment')",
        "detail": "hypertools.docs.auto_examples.plot_procrustes",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_sotus",
        "description": "hypertools.docs.auto_examples.plot_sotus",
        "peekOfCode": "geo = hyp.load('sotus')\n# plot it\ngeo.plot()",
        "detail": "hypertools.docs.auto_examples.plot_sotus",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.plot_text",
        "description": "hypertools.docs.auto_examples.plot_text",
        "peekOfCode": "data = [['i like cats alot', 'cats r pretty cool', 'cats are better than dogs'],\n        ['dogs rule the haus', 'dogs are my jam', 'dogs are a mans best friend'],\n        'i haz a cheezeburger?']\n# plot it\nhyp.plot(data, 'o')\n# convert text to matrix without plotting\n# mtx = hyp.tools.format_data(data, vectorizer='TfidfVectorizer', semantic='NMF')",
        "detail": "hypertools.docs.auto_examples.plot_text",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.precog",
        "description": "hypertools.docs.auto_examples.precog",
        "peekOfCode": "geo = hyp.load('weights_avg')\n# plot\ngeo.plot(animate=True, precog=True)",
        "detail": "hypertools.docs.auto_examples.precog",
        "documentation": {}
    },
    {
        "label": "group1",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.save_movie",
        "description": "hypertools.docs.auto_examples.save_movie",
        "peekOfCode": "group1 = np.mean(data[:17], 0)\ngroup2 = np.mean(data[18:], 0)\nhyp.plot([group1, group2], animate=True, save_path='animation.mp4')",
        "detail": "hypertools.docs.auto_examples.save_movie",
        "documentation": {}
    },
    {
        "label": "group2",
        "kind": 5,
        "importPath": "hypertools.docs.auto_examples.save_movie",
        "description": "hypertools.docs.auto_examples.save_movie",
        "peekOfCode": "group2 = np.mean(data[18:], 0)\nhyp.plot([group1, group2], animate=True, save_path='animation.mp4')",
        "detail": "hypertools.docs.auto_examples.save_movie",
        "documentation": {}
    },
    {
        "label": "convert_nb",
        "kind": 2,
        "importPath": "hypertools.docs.tutorials.tools.nb_to_doc",
        "description": "hypertools.docs.tutorials.tools.nb_to_doc",
        "peekOfCode": "def convert_nb(nbname):\n\t# Execute the notebook\n\tsh([\"jupyter\", \"nbconvert\", \"--to\", \"notebook\",\n\t\t\"--execute\", \"--inplace\", \"--ExecutePreprocessor.timeout=60\", nbname + \".ipynb\"])\n\t# Convert to .rst for Sphinx\n\tsh([\"jupyter\", \"nbconvert\", \"--to\", \"rst\", nbname + \".ipynb\"])\n\t# Clear notebook output\n\tsh([\"jupyter\", \"nbconvert\", \"--to\", \"notebook\", \"--inplace\",\n\t\t\"--ClearOutputPreprocessor.enabled=True\", nbname + \".ipynb\"])\nif __name__ == \"__main__\":",
        "detail": "hypertools.docs.tutorials.tools.nb_to_doc",
        "documentation": {}
    },
    {
        "label": "extensions",
        "kind": 5,
        "importPath": "hypertools.docs.conf",
        "description": "hypertools.docs.conf",
        "peekOfCode": "extensions = ['sphinx.ext.autodoc',\n    'numpydoc',\n    'sphinx.ext.autosummary',\n    'sphinx.ext.viewcode',\n    'sphinx_gallery.gen_gallery',\n    'nbsphinx']\n# do not allow nbsphinx errors\nnbsphinx_allow_errors = False\n# Generate the API documentation when building\nautosummary_generate = True",
        "detail": "hypertools.docs.conf",
        "documentation": {}
    },
    {
        "label": "nbsphinx_allow_errors",
        "kind": 5,
        "importPath": "hypertools.docs.conf",
        "description": "hypertools.docs.conf",
        "peekOfCode": "nbsphinx_allow_errors = False\n# Generate the API documentation when building\nautosummary_generate = True\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = ['_templates']\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\n# source_suffix = ['.rst', '.md']\nsource_suffix = '.rst'",
        "detail": "hypertools.docs.conf",
        "documentation": {}
    },
    {
        "label": "autosummary_generate",
        "kind": 5,
        "importPath": "hypertools.docs.conf",
        "description": "hypertools.docs.conf",
        "peekOfCode": "autosummary_generate = True\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = ['_templates']\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\n# source_suffix = ['.rst', '.md']\nsource_suffix = '.rst'\n# The master toctree document.\nmaster_doc = 'index'",
        "detail": "hypertools.docs.conf",
        "documentation": {}
    },
    {
        "label": "templates_path",
        "kind": 5,
        "importPath": "hypertools.docs.conf",
        "description": "hypertools.docs.conf",
        "peekOfCode": "templates_path = ['_templates']\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\n# source_suffix = ['.rst', '.md']\nsource_suffix = '.rst'\n# The master toctree document.\nmaster_doc = 'index'\n# General information about the project.\nproject = u'hypertools'",
        "detail": "hypertools.docs.conf",
        "documentation": {}
    },
    {
        "label": "source_suffix",
        "kind": 5,
        "importPath": "hypertools.docs.conf",
        "description": "hypertools.docs.conf",
        "peekOfCode": "source_suffix = '.rst'\n# The master toctree document.\nmaster_doc = 'index'\n# General information about the project.\nproject = u'hypertools'\ncopyright = u'2017, Contextual Dynamics Laboratory'\nauthor = u'Andrew C. Heusser, Kirsten Ziman, Lucy L. W. Owen, Jeremy R. Manning'\n# The version info for the project you're documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.",
        "detail": "hypertools.docs.conf",
        "documentation": {}
    },
    {
        "label": "master_doc",
        "kind": 5,
        "importPath": "hypertools.docs.conf",
        "description": "hypertools.docs.conf",
        "peekOfCode": "master_doc = 'index'\n# General information about the project.\nproject = u'hypertools'\ncopyright = u'2017, Contextual Dynamics Laboratory'\nauthor = u'Andrew C. Heusser, Kirsten Ziman, Lucy L. W. Owen, Jeremy R. Manning'\n# The version info for the project you're documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The short X.Y version.",
        "detail": "hypertools.docs.conf",
        "documentation": {}
    },
    {
        "label": "project",
        "kind": 5,
        "importPath": "hypertools.docs.conf",
        "description": "hypertools.docs.conf",
        "peekOfCode": "project = u'hypertools'\ncopyright = u'2017, Contextual Dynamics Laboratory'\nauthor = u'Andrew C. Heusser, Kirsten Ziman, Lucy L. W. Owen, Jeremy R. Manning'\n# The version info for the project you're documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The short X.Y version.\nversion = u'0.6'\n# The full version, including alpha/beta/rc tags.",
        "detail": "hypertools.docs.conf",
        "documentation": {}
    },
    {
        "label": "copyright",
        "kind": 5,
        "importPath": "hypertools.docs.conf",
        "description": "hypertools.docs.conf",
        "peekOfCode": "copyright = u'2017, Contextual Dynamics Laboratory'\nauthor = u'Andrew C. Heusser, Kirsten Ziman, Lucy L. W. Owen, Jeremy R. Manning'\n# The version info for the project you're documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The short X.Y version.\nversion = u'0.6'\n# The full version, including alpha/beta/rc tags.\nrelease = u'0.6.2'",
        "detail": "hypertools.docs.conf",
        "documentation": {}
    },
    {
        "label": "author",
        "kind": 5,
        "importPath": "hypertools.docs.conf",
        "description": "hypertools.docs.conf",
        "peekOfCode": "author = u'Andrew C. Heusser, Kirsten Ziman, Lucy L. W. Owen, Jeremy R. Manning'\n# The version info for the project you're documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The short X.Y version.\nversion = u'0.6'\n# The full version, including alpha/beta/rc tags.\nrelease = u'0.6.2'\n# The language for content autogenerated by Sphinx. Refer to documentation",
        "detail": "hypertools.docs.conf",
        "documentation": {}
    },
    {
        "label": "version",
        "kind": 5,
        "importPath": "hypertools.docs.conf",
        "description": "hypertools.docs.conf",
        "peekOfCode": "version = u'0.6'\n# The full version, including alpha/beta/rc tags.\nrelease = u'0.6.2'\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set \"language\" from the command line for these cases.\nlanguage = None\n# List of patterns, relative to source directory, that match files and",
        "detail": "hypertools.docs.conf",
        "documentation": {}
    },
    {
        "label": "release",
        "kind": 5,
        "importPath": "hypertools.docs.conf",
        "description": "hypertools.docs.conf",
        "peekOfCode": "release = u'0.6.2'\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set \"language\" from the command line for these cases.\nlanguage = None\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This patterns also effect to html_static_path and html_extra_path",
        "detail": "hypertools.docs.conf",
        "documentation": {}
    },
    {
        "label": "language",
        "kind": 5,
        "importPath": "hypertools.docs.conf",
        "description": "hypertools.docs.conf",
        "peekOfCode": "language = None\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This patterns also effect to html_static_path and html_extra_path\nexclude_patterns = ['_build', 'Thumbs.db', '.DS_Store']\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = 'sphinx'\n# If true, `todo` and `todoList` produce output, else they produce nothing.\ntodo_include_todos = False\n# # -- Options for HTML output ----------------------------------------------",
        "detail": "hypertools.docs.conf",
        "documentation": {}
    },
    {
        "label": "exclude_patterns",
        "kind": 5,
        "importPath": "hypertools.docs.conf",
        "description": "hypertools.docs.conf",
        "peekOfCode": "exclude_patterns = ['_build', 'Thumbs.db', '.DS_Store']\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = 'sphinx'\n# If true, `todo` and `todoList` produce output, else they produce nothing.\ntodo_include_todos = False\n# # -- Options for HTML output ----------------------------------------------\n#\n# # The theme to use for HTML and HTML Help pages.  See the documentation for\n# # a list of builtin themes.\n# #",
        "detail": "hypertools.docs.conf",
        "documentation": {}
    },
    {
        "label": "pygments_style",
        "kind": 5,
        "importPath": "hypertools.docs.conf",
        "description": "hypertools.docs.conf",
        "peekOfCode": "pygments_style = 'sphinx'\n# If true, `todo` and `todoList` produce output, else they produce nothing.\ntodo_include_todos = False\n# # -- Options for HTML output ----------------------------------------------\n#\n# # The theme to use for HTML and HTML Help pages.  See the documentation for\n# # a list of builtin themes.\n# #\n# html_theme = 'bootstrap'\n#",
        "detail": "hypertools.docs.conf",
        "documentation": {}
    },
    {
        "label": "todo_include_todos",
        "kind": 5,
        "importPath": "hypertools.docs.conf",
        "description": "hypertools.docs.conf",
        "peekOfCode": "todo_include_todos = False\n# # -- Options for HTML output ----------------------------------------------\n#\n# # The theme to use for HTML and HTML Help pages.  See the documentation for\n# # a list of builtin themes.\n# #\n# html_theme = 'bootstrap'\n#\n# # Theme options are theme-specific and customize the look and feel of a theme\n# # further.  For a list of options available for each theme, see the",
        "detail": "hypertools.docs.conf",
        "documentation": {}
    },
    {
        "label": "html_theme",
        "kind": 5,
        "importPath": "hypertools.docs.conf",
        "description": "hypertools.docs.conf",
        "peekOfCode": "html_theme = 'bootstrap'\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\nextlinks = {'github': 'https://github.com/ContextLab/hypertools'}\nhtml_theme_options = {\n    'source_link_position': \"footer\",\n    'bootswatch_theme': \"yeti\",\n    'navbar_sidebarrel': False,\n    'bootstrap_version': \"3\",",
        "detail": "hypertools.docs.conf",
        "documentation": {}
    },
    {
        "label": "extlinks",
        "kind": 5,
        "importPath": "hypertools.docs.conf",
        "description": "hypertools.docs.conf",
        "peekOfCode": "extlinks = {'github': 'https://github.com/ContextLab/hypertools'}\nhtml_theme_options = {\n    'source_link_position': \"footer\",\n    'bootswatch_theme': \"yeti\",\n    'navbar_sidebarrel': False,\n    'bootstrap_version': \"3\",\n    'navbar_links': [(\"API\", \"api\"),\n                     (\"Gallery\", \"auto_examples/index\"),\n                     (\"Tutorials\", \"tutorials\"),\n                     (\"Download\", \"http://www.github.com/ContextLab/hypertools\", True)],",
        "detail": "hypertools.docs.conf",
        "documentation": {}
    },
    {
        "label": "html_theme_options",
        "kind": 5,
        "importPath": "hypertools.docs.conf",
        "description": "hypertools.docs.conf",
        "peekOfCode": "html_theme_options = {\n    'source_link_position': \"footer\",\n    'bootswatch_theme': \"yeti\",\n    'navbar_sidebarrel': False,\n    'bootstrap_version': \"3\",\n    'navbar_links': [(\"API\", \"api\"),\n                     (\"Gallery\", \"auto_examples/index\"),\n                     (\"Tutorials\", \"tutorials\"),\n                     (\"Download\", \"http://www.github.com/ContextLab/hypertools\", True)],\n    }",
        "detail": "hypertools.docs.conf",
        "documentation": {}
    },
    {
        "label": "html_theme_path",
        "kind": 5,
        "importPath": "hypertools.docs.conf",
        "description": "hypertools.docs.conf",
        "peekOfCode": "html_theme_path = sphinx_bootstrap_theme.get_html_theme_path()\n# -- Options for HTMLHelp output ------------------------------------------\n# Output file base name for HTML help builder.\nhtmlhelp_basename = 'hypertoolsdoc'\n# -- Options for LaTeX output ---------------------------------------------\nlatex_elements = {\n    # The paper size ('letterpaper' or 'a4paper').\n    #\n    # 'papersize': 'letterpaper',\n    # The font size ('10pt', '11pt' or '12pt').",
        "detail": "hypertools.docs.conf",
        "documentation": {}
    },
    {
        "label": "htmlhelp_basename",
        "kind": 5,
        "importPath": "hypertools.docs.conf",
        "description": "hypertools.docs.conf",
        "peekOfCode": "htmlhelp_basename = 'hypertoolsdoc'\n# -- Options for LaTeX output ---------------------------------------------\nlatex_elements = {\n    # The paper size ('letterpaper' or 'a4paper').\n    #\n    # 'papersize': 'letterpaper',\n    # The font size ('10pt', '11pt' or '12pt').\n    #\n    # 'pointsize': '10pt',\n    # Additional stuff for the LaTeX preamble.",
        "detail": "hypertools.docs.conf",
        "documentation": {}
    },
    {
        "label": "latex_elements",
        "kind": 5,
        "importPath": "hypertools.docs.conf",
        "description": "hypertools.docs.conf",
        "peekOfCode": "latex_elements = {\n    # The paper size ('letterpaper' or 'a4paper').\n    #\n    # 'papersize': 'letterpaper',\n    # The font size ('10pt', '11pt' or '12pt').\n    #\n    # 'pointsize': '10pt',\n    # Additional stuff for the LaTeX preamble.\n    #\n    # 'preamble': '',",
        "detail": "hypertools.docs.conf",
        "documentation": {}
    },
    {
        "label": "latex_documents",
        "kind": 5,
        "importPath": "hypertools.docs.conf",
        "description": "hypertools.docs.conf",
        "peekOfCode": "latex_documents = [\n    (master_doc, 'hypertools.tex', u'hypertools Documentation',\n     u'Contextual Dynamics Laboratory', 'manual'),\n]\n# -- Options for manual page output ---------------------------------------\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    (master_doc, 'hypertools', u'hypertools Documentation',\n     [author], 1)",
        "detail": "hypertools.docs.conf",
        "documentation": {}
    },
    {
        "label": "man_pages",
        "kind": 5,
        "importPath": "hypertools.docs.conf",
        "description": "hypertools.docs.conf",
        "peekOfCode": "man_pages = [\n    (master_doc, 'hypertools', u'hypertools Documentation',\n     [author], 1)\n]\n# -- Options for Texinfo output -------------------------------------------\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (master_doc, 'hypertools', u'hypertools Documentation',",
        "detail": "hypertools.docs.conf",
        "documentation": {}
    },
    {
        "label": "texinfo_documents",
        "kind": 5,
        "importPath": "hypertools.docs.conf",
        "description": "hypertools.docs.conf",
        "peekOfCode": "texinfo_documents = [\n    (master_doc, 'hypertools', u'hypertools Documentation',\n     author, 'hypertools', 'One line description of project.',\n     'Miscellaneous'),\n]\nsphinx_gallery_conf = {\n    # path to your examples scripts\n    'examples_dirs' : '../examples',\n    # path where to save gallery generated examples\n    'gallery_dirs'  : 'auto_examples'}",
        "detail": "hypertools.docs.conf",
        "documentation": {}
    },
    {
        "label": "sphinx_gallery_conf",
        "kind": 5,
        "importPath": "hypertools.docs.conf",
        "description": "hypertools.docs.conf",
        "peekOfCode": "sphinx_gallery_conf = {\n    # path to your examples scripts\n    'examples_dirs' : '../examples',\n    # path where to save gallery generated examples\n    'gallery_dirs'  : 'auto_examples'}",
        "detail": "hypertools.docs.conf",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.examples.analyze",
        "description": "hypertools.examples.analyze",
        "peekOfCode": "geo = hyp.load('weights')\ndata = geo.get_data()\n# process the data\ndata = hyp.analyze(data, normalize='within', reduce='PCA', ndims=10,\n                align='hyper')\n# plot it\nhyp.plot(data)",
        "detail": "hypertools.examples.analyze",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "hypertools.examples.analyze",
        "description": "hypertools.examples.analyze",
        "peekOfCode": "data = geo.get_data()\n# process the data\ndata = hyp.analyze(data, normalize='within', reduce='PCA', ndims=10,\n                align='hyper')\n# plot it\nhyp.plot(data)",
        "detail": "hypertools.examples.analyze",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "hypertools.examples.analyze",
        "description": "hypertools.examples.analyze",
        "peekOfCode": "data = hyp.analyze(data, normalize='within', reduce='PCA', ndims=10,\n                align='hyper')\n# plot it\nhyp.plot(data)",
        "detail": "hypertools.examples.analyze",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.examples.animate",
        "description": "hypertools.examples.animate",
        "peekOfCode": "geo = hyp.load('weights_avg')\n# plot\ngeo.plot(animate=True, legend=['first', 'second'])",
        "detail": "hypertools.examples.animate",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.examples.animate_MDS",
        "description": "hypertools.examples.animate_MDS",
        "peekOfCode": "geo = hyp.load('weights_avg')\n# plot\ngeo.plot(animate=True, reduce='MDS')",
        "detail": "hypertools.examples.animate_MDS",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.examples.animate_spin",
        "description": "hypertools.examples.animate_spin",
        "peekOfCode": "geo = hyp.load('weights_sample')\n# plot\ngeo.plot(fmt='.', animate='spin')",
        "detail": "hypertools.examples.animate_spin",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.examples.chemtrails",
        "description": "hypertools.examples.chemtrails",
        "peekOfCode": "geo = hyp.load('weights_avg')\n# plot\ngeo.plot(animate=True, chemtrails=True)",
        "detail": "hypertools.examples.chemtrails",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.examples.explore",
        "description": "hypertools.examples.explore",
        "peekOfCode": "geo = hyp.load('weights_sample')\n# plot\ngeo.plot(fmt='.', explore=True)",
        "detail": "hypertools.examples.explore",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.examples.plot_2D",
        "description": "hypertools.examples.plot_2D",
        "peekOfCode": "geo = hyp.load('weights_sample')\n# plot\ngeo.plot(fmt='.', ndims=2)",
        "detail": "hypertools.examples.plot_2D",
        "documentation": {}
    },
    {
        "label": "K",
        "kind": 5,
        "importPath": "hypertools.examples.plot_PPCA",
        "description": "hypertools.examples.plot_PPCA",
        "peekOfCode": "K = 10 - toeplitz(np.arange(10))\ndata1 = np.cumsum(np.random.multivariate_normal(np.zeros(10), K, 250), axis=0)\ndata2 = copy(data1)\n# simulate missing data\nmissing = .1\ninds = [(i,j) for i in range(data2.shape[0]) for j in range(data2.shape[1])]\nmissing_data = [inds[i] for i in np.random.choice(int(len(inds)), int(len(inds)*missing))]\nfor i,j in missing_data:\n    data2[i,j]=np.nan\n# plot",
        "detail": "hypertools.examples.plot_PPCA",
        "documentation": {}
    },
    {
        "label": "data1",
        "kind": 5,
        "importPath": "hypertools.examples.plot_PPCA",
        "description": "hypertools.examples.plot_PPCA",
        "peekOfCode": "data1 = np.cumsum(np.random.multivariate_normal(np.zeros(10), K, 250), axis=0)\ndata2 = copy(data1)\n# simulate missing data\nmissing = .1\ninds = [(i,j) for i in range(data2.shape[0]) for j in range(data2.shape[1])]\nmissing_data = [inds[i] for i in np.random.choice(int(len(inds)), int(len(inds)*missing))]\nfor i,j in missing_data:\n    data2[i,j]=np.nan\n# plot\nhyp.plot([data1, data2], linestyle=['-',':'], legend=['Original', 'PPCA'])",
        "detail": "hypertools.examples.plot_PPCA",
        "documentation": {}
    },
    {
        "label": "data2",
        "kind": 5,
        "importPath": "hypertools.examples.plot_PPCA",
        "description": "hypertools.examples.plot_PPCA",
        "peekOfCode": "data2 = copy(data1)\n# simulate missing data\nmissing = .1\ninds = [(i,j) for i in range(data2.shape[0]) for j in range(data2.shape[1])]\nmissing_data = [inds[i] for i in np.random.choice(int(len(inds)), int(len(inds)*missing))]\nfor i,j in missing_data:\n    data2[i,j]=np.nan\n# plot\nhyp.plot([data1, data2], linestyle=['-',':'], legend=['Original', 'PPCA'])",
        "detail": "hypertools.examples.plot_PPCA",
        "documentation": {}
    },
    {
        "label": "missing",
        "kind": 5,
        "importPath": "hypertools.examples.plot_PPCA",
        "description": "hypertools.examples.plot_PPCA",
        "peekOfCode": "missing = .1\ninds = [(i,j) for i in range(data2.shape[0]) for j in range(data2.shape[1])]\nmissing_data = [inds[i] for i in np.random.choice(int(len(inds)), int(len(inds)*missing))]\nfor i,j in missing_data:\n    data2[i,j]=np.nan\n# plot\nhyp.plot([data1, data2], linestyle=['-',':'], legend=['Original', 'PPCA'])",
        "detail": "hypertools.examples.plot_PPCA",
        "documentation": {}
    },
    {
        "label": "inds",
        "kind": 5,
        "importPath": "hypertools.examples.plot_PPCA",
        "description": "hypertools.examples.plot_PPCA",
        "peekOfCode": "inds = [(i,j) for i in range(data2.shape[0]) for j in range(data2.shape[1])]\nmissing_data = [inds[i] for i in np.random.choice(int(len(inds)), int(len(inds)*missing))]\nfor i,j in missing_data:\n    data2[i,j]=np.nan\n# plot\nhyp.plot([data1, data2], linestyle=['-',':'], legend=['Original', 'PPCA'])",
        "detail": "hypertools.examples.plot_PPCA",
        "documentation": {}
    },
    {
        "label": "missing_data",
        "kind": 5,
        "importPath": "hypertools.examples.plot_PPCA",
        "description": "hypertools.examples.plot_PPCA",
        "peekOfCode": "missing_data = [inds[i] for i in np.random.choice(int(len(inds)), int(len(inds)*missing))]\nfor i,j in missing_data:\n    data2[i,j]=np.nan\n# plot\nhyp.plot([data1, data2], linestyle=['-',':'], legend=['Original', 'PPCA'])",
        "detail": "hypertools.examples.plot_PPCA",
        "documentation": {}
    },
    {
        "label": "digits",
        "kind": 5,
        "importPath": "hypertools.examples.plot_TSNE",
        "description": "hypertools.examples.plot_TSNE",
        "peekOfCode": "digits = datasets.load_digits(n_class=6)\ndata = digits.data\nhue = digits.target.astype('str')\nhyp.plot(data, '.', reduce='TSNE', hue=hue, ndims=2)",
        "detail": "hypertools.examples.plot_TSNE",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "hypertools.examples.plot_TSNE",
        "description": "hypertools.examples.plot_TSNE",
        "peekOfCode": "data = digits.data\nhue = digits.target.astype('str')\nhyp.plot(data, '.', reduce='TSNE', hue=hue, ndims=2)",
        "detail": "hypertools.examples.plot_TSNE",
        "documentation": {}
    },
    {
        "label": "hue",
        "kind": 5,
        "importPath": "hypertools.examples.plot_TSNE",
        "description": "hypertools.examples.plot_TSNE",
        "peekOfCode": "hue = digits.target.astype('str')\nhyp.plot(data, '.', reduce='TSNE', hue=hue, ndims=2)",
        "detail": "hypertools.examples.plot_TSNE",
        "documentation": {}
    },
    {
        "label": "digits",
        "kind": 5,
        "importPath": "hypertools.examples.plot_UMAP",
        "description": "hypertools.examples.plot_UMAP",
        "peekOfCode": "digits = datasets.load_digits(n_class=6)\ndata = digits.data\nhue = digits.target.astype('str')\nhyp.plot(data, '.', reduce='UMAP', hue=hue, ndims=2)",
        "detail": "hypertools.examples.plot_UMAP",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "hypertools.examples.plot_UMAP",
        "description": "hypertools.examples.plot_UMAP",
        "peekOfCode": "data = digits.data\nhue = digits.target.astype('str')\nhyp.plot(data, '.', reduce='UMAP', hue=hue, ndims=2)",
        "detail": "hypertools.examples.plot_UMAP",
        "documentation": {}
    },
    {
        "label": "hue",
        "kind": 5,
        "importPath": "hypertools.examples.plot_UMAP",
        "description": "hypertools.examples.plot_UMAP",
        "peekOfCode": "hue = digits.target.astype('str')\nhyp.plot(data, '.', reduce='UMAP', hue=hue, ndims=2)",
        "detail": "hypertools.examples.plot_UMAP",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "hypertools.examples.plot_align",
        "description": "hypertools.examples.plot_align",
        "peekOfCode": "data = hyp.load('weights').get_data()\ndata = hyp.align(data, align='hyper')\n# average into two groups\ngroup1 = np.mean(data[:17], 0)\ngroup2 = np.mean(data[18:], 0)\n# plot\nhyp.plot([group1[:100, :], group2[:100, :]])",
        "detail": "hypertools.examples.plot_align",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "hypertools.examples.plot_align",
        "description": "hypertools.examples.plot_align",
        "peekOfCode": "data = hyp.align(data, align='hyper')\n# average into two groups\ngroup1 = np.mean(data[:17], 0)\ngroup2 = np.mean(data[18:], 0)\n# plot\nhyp.plot([group1[:100, :], group2[:100, :]])",
        "detail": "hypertools.examples.plot_align",
        "documentation": {}
    },
    {
        "label": "group1",
        "kind": 5,
        "importPath": "hypertools.examples.plot_align",
        "description": "hypertools.examples.plot_align",
        "peekOfCode": "group1 = np.mean(data[:17], 0)\ngroup2 = np.mean(data[18:], 0)\n# plot\nhyp.plot([group1[:100, :], group2[:100, :]])",
        "detail": "hypertools.examples.plot_align",
        "documentation": {}
    },
    {
        "label": "group2",
        "kind": 5,
        "importPath": "hypertools.examples.plot_align",
        "description": "hypertools.examples.plot_align",
        "peekOfCode": "group2 = np.mean(data[18:], 0)\n# plot\nhyp.plot([group1[:100, :], group2[:100, :]])",
        "detail": "hypertools.examples.plot_align",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.examples.plot_basic",
        "description": "hypertools.examples.plot_basic",
        "peekOfCode": "geo = hyp.load('weights_sample')\n# plot\ngeo.plot(fmt='.')",
        "detail": "hypertools.examples.plot_basic",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.examples.plot_clusters",
        "description": "hypertools.examples.plot_clusters",
        "peekOfCode": "geo = hyp.load('mushrooms')\n# plot\ngeo.plot(n_clusters=10)",
        "detail": "hypertools.examples.plot_clusters",
        "documentation": {}
    },
    {
        "label": "cluster1",
        "kind": 5,
        "importPath": "hypertools.examples.plot_clusters2",
        "description": "hypertools.examples.plot_clusters2",
        "peekOfCode": "cluster1 = np.random.multivariate_normal(np.zeros(3), np.eye(3), size=100)\ncluster2 = np.random.multivariate_normal(np.zeros(3)+3, np.eye(3), size=100)\ndata = np.vstack([cluster1, cluster2])\n# get cluster labels\ncluster_labels = hyp.cluster(data, n_clusters=2)\n# plot\nhyp.plot(data, '.', hue=cluster_labels)",
        "detail": "hypertools.examples.plot_clusters2",
        "documentation": {}
    },
    {
        "label": "cluster2",
        "kind": 5,
        "importPath": "hypertools.examples.plot_clusters2",
        "description": "hypertools.examples.plot_clusters2",
        "peekOfCode": "cluster2 = np.random.multivariate_normal(np.zeros(3)+3, np.eye(3), size=100)\ndata = np.vstack([cluster1, cluster2])\n# get cluster labels\ncluster_labels = hyp.cluster(data, n_clusters=2)\n# plot\nhyp.plot(data, '.', hue=cluster_labels)",
        "detail": "hypertools.examples.plot_clusters2",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "hypertools.examples.plot_clusters2",
        "description": "hypertools.examples.plot_clusters2",
        "peekOfCode": "data = np.vstack([cluster1, cluster2])\n# get cluster labels\ncluster_labels = hyp.cluster(data, n_clusters=2)\n# plot\nhyp.plot(data, '.', hue=cluster_labels)",
        "detail": "hypertools.examples.plot_clusters2",
        "documentation": {}
    },
    {
        "label": "cluster_labels",
        "kind": 5,
        "importPath": "hypertools.examples.plot_clusters2",
        "description": "hypertools.examples.plot_clusters2",
        "peekOfCode": "cluster_labels = hyp.cluster(data, n_clusters=2)\n# plot\nhyp.plot(data, '.', hue=cluster_labels)",
        "detail": "hypertools.examples.plot_clusters2",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.examples.plot_clusters3",
        "description": "hypertools.examples.plot_clusters3",
        "peekOfCode": "geo = hyp.load('mushrooms')\n# plot\ngeo.plot(cluster={'model':'HDBSCAN',\n                             'params': {'min_samples':5,\n                                        'min_cluster_size':30}})",
        "detail": "hypertools.examples.plot_clusters3",
        "documentation": {}
    },
    {
        "label": "text_samples",
        "kind": 5,
        "importPath": "hypertools.examples.plot_corpus",
        "description": "hypertools.examples.plot_corpus",
        "peekOfCode": "text_samples = ['i like cats alot', 'cats r pretty cool', 'cats are better than dogs',\n        'dogs rule the haus', 'dogs are my jam', 'dogs are a mans best friend',\n        'i haz a cheezeburger?']\n# plot it\nhyp.plot(text_samples, 'o', corpus=text_samples)",
        "detail": "hypertools.examples.plot_corpus",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.examples.plot_dataframe",
        "description": "hypertools.examples.plot_dataframe",
        "peekOfCode": "geo = hyp.load('mushrooms')\nprint(geo.get_data().head())\n# plot\ngeo.plot()",
        "detail": "hypertools.examples.plot_dataframe",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.examples.plot_describe",
        "description": "hypertools.examples.plot_describe",
        "peekOfCode": "geo = hyp.load('weights_sample')\ndata = geo.get_data()\n# plot\nhyp.describe(data)",
        "detail": "hypertools.examples.plot_describe",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "hypertools.examples.plot_describe",
        "description": "hypertools.examples.plot_describe",
        "peekOfCode": "data = geo.get_data()\n# plot\nhyp.describe(data)",
        "detail": "hypertools.examples.plot_describe",
        "documentation": {}
    },
    {
        "label": "digits",
        "kind": 5,
        "importPath": "hypertools.examples.plot_digits",
        "description": "hypertools.examples.plot_digits",
        "peekOfCode": "digits = datasets.load_digits(n_class=6)\ndata = digits.data\nhue = digits.target\n# plot\nhyp.plot(data, '.', hue=hue)",
        "detail": "hypertools.examples.plot_digits",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "hypertools.examples.plot_digits",
        "description": "hypertools.examples.plot_digits",
        "peekOfCode": "data = digits.data\nhue = digits.target\n# plot\nhyp.plot(data, '.', hue=hue)",
        "detail": "hypertools.examples.plot_digits",
        "documentation": {}
    },
    {
        "label": "hue",
        "kind": 5,
        "importPath": "hypertools.examples.plot_digits",
        "description": "hypertools.examples.plot_digits",
        "peekOfCode": "hue = digits.target\n# plot\nhyp.plot(data, '.', hue=hue)",
        "detail": "hypertools.examples.plot_digits",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.examples.plot_geo",
        "description": "hypertools.examples.plot_geo",
        "peekOfCode": "geo = hyp.load('mushrooms')\n# plot\nt = geo.plot()\n# replot with new parameters\ngeo.plot(normalize='within', color='green')\n# save the object\n# geo.save('test')\n# load it back in\n# geo = hyp.load('test.geo')\n# transform some new data",
        "detail": "hypertools.examples.plot_geo",
        "documentation": {}
    },
    {
        "label": "t",
        "kind": 5,
        "importPath": "hypertools.examples.plot_geo",
        "description": "hypertools.examples.plot_geo",
        "peekOfCode": "t = geo.plot()\n# replot with new parameters\ngeo.plot(normalize='within', color='green')\n# save the object\n# geo.save('test')\n# load it back in\n# geo = hyp.load('test.geo')\n# transform some new data\n# transformed_data = geo.transform(data)\n# transform some 'new' data and plot it",
        "detail": "hypertools.examples.plot_geo",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.examples.plot_hue",
        "description": "hypertools.examples.plot_hue",
        "peekOfCode": "geo = hyp.load('weights_sample')\ndata = geo.get_data()\n# simulate random groups\nhue=[]\nfor idx,i in enumerate(data):\n    tmp=[]\n    for iidx,ii in enumerate(i):\n            tmp.append(int(np.random.randint(1000, size=1)))\n    hue.append(tmp)\n# plot",
        "detail": "hypertools.examples.plot_hue",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "hypertools.examples.plot_hue",
        "description": "hypertools.examples.plot_hue",
        "peekOfCode": "data = geo.get_data()\n# simulate random groups\nhue=[]\nfor idx,i in enumerate(data):\n    tmp=[]\n    for iidx,ii in enumerate(i):\n            tmp.append(int(np.random.randint(1000, size=1)))\n    hue.append(tmp)\n# plot\ngeo.plot(fmt='.', hue=hue)",
        "detail": "hypertools.examples.plot_hue",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.examples.plot_labels",
        "description": "hypertools.examples.plot_labels",
        "peekOfCode": "geo = hyp.load('weights_sample')\ndata = geo.get_data()\n# simulate labels\nlabels=[]\nfor idx,i in enumerate(data):\n    tmp=[]\n    for iidx,ii in enumerate(i):\n        if iidx==0:\n            tmp.append('Subject ' + str(idx))\n        else:",
        "detail": "hypertools.examples.plot_labels",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "hypertools.examples.plot_labels",
        "description": "hypertools.examples.plot_labels",
        "peekOfCode": "data = geo.get_data()\n# simulate labels\nlabels=[]\nfor idx,i in enumerate(data):\n    tmp=[]\n    for iidx,ii in enumerate(i):\n        if iidx==0:\n            tmp.append('Subject ' + str(idx))\n        else:\n            tmp.append(None)",
        "detail": "hypertools.examples.plot_labels",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.examples.plot_legend",
        "description": "hypertools.examples.plot_legend",
        "peekOfCode": "geo = hyp.load('weights_sample')\n# plot\ngeo.plot(fmt='.', legend=['Group A', 'Group B', 'Group C'])",
        "detail": "hypertools.examples.plot_legend",
        "documentation": {}
    },
    {
        "label": "K",
        "kind": 5,
        "importPath": "hypertools.examples.plot_missing_data",
        "description": "hypertools.examples.plot_missing_data",
        "peekOfCode": "K = 10 - toeplitz(np.arange(10))\ndata1 = np.cumsum(np.random.multivariate_normal(np.zeros(10), K, 250), axis=0)\ndata2 = copy(data1)\n# randomly remove 5% of the data\nmissing = .01\ninds = [(i,j) for i in range(data1.shape[0]) for j in range(data1.shape[1])]\nmissing_data = [inds[i] for i in np.random.choice(int(len(inds)), int(len(inds)*missing))]\nfor i,j in missing_data:\n    data2[i,j]=np.nan\n# reduce the data",
        "detail": "hypertools.examples.plot_missing_data",
        "documentation": {}
    },
    {
        "label": "data1",
        "kind": 5,
        "importPath": "hypertools.examples.plot_missing_data",
        "description": "hypertools.examples.plot_missing_data",
        "peekOfCode": "data1 = np.cumsum(np.random.multivariate_normal(np.zeros(10), K, 250), axis=0)\ndata2 = copy(data1)\n# randomly remove 5% of the data\nmissing = .01\ninds = [(i,j) for i in range(data1.shape[0]) for j in range(data1.shape[1])]\nmissing_data = [inds[i] for i in np.random.choice(int(len(inds)), int(len(inds)*missing))]\nfor i,j in missing_data:\n    data2[i,j]=np.nan\n# reduce the data\ndata1_r,data2_r = hyp.reduce([data1, data2], ndims=3)",
        "detail": "hypertools.examples.plot_missing_data",
        "documentation": {}
    },
    {
        "label": "data2",
        "kind": 5,
        "importPath": "hypertools.examples.plot_missing_data",
        "description": "hypertools.examples.plot_missing_data",
        "peekOfCode": "data2 = copy(data1)\n# randomly remove 5% of the data\nmissing = .01\ninds = [(i,j) for i in range(data1.shape[0]) for j in range(data1.shape[1])]\nmissing_data = [inds[i] for i in np.random.choice(int(len(inds)), int(len(inds)*missing))]\nfor i,j in missing_data:\n    data2[i,j]=np.nan\n# reduce the data\ndata1_r,data2_r = hyp.reduce([data1, data2], ndims=3)\n# pull out missing inds",
        "detail": "hypertools.examples.plot_missing_data",
        "documentation": {}
    },
    {
        "label": "missing",
        "kind": 5,
        "importPath": "hypertools.examples.plot_missing_data",
        "description": "hypertools.examples.plot_missing_data",
        "peekOfCode": "missing = .01\ninds = [(i,j) for i in range(data1.shape[0]) for j in range(data1.shape[1])]\nmissing_data = [inds[i] for i in np.random.choice(int(len(inds)), int(len(inds)*missing))]\nfor i,j in missing_data:\n    data2[i,j]=np.nan\n# reduce the data\ndata1_r,data2_r = hyp.reduce([data1, data2], ndims=3)\n# pull out missing inds\nmissing_inds = hyp.tools.missing_inds(data2)\nmissing_data = data2_r[missing_inds, :]",
        "detail": "hypertools.examples.plot_missing_data",
        "documentation": {}
    },
    {
        "label": "inds",
        "kind": 5,
        "importPath": "hypertools.examples.plot_missing_data",
        "description": "hypertools.examples.plot_missing_data",
        "peekOfCode": "inds = [(i,j) for i in range(data1.shape[0]) for j in range(data1.shape[1])]\nmissing_data = [inds[i] for i in np.random.choice(int(len(inds)), int(len(inds)*missing))]\nfor i,j in missing_data:\n    data2[i,j]=np.nan\n# reduce the data\ndata1_r,data2_r = hyp.reduce([data1, data2], ndims=3)\n# pull out missing inds\nmissing_inds = hyp.tools.missing_inds(data2)\nmissing_data = data2_r[missing_inds, :]\n# plot",
        "detail": "hypertools.examples.plot_missing_data",
        "documentation": {}
    },
    {
        "label": "missing_data",
        "kind": 5,
        "importPath": "hypertools.examples.plot_missing_data",
        "description": "hypertools.examples.plot_missing_data",
        "peekOfCode": "missing_data = [inds[i] for i in np.random.choice(int(len(inds)), int(len(inds)*missing))]\nfor i,j in missing_data:\n    data2[i,j]=np.nan\n# reduce the data\ndata1_r,data2_r = hyp.reduce([data1, data2], ndims=3)\n# pull out missing inds\nmissing_inds = hyp.tools.missing_inds(data2)\nmissing_data = data2_r[missing_inds, :]\n# plot\nhyp.plot([data1_r, data2_r, missing_data], ['-', '--', '*'],",
        "detail": "hypertools.examples.plot_missing_data",
        "documentation": {}
    },
    {
        "label": "data1_r,data2_r",
        "kind": 5,
        "importPath": "hypertools.examples.plot_missing_data",
        "description": "hypertools.examples.plot_missing_data",
        "peekOfCode": "data1_r,data2_r = hyp.reduce([data1, data2], ndims=3)\n# pull out missing inds\nmissing_inds = hyp.tools.missing_inds(data2)\nmissing_data = data2_r[missing_inds, :]\n# plot\nhyp.plot([data1_r, data2_r, missing_data], ['-', '--', '*'],\n         legend=['Full', 'Missing', 'Missing Points'])",
        "detail": "hypertools.examples.plot_missing_data",
        "documentation": {}
    },
    {
        "label": "missing_inds",
        "kind": 5,
        "importPath": "hypertools.examples.plot_missing_data",
        "description": "hypertools.examples.plot_missing_data",
        "peekOfCode": "missing_inds = hyp.tools.missing_inds(data2)\nmissing_data = data2_r[missing_inds, :]\n# plot\nhyp.plot([data1_r, data2_r, missing_data], ['-', '--', '*'],\n         legend=['Full', 'Missing', 'Missing Points'])",
        "detail": "hypertools.examples.plot_missing_data",
        "documentation": {}
    },
    {
        "label": "missing_data",
        "kind": 5,
        "importPath": "hypertools.examples.plot_missing_data",
        "description": "hypertools.examples.plot_missing_data",
        "peekOfCode": "missing_data = data2_r[missing_inds, :]\n# plot\nhyp.plot([data1_r, data2_r, missing_data], ['-', '--', '*'],\n         legend=['Full', 'Missing', 'Missing Points'])",
        "detail": "hypertools.examples.plot_missing_data",
        "documentation": {}
    },
    {
        "label": "cluster1",
        "kind": 5,
        "importPath": "hypertools.examples.plot_normalize",
        "description": "hypertools.examples.plot_normalize",
        "peekOfCode": "cluster1 = np.random.multivariate_normal(np.zeros(3), np.eye(3), size=100)\ncluster2 = np.random.multivariate_normal(np.zeros(3)+10, np.eye(3), size=100)\ndata = [cluster1, cluster2]\n# plot normalized across lists\nhyp.plot(data, '.', normalize='across', title='Normalized across datasets')\n# plot normalized within list\nhyp.plot(data, '.', normalize='within', title='Normalized within dataset')\n# normalize by row\nnormalized_row = hyp.normalize(data, normalize='row')\n# plot normalized by row",
        "detail": "hypertools.examples.plot_normalize",
        "documentation": {}
    },
    {
        "label": "cluster2",
        "kind": 5,
        "importPath": "hypertools.examples.plot_normalize",
        "description": "hypertools.examples.plot_normalize",
        "peekOfCode": "cluster2 = np.random.multivariate_normal(np.zeros(3)+10, np.eye(3), size=100)\ndata = [cluster1, cluster2]\n# plot normalized across lists\nhyp.plot(data, '.', normalize='across', title='Normalized across datasets')\n# plot normalized within list\nhyp.plot(data, '.', normalize='within', title='Normalized within dataset')\n# normalize by row\nnormalized_row = hyp.normalize(data, normalize='row')\n# plot normalized by row\nhyp.plot(normalized_row, '.', title='Normalized across row')",
        "detail": "hypertools.examples.plot_normalize",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "hypertools.examples.plot_normalize",
        "description": "hypertools.examples.plot_normalize",
        "peekOfCode": "data = [cluster1, cluster2]\n# plot normalized across lists\nhyp.plot(data, '.', normalize='across', title='Normalized across datasets')\n# plot normalized within list\nhyp.plot(data, '.', normalize='within', title='Normalized within dataset')\n# normalize by row\nnormalized_row = hyp.normalize(data, normalize='row')\n# plot normalized by row\nhyp.plot(normalized_row, '.', title='Normalized across row')",
        "detail": "hypertools.examples.plot_normalize",
        "documentation": {}
    },
    {
        "label": "normalized_row",
        "kind": 5,
        "importPath": "hypertools.examples.plot_normalize",
        "description": "hypertools.examples.plot_normalize",
        "peekOfCode": "normalized_row = hyp.normalize(data, normalize='row')\n# plot normalized by row\nhyp.plot(normalized_row, '.', title='Normalized across row')",
        "detail": "hypertools.examples.plot_normalize",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.examples.plot_procrustes",
        "description": "hypertools.examples.plot_procrustes",
        "peekOfCode": "geo = hyp.load('spiral')\ngeo.plot(title='Before Alignment')\n# use procrusted to align the data\nsource, target = geo.get_data()\naligned = [hyp.tools.procrustes(source, target), target]\n# after alignment\nhyp.plot(aligned, ['-','--'], title='After alignment')",
        "detail": "hypertools.examples.plot_procrustes",
        "documentation": {}
    },
    {
        "label": "aligned",
        "kind": 5,
        "importPath": "hypertools.examples.plot_procrustes",
        "description": "hypertools.examples.plot_procrustes",
        "peekOfCode": "aligned = [hyp.tools.procrustes(source, target), target]\n# after alignment\nhyp.plot(aligned, ['-','--'], title='After alignment')",
        "detail": "hypertools.examples.plot_procrustes",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.examples.plot_sotus",
        "description": "hypertools.examples.plot_sotus",
        "peekOfCode": "geo = hyp.load('sotus')\n# plot it\ngeo.plot()",
        "detail": "hypertools.examples.plot_sotus",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "hypertools.examples.plot_text",
        "description": "hypertools.examples.plot_text",
        "peekOfCode": "data = [['i like cats alot', 'cats r pretty cool', 'cats are better than dogs'],\n        ['dogs rule the haus', 'dogs are my jam', 'dogs are a mans best friend'],\n        'i haz a cheezeburger?']\n# plot it\nhyp.plot(data, 'o')\n# convert text to matrix without plotting\n# mtx = hyp.tools.format_data(data, vectorizer='TfidfVectorizer', semantic='NMF')",
        "detail": "hypertools.examples.plot_text",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.examples.precog",
        "description": "hypertools.examples.precog",
        "peekOfCode": "geo = hyp.load('weights_avg')\n# plot\ngeo.plot(animate=True, precog=True)",
        "detail": "hypertools.examples.precog",
        "documentation": {}
    },
    {
        "label": "group1",
        "kind": 5,
        "importPath": "hypertools.examples.save_movie",
        "description": "hypertools.examples.save_movie",
        "peekOfCode": "group1 = np.mean(data[:17], 0)\ngroup2 = np.mean(data[18:], 0)\nhyp.plot([group1, group2], animate=True, save_path='animation.mp4')",
        "detail": "hypertools.examples.save_movie",
        "documentation": {}
    },
    {
        "label": "group2",
        "kind": 5,
        "importPath": "hypertools.examples.save_movie",
        "description": "hypertools.examples.save_movie",
        "peekOfCode": "group2 = np.mean(data[18:], 0)\nhyp.plot([group1, group2], animate=True, save_path='animation.mp4')",
        "detail": "hypertools.examples.save_movie",
        "documentation": {}
    },
    {
        "label": "PPCA",
        "kind": 6,
        "importPath": "hypertools.hypertools._externals.ppca",
        "description": "hypertools.hypertools._externals.ppca",
        "peekOfCode": "class PPCA(object):\n    def __init__(self):\n        self.raw = None\n        self.data = None\n        self.C = None\n        self.means = None\n        self.stds = None\n    def _standardize(self, X):\n        if self.means is None or self.stds is None:\n            raise RuntimeError(\"Fit model first\")",
        "detail": "hypertools.hypertools._externals.ppca",
        "documentation": {}
    },
    {
        "label": "SRM",
        "kind": 6,
        "importPath": "hypertools.hypertools._externals.srm",
        "description": "hypertools.hypertools._externals.srm",
        "peekOfCode": "class SRM(BaseEstimator, TransformerMixin):\n    \"\"\"Probabilistic Shared Response Model (SRM)\n    Given multi-subject data, factorize it as a shared response S among all\n    subjects and an orthogonal transform W per subject:\n    .. math:: X_i \\\\approx W_i S, \\\\forall i=1 \\\\dots N\n    Parameters\n    ----------\n    n_iter : int, default: 10\n        Number of iterations to run the algorithm.\n    features : int, default: 50",
        "detail": "hypertools.hypertools._externals.srm",
        "documentation": {}
    },
    {
        "label": "DetSRM",
        "kind": 6,
        "importPath": "hypertools.hypertools._externals.srm",
        "description": "hypertools.hypertools._externals.srm",
        "peekOfCode": "class DetSRM(BaseEstimator, TransformerMixin):\n    \"\"\"Deterministic Shared Response Model (DetSRM)\n    Given multi-subject data, factorize it as a shared response S among all\n    subjects and an orthogonal transform W per subject:\n    .. math:: X_i \\\\approx W_i S, \\\\forall i=1 \\\\dots N\n    Parameters\n    ----------\n    n_iter : int, default: 10\n        Number of iterations to run the algorithm.\n    features : int, default: 50",
        "detail": "hypertools.hypertools._externals.srm",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "hypertools.hypertools._externals.srm",
        "description": "hypertools.hypertools._externals.srm",
        "peekOfCode": "__all__ = [\n    \"SRM\", \"DetSRM\"\n]\nlogger = logging.getLogger(__name__)\ndef _init_w_transforms(data, features):\n    \"\"\"Initialize the mappings (Wi) for the SRM with random orthogonal matrices.\n    Parameters\n    ----------\n    data : list of 2D arrays, element i has shape=[voxels_i, samples]\n        Each element in the list contains the fMRI data of one subject.",
        "detail": "hypertools.hypertools._externals.srm",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "hypertools.hypertools._externals.srm",
        "description": "hypertools.hypertools._externals.srm",
        "peekOfCode": "logger = logging.getLogger(__name__)\ndef _init_w_transforms(data, features):\n    \"\"\"Initialize the mappings (Wi) for the SRM with random orthogonal matrices.\n    Parameters\n    ----------\n    data : list of 2D arrays, element i has shape=[voxels_i, samples]\n        Each element in the list contains the fMRI data of one subject.\n    features : int\n        The number of features in the model.\n    Returns",
        "detail": "hypertools.hypertools._externals.srm",
        "documentation": {}
    },
    {
        "label": "HypertoolsError",
        "kind": 6,
        "importPath": "hypertools.hypertools._shared.exceptions",
        "description": "hypertools.hypertools._shared.exceptions",
        "peekOfCode": "class HypertoolsError(Exception):\n    pass\nclass HypertoolsBackendError(HypertoolsError):\n    def __init__(self, message):\n        super().__init__(message)\n        self.message = message\nclass HypertoolsIOError(HypertoolsError, OSError):\n    def __init__(self, message):\n        super().__init__(message)\n        self.message = message",
        "detail": "hypertools.hypertools._shared.exceptions",
        "documentation": {}
    },
    {
        "label": "HypertoolsBackendError",
        "kind": 6,
        "importPath": "hypertools.hypertools._shared.exceptions",
        "description": "hypertools.hypertools._shared.exceptions",
        "peekOfCode": "class HypertoolsBackendError(HypertoolsError):\n    def __init__(self, message):\n        super().__init__(message)\n        self.message = message\nclass HypertoolsIOError(HypertoolsError, OSError):\n    def __init__(self, message):\n        super().__init__(message)\n        self.message = message",
        "detail": "hypertools.hypertools._shared.exceptions",
        "documentation": {}
    },
    {
        "label": "HypertoolsIOError",
        "kind": 6,
        "importPath": "hypertools.hypertools._shared.exceptions",
        "description": "hypertools.hypertools._shared.exceptions",
        "peekOfCode": "class HypertoolsIOError(HypertoolsError, OSError):\n    def __init__(self, message):\n        super().__init__(message)\n        self.message = message",
        "detail": "hypertools.hypertools._shared.exceptions",
        "documentation": {}
    },
    {
        "label": "center",
        "kind": 2,
        "importPath": "hypertools.hypertools._shared.helpers",
        "description": "hypertools.hypertools._shared.helpers",
        "peekOfCode": "def center(x):\n    assert type(x) is list, \"Input data to center must be list\"\n    x_stacked = np.vstack(x)\n    return [i - np.mean(x_stacked, 0) for i in x]\ndef scale(x):\n    assert type(x) is list, \"Input data to scale must be list\"\n    x_stacked = np.vstack(x)\n    m1 = np.min(x_stacked)\n    m2 = np.max(x_stacked - m1)\n    f = lambda x: 2*(np.divide(x - m1, m2)) - 1",
        "detail": "hypertools.hypertools._shared.helpers",
        "documentation": {}
    },
    {
        "label": "scale",
        "kind": 2,
        "importPath": "hypertools.hypertools._shared.helpers",
        "description": "hypertools.hypertools._shared.helpers",
        "peekOfCode": "def scale(x):\n    assert type(x) is list, \"Input data to scale must be list\"\n    x_stacked = np.vstack(x)\n    m1 = np.min(x_stacked)\n    m2 = np.max(x_stacked - m1)\n    f = lambda x: 2*(np.divide(x - m1, m2)) - 1\n    return [f(i) for i in x]\ndef group_by_category(vals):\n    if any(isinstance(el, list) for el in vals):\n        vals = list(itertools.chain(*vals))",
        "detail": "hypertools.hypertools._shared.helpers",
        "documentation": {}
    },
    {
        "label": "group_by_category",
        "kind": 2,
        "importPath": "hypertools.hypertools._shared.helpers",
        "description": "hypertools.hypertools._shared.helpers",
        "peekOfCode": "def group_by_category(vals):\n    if any(isinstance(el, list) for el in vals):\n        vals = list(itertools.chain(*vals))\n    val_set = list(sorted(set(vals), key=list(vals).index))\n    return [val_set.index(val) for val in vals]\ndef vals2colors(vals, cmap='GnBu',res=100):\n    \"\"\"Maps values to colors\n    Args:\n    values (list or list of lists) - list of values to map to colors\n    cmap (str) - color map (default is 'GnBu')",
        "detail": "hypertools.hypertools._shared.helpers",
        "documentation": {}
    },
    {
        "label": "vals2colors",
        "kind": 2,
        "importPath": "hypertools.hypertools._shared.helpers",
        "description": "hypertools.hypertools._shared.helpers",
        "peekOfCode": "def vals2colors(vals, cmap='GnBu',res=100):\n    \"\"\"Maps values to colors\n    Args:\n    values (list or list of lists) - list of values to map to colors\n    cmap (str) - color map (default is 'GnBu')\n    res (int) - resolution of the color map (default: 100)\n    Returns:\n    list of rgb tuples\n    \"\"\"\n    # flatten if list of lists",
        "detail": "hypertools.hypertools._shared.helpers",
        "documentation": {}
    },
    {
        "label": "vals2bins",
        "kind": 2,
        "importPath": "hypertools.hypertools._shared.helpers",
        "description": "hypertools.hypertools._shared.helpers",
        "peekOfCode": "def vals2bins(vals,res=100):\n    \"\"\"Maps values to bins\n    Args:\n    values (list or list of lists) - list of values to map to colors\n    res (int) - resolution of the color map (default: 100)\n    Returns:\n    list of numbers representing bins\n    \"\"\"\n    # flatten if list of lists\n    if any(isinstance(el, list) for el in vals):",
        "detail": "hypertools.hypertools._shared.helpers",
        "documentation": {}
    },
    {
        "label": "interp_array",
        "kind": 2,
        "importPath": "hypertools.hypertools._shared.helpers",
        "description": "hypertools.hypertools._shared.helpers",
        "peekOfCode": "def interp_array(arr,interp_val=10):\n    x=np.arange(0, len(arr), 1)\n    xx=np.arange(0, len(arr)-1, 1/interp_val)\n    q=pchip(x,arr)\n    return q(xx)\ndef interp_array_list(arr_list,interp_val=10):\n    smoothed= [np.zeros(arr_list[0].shape) for item in arr_list]\n    for idx,arr in enumerate(arr_list):\n        smoothed[idx] = interp_array(arr,interp_val)\n    return smoothed",
        "detail": "hypertools.hypertools._shared.helpers",
        "documentation": {}
    },
    {
        "label": "interp_array_list",
        "kind": 2,
        "importPath": "hypertools.hypertools._shared.helpers",
        "description": "hypertools.hypertools._shared.helpers",
        "peekOfCode": "def interp_array_list(arr_list,interp_val=10):\n    smoothed= [np.zeros(arr_list[0].shape) for item in arr_list]\n    for idx,arr in enumerate(arr_list):\n        smoothed[idx] = interp_array(arr,interp_val)\n    return smoothed\ndef parse_args(x,args):\n    args_list = []\n    for i,item in enumerate(x):\n        tmp = []\n        for ii, arg in enumerate(args):",
        "detail": "hypertools.hypertools._shared.helpers",
        "documentation": {}
    },
    {
        "label": "parse_args",
        "kind": 2,
        "importPath": "hypertools.hypertools._shared.helpers",
        "description": "hypertools.hypertools._shared.helpers",
        "peekOfCode": "def parse_args(x,args):\n    args_list = []\n    for i,item in enumerate(x):\n        tmp = []\n        for ii, arg in enumerate(args):\n            if isinstance(arg, (tuple, list)):\n                if len(arg) == len(x):\n                    tmp.append(arg[i])\n                else:\n                    print('Error: arguments must be a list of the same length as x')",
        "detail": "hypertools.hypertools._shared.helpers",
        "documentation": {}
    },
    {
        "label": "parse_kwargs",
        "kind": 2,
        "importPath": "hypertools.hypertools._shared.helpers",
        "description": "hypertools.hypertools._shared.helpers",
        "peekOfCode": "def parse_kwargs(x, kwargs):\n    kwargs_list = []\n    for i,item in enumerate(x):\n        tmp = {}\n        for kwarg in kwargs:\n            if isinstance(kwargs[kwarg], (tuple, list)):\n                if len(kwargs[kwarg]) == len(x):\n                    tmp[kwarg]=kwargs[kwarg][i]\n                else:\n                    tmp[kwarg] = None",
        "detail": "hypertools.hypertools._shared.helpers",
        "documentation": {}
    },
    {
        "label": "reshape_data",
        "kind": 2,
        "importPath": "hypertools.hypertools._shared.helpers",
        "description": "hypertools.hypertools._shared.helpers",
        "peekOfCode": "def reshape_data(x, hue, labels):\n    categories = list(sorted(set(hue), key=list(hue).index))\n    x_stacked = np.vstack(x)\n    x_reshaped = [[] for _ in categories]\n    labels_reshaped = [[] for _ in categories]\n    if labels is None:\n        labels = [None]*len(hue)\n    for idx, (point, label) in enumerate(zip(hue, labels)):\n        x_reshaped[categories.index(point)].append(x_stacked[idx])\n        labels_reshaped[categories.index(point)].append(labels[idx])",
        "detail": "hypertools.hypertools._shared.helpers",
        "documentation": {}
    },
    {
        "label": "patch_lines",
        "kind": 2,
        "importPath": "hypertools.hypertools._shared.helpers",
        "description": "hypertools.hypertools._shared.helpers",
        "peekOfCode": "def patch_lines(x):\n    \"\"\"\n    Draw lines between groups\n    \"\"\"\n    for idx in range(len(x)-1):\n        x[idx] = np.vstack([x[idx], x[idx+1][0,:]])\n    return x\ndef is_line(format_str):\n    if isinstance(format_str, np.bytes_):\n        format_str = format_str.decode('utf-8')",
        "detail": "hypertools.hypertools._shared.helpers",
        "documentation": {}
    },
    {
        "label": "is_line",
        "kind": 2,
        "importPath": "hypertools.hypertools._shared.helpers",
        "description": "hypertools.hypertools._shared.helpers",
        "peekOfCode": "def is_line(format_str):\n    if isinstance(format_str, np.bytes_):\n        format_str = format_str.decode('utf-8')\n    markers = list(map(lambda x: str(x), Line2D.markers.keys()))\n    return (format_str is None) or (all([str(symbol) not in format_str for symbol in markers]))\ndef memoize(obj):\n    cache = obj.cache = {}\n    @functools.wraps(obj)\n    def memoizer(*args, **kwargs):\n        key = str(args) + str(kwargs)",
        "detail": "hypertools.hypertools._shared.helpers",
        "documentation": {}
    },
    {
        "label": "memoize",
        "kind": 2,
        "importPath": "hypertools.hypertools._shared.helpers",
        "description": "hypertools.hypertools._shared.helpers",
        "peekOfCode": "def memoize(obj):\n    cache = obj.cache = {}\n    @functools.wraps(obj)\n    def memoizer(*args, **kwargs):\n        key = str(args) + str(kwargs)\n        if key not in cache:\n            cache[key] = obj(*args, **kwargs)\n        return cache[key]\n    return memoizer\ndef get_type(data):",
        "detail": "hypertools.hypertools._shared.helpers",
        "documentation": {}
    },
    {
        "label": "get_type",
        "kind": 2,
        "importPath": "hypertools.hypertools._shared.helpers",
        "description": "hypertools.hypertools._shared.helpers",
        "peekOfCode": "def get_type(data):\n    \"\"\"\n    Checks what the data type is and returns it as a string label\n    \"\"\"\n    from ..datageometry import DataGeometry\n    if isinstance(data, list):\n        if isinstance(data[0], (str, bytes)):\n            return 'list_str'\n        elif isinstance(data[0], (int, float)):\n            return 'list_num'",
        "detail": "hypertools.hypertools._shared.helpers",
        "documentation": {}
    },
    {
        "label": "convert_text",
        "kind": 2,
        "importPath": "hypertools.hypertools._shared.helpers",
        "description": "hypertools.hypertools._shared.helpers",
        "peekOfCode": "def convert_text(data):\n    dtype = get_type(data)\n    if dtype in ['list_str', 'str']:\n        data = np.array(data).reshape(-1, 1)\n    return data\ndef check_geo(geo):\n    \"\"\" Checks a geo and makes sure the text fields are not binary \"\"\"\n    geo = copy.copy(geo)\n    def fix_item(item):\n        if isinstance(item, bytes):",
        "detail": "hypertools.hypertools._shared.helpers",
        "documentation": {}
    },
    {
        "label": "check_geo",
        "kind": 2,
        "importPath": "hypertools.hypertools._shared.helpers",
        "description": "hypertools.hypertools._shared.helpers",
        "peekOfCode": "def check_geo(geo):\n    \"\"\" Checks a geo and makes sure the text fields are not binary \"\"\"\n    geo = copy.copy(geo)\n    def fix_item(item):\n        if isinstance(item, bytes):\n            return item.decode()\n        return item\n    def fix_list(lst):\n        return [fix_item(i) for i in lst]\n    if isinstance(geo.reduce, bytes):",
        "detail": "hypertools.hypertools._shared.helpers",
        "documentation": {}
    },
    {
        "label": "get_dtype",
        "kind": 2,
        "importPath": "hypertools.hypertools._shared.helpers",
        "description": "hypertools.hypertools._shared.helpers",
        "peekOfCode": "def get_dtype(data):\n    \"\"\"\n    Checks what the data type is and returns it as a string label\n    \"\"\"\n    from ..datageometry import DataGeometry\n    if isinstance(data, list):\n        return 'list'\n    elif isinstance(data, np.ndarray):\n        return 'arr'\n    elif isinstance(data, pd.DataFrame):",
        "detail": "hypertools.hypertools._shared.helpers",
        "documentation": {}
    },
    {
        "label": "default_params",
        "kind": 2,
        "importPath": "hypertools.hypertools._shared.params",
        "description": "hypertools.hypertools._shared.params",
        "peekOfCode": "def default_params(model, update_dict=None):\n    \"\"\"\n    Loads and updates default model parameters\n    Parameters\n    ----------\n    model : str\n        The name of a model\n    update_dict : dict\n        A dict to update default parameters\n    Returns",
        "detail": "hypertools.hypertools._shared.params",
        "documentation": {}
    },
    {
        "label": "parameters",
        "kind": 5,
        "importPath": "hypertools.hypertools._shared.params",
        "description": "hypertools.hypertools._shared.params",
        "peekOfCode": "parameters = {\n    'KMeans': {'n_clusters': 5},\n    'MiniBatchKMeans': {'n_clusters': 5},\n    'SpectralClustering': {'n_clusters': 5,\n                           'affinity': 'nearest_neighbors',\n                           'n_neighbors': 10},\n    'AgglomerativeClustering': {'n_clusters': 5, 'linkage' : 'ward'},\n    'FeatureAgglomeration': {'n_clusters': 5},\n    'Birch': {'n_clusters': 5},\n    'HDBSCAN': {'min_samples': 5, 'min_cluster_size': 15},",
        "detail": "hypertools.hypertools._shared.params",
        "documentation": {}
    },
    {
        "label": "ParrotDict",
        "kind": 6,
        "importPath": "hypertools.hypertools.plot.backend",
        "description": "hypertools.hypertools.plot.backend",
        "peekOfCode": "class ParrotDict(dict):\n    \"\"\"\n    Dictionary subclass with a few changes in behavior:\n      1. all keys and values are stored and indexed as\n         `HypertoolsBackend` instances\n      2. indexing a `ParrotDict` with a key that doesn't exist returns\n         the key (it's \"parroted\" back to you). The key is converted to\n         a `HypertoolsBackend` instance if it is not already. Similar\n         to `collections.defaultdict`, but does *not* add missing keys\n         on indexing.",
        "detail": "hypertools.hypertools.plot.backend",
        "documentation": {}
    },
    {
        "label": "BackendMapping",
        "kind": 6,
        "importPath": "hypertools.hypertools.plot.backend",
        "description": "hypertools.hypertools.plot.backend",
        "peekOfCode": "class BackendMapping:\n    \"\"\"\n    A two-way, non-unique dict-like mapping between keys used to set\n    the matplotlib plotting backend in Python and IPython environments.\n    Primarily used by `as_python()` and `as_ipython()` methods of\n    `HypertoolsBackend`.  Funnels multiple equivalent keys within the\n    same interpreter (Python vs. IPython) to a \"default\", then maps\n    between that and the analog from the other interpreter type. At\n    either step, a key with no corresponding value returns the key (see\n    `ParrotDict` docstring for more info).",
        "detail": "hypertools.hypertools.plot.backend",
        "documentation": {}
    },
    {
        "label": "HypertoolsBackend",
        "kind": 6,
        "importPath": "hypertools.hypertools.plot.backend",
        "description": "hypertools.hypertools.plot.backend",
        "peekOfCode": "class HypertoolsBackend(str):\n    \"\"\"\n    A subclass of the `str` built-in, intended for easy(ish...)\n    conversion between the different valid matplotlib backend keys in\n    Python vs IPython and equality/membership checks.\n    Notes\n    -----\n    Normally, a lot of this could be simplified and a lot of grief saved\n    by subclassing `collections.UserString` rather than `str` directly.\n    The issue is that these objects get passed to a ton of different",
        "detail": "hypertools.hypertools.plot.backend",
        "documentation": {}
    },
    {
        "label": "set_interactive_backend",
        "kind": 6,
        "importPath": "hypertools.hypertools.plot.backend",
        "description": "hypertools.hypertools.plot.backend",
        "peekOfCode": "class set_interactive_backend:\n    \"\"\"\n    Manually set the `matplotlib` backend used for generating\n    interactive plots.\n    Whereas `hypertools.plot`'s `mpl_backend` keyword argument can be\n    used to specify the backend for a single plot,\n    `hypertools.set_interactive_backend` is useful for doing so for\n    multiple (or all) interactive plots at once, and can be in two\n    different ways:\n    1. directly, to change the backend for all subsequent interactive",
        "detail": "hypertools.hypertools.plot.backend",
        "documentation": {}
    },
    {
        "label": "manage_backend",
        "kind": 2,
        "importPath": "hypertools.hypertools.plot.backend",
        "description": "hypertools.hypertools.plot.backend",
        "peekOfCode": "def manage_backend(plot_func):\n    \"\"\"\n    Decorator for hypertools.plot that prevents unexpected changes to\n    matplotlib rcParams (https://github.com/ContextLab/hypertools/issues/243)\n    and handles temporarily changing the matplotlib backend for\n    interactive and animated plots, as necessary.\n    Parameters\n    ----------\n    plot_func : function\n        Function around which to set/reset the plotting backend and",
        "detail": "hypertools.hypertools.plot.backend",
        "documentation": {}
    },
    {
        "label": "BACKEND_KEYS",
        "kind": 5,
        "importPath": "hypertools.hypertools.plot.backend",
        "description": "hypertools.hypertools.plot.backend",
        "peekOfCode": "BACKEND_KEYS = {\n    'TkAgg': 'tk',\n    'GTK3Agg': ['gtk3', 'gtk'],\n    'WXAgg': 'wx',\n    'Qt4Agg': 'qt4',\n    'Qt5Agg': ['qt5', 'qt'],\n    'MacOSX': 'osx',\n    'nbAgg': ['notebook', 'nbagg'],\n    'module://ipykernel.pylab.backend_inline': 'inline',\n    'module://matplotlib_inline.backend_inline': 'inline',",
        "detail": "hypertools.hypertools.plot.backend",
        "documentation": {}
    },
    {
        "label": "BACKEND_MAPPING",
        "kind": 5,
        "importPath": "hypertools.hypertools.plot.backend",
        "description": "hypertools.hypertools.plot.backend",
        "peekOfCode": "BACKEND_MAPPING = None\nBACKEND_WARNING = None\nHYPERTOOLS_BACKEND = None\nIN_SET_CONTEXT = False\nIPYTHON_INSTANCE = None\nIS_NOTEBOOK = None\nreset_backend = None\nswitch_backend = None\nclass ParrotDict(dict):\n    \"\"\"",
        "detail": "hypertools.hypertools.plot.backend",
        "documentation": {}
    },
    {
        "label": "BACKEND_WARNING",
        "kind": 5,
        "importPath": "hypertools.hypertools.plot.backend",
        "description": "hypertools.hypertools.plot.backend",
        "peekOfCode": "BACKEND_WARNING = None\nHYPERTOOLS_BACKEND = None\nIN_SET_CONTEXT = False\nIPYTHON_INSTANCE = None\nIS_NOTEBOOK = None\nreset_backend = None\nswitch_backend = None\nclass ParrotDict(dict):\n    \"\"\"\n    Dictionary subclass with a few changes in behavior:",
        "detail": "hypertools.hypertools.plot.backend",
        "documentation": {}
    },
    {
        "label": "HYPERTOOLS_BACKEND",
        "kind": 5,
        "importPath": "hypertools.hypertools.plot.backend",
        "description": "hypertools.hypertools.plot.backend",
        "peekOfCode": "HYPERTOOLS_BACKEND = None\nIN_SET_CONTEXT = False\nIPYTHON_INSTANCE = None\nIS_NOTEBOOK = None\nreset_backend = None\nswitch_backend = None\nclass ParrotDict(dict):\n    \"\"\"\n    Dictionary subclass with a few changes in behavior:\n      1. all keys and values are stored and indexed as",
        "detail": "hypertools.hypertools.plot.backend",
        "documentation": {}
    },
    {
        "label": "IN_SET_CONTEXT",
        "kind": 5,
        "importPath": "hypertools.hypertools.plot.backend",
        "description": "hypertools.hypertools.plot.backend",
        "peekOfCode": "IN_SET_CONTEXT = False\nIPYTHON_INSTANCE = None\nIS_NOTEBOOK = None\nreset_backend = None\nswitch_backend = None\nclass ParrotDict(dict):\n    \"\"\"\n    Dictionary subclass with a few changes in behavior:\n      1. all keys and values are stored and indexed as\n         `HypertoolsBackend` instances",
        "detail": "hypertools.hypertools.plot.backend",
        "documentation": {}
    },
    {
        "label": "IPYTHON_INSTANCE",
        "kind": 5,
        "importPath": "hypertools.hypertools.plot.backend",
        "description": "hypertools.hypertools.plot.backend",
        "peekOfCode": "IPYTHON_INSTANCE = None\nIS_NOTEBOOK = None\nreset_backend = None\nswitch_backend = None\nclass ParrotDict(dict):\n    \"\"\"\n    Dictionary subclass with a few changes in behavior:\n      1. all keys and values are stored and indexed as\n         `HypertoolsBackend` instances\n      2. indexing a `ParrotDict` with a key that doesn't exist returns",
        "detail": "hypertools.hypertools.plot.backend",
        "documentation": {}
    },
    {
        "label": "IS_NOTEBOOK",
        "kind": 5,
        "importPath": "hypertools.hypertools.plot.backend",
        "description": "hypertools.hypertools.plot.backend",
        "peekOfCode": "IS_NOTEBOOK = None\nreset_backend = None\nswitch_backend = None\nclass ParrotDict(dict):\n    \"\"\"\n    Dictionary subclass with a few changes in behavior:\n      1. all keys and values are stored and indexed as\n         `HypertoolsBackend` instances\n      2. indexing a `ParrotDict` with a key that doesn't exist returns\n         the key (it's \"parroted\" back to you). The key is converted to",
        "detail": "hypertools.hypertools.plot.backend",
        "documentation": {}
    },
    {
        "label": "reset_backend",
        "kind": 5,
        "importPath": "hypertools.hypertools.plot.backend",
        "description": "hypertools.hypertools.plot.backend",
        "peekOfCode": "reset_backend = None\nswitch_backend = None\nclass ParrotDict(dict):\n    \"\"\"\n    Dictionary subclass with a few changes in behavior:\n      1. all keys and values are stored and indexed as\n         `HypertoolsBackend` instances\n      2. indexing a `ParrotDict` with a key that doesn't exist returns\n         the key (it's \"parroted\" back to you). The key is converted to\n         a `HypertoolsBackend` instance if it is not already. Similar",
        "detail": "hypertools.hypertools.plot.backend",
        "documentation": {}
    },
    {
        "label": "switch_backend",
        "kind": 5,
        "importPath": "hypertools.hypertools.plot.backend",
        "description": "hypertools.hypertools.plot.backend",
        "peekOfCode": "switch_backend = None\nclass ParrotDict(dict):\n    \"\"\"\n    Dictionary subclass with a few changes in behavior:\n      1. all keys and values are stored and indexed as\n         `HypertoolsBackend` instances\n      2. indexing a `ParrotDict` with a key that doesn't exist returns\n         the key (it's \"parroted\" back to you). The key is converted to\n         a `HypertoolsBackend` instance if it is not already. Similar\n         to `collections.defaultdict`, but does *not* add missing keys",
        "detail": "hypertools.hypertools.plot.backend",
        "documentation": {}
    },
    {
        "label": "matplotlib.rcParams[\"pdf.fonttype\"]",
        "kind": 5,
        "importPath": "hypertools.hypertools.plot.draw",
        "description": "hypertools.hypertools.plot.draw",
        "peekOfCode": "matplotlib.rcParams[\"pdf.fonttype\"] = 42\ndef _draw(\n    x,\n    legend=None,\n    title=None,\n    labels=False,\n    show=True,\n    kwargs_list=None,\n    fmt=None,\n    animate=False,",
        "detail": "hypertools.hypertools.plot.draw",
        "documentation": {}
    },
    {
        "label": "plot",
        "kind": 2,
        "importPath": "hypertools.hypertools.plot.plot",
        "description": "hypertools.hypertools.plot.plot",
        "peekOfCode": "def plot(\n    x,\n    fmt=\"-\",\n    marker=None,\n    markers=None,\n    linestyle=None,\n    linestyles=None,\n    color=None,\n    colors=None,\n    palette=\"hls\",",
        "detail": "hypertools.hypertools.plot.plot",
        "documentation": {}
    },
    {
        "label": "align",
        "kind": 2,
        "importPath": "hypertools.hypertools.tools.align",
        "description": "hypertools.hypertools.tools.align",
        "peekOfCode": "def align(data, align='hyper', normalize=None, ndims=None, method=None,\n          format_data=True):\n    \"\"\"\n    Aligns a list of arrays\n    This function takes a list of high dimensional arrays and 'hyperaligns' them\n    to a 'common' space, or coordinate system following the approach outlined by\n    Haxby et al, 2011. Hyperalignment uses linear transformations (rotation,\n    reflection, translation, scaling) to register a group of arrays to a common\n    space. This can be useful when two or more datasets describe an identical\n    or similar system, but may not be in same coordinate system. For example,",
        "detail": "hypertools.hypertools.tools.align",
        "documentation": {}
    },
    {
        "label": "analyze",
        "kind": 2,
        "importPath": "hypertools.hypertools.tools.analyze",
        "description": "hypertools.hypertools.tools.analyze",
        "peekOfCode": "def analyze(data, normalize=None, reduce=None, ndims=None, align=None, internal=False):\n    \"\"\"\n    Wrapper function for normalize -> reduce -> align transformations.\n    Parameters\n    ----------\n    data : numpy array, pandas df, or list of arrays/dfs\n        The data to analyze\n    normalize : str or False or None\n        If set to 'across', the columns of the input data will be z-scored\n        across lists (default). That is, the z-scores will be computed with",
        "detail": "hypertools.hypertools.tools.analyze",
        "documentation": {}
    },
    {
        "label": "cluster",
        "kind": 2,
        "importPath": "hypertools.hypertools.tools.cluster",
        "description": "hypertools.hypertools.tools.cluster",
        "peekOfCode": "def cluster(x, cluster='KMeans', n_clusters=3, ndims=None, format_data=True):\n    \"\"\"\n    Performs clustering analysis and returns a list of cluster labels\n    Parameters\n    ----------\n    x : A Numpy array, Pandas Dataframe or list of arrays/dfs\n        The data to be clustered.  You can pass a single array/df or a list.\n        If a list is passed, the arrays will be stacked and the clustering\n        will be performed across all lists (i.e. not within each list).\n    cluster : str or dict",
        "detail": "hypertools.hypertools.tools.cluster",
        "documentation": {}
    },
    {
        "label": "models",
        "kind": 5,
        "importPath": "hypertools.hypertools.tools.cluster",
        "description": "hypertools.hypertools.tools.cluster",
        "peekOfCode": "models = {\n    'KMeans': KMeans,\n    'MiniBatchKMeans': MiniBatchKMeans,\n    'AgglomerativeClustering': AgglomerativeClustering,\n    'FeatureAgglomeration': FeatureAgglomeration,\n    'Birch': Birch,\n    'SpectralClustering': SpectralClustering,\n}\ntry:\n    from hdbscan import HDBSCAN",
        "detail": "hypertools.hypertools.tools.cluster",
        "documentation": {}
    },
    {
        "label": "describe",
        "kind": 2,
        "importPath": "hypertools.hypertools.tools.describe",
        "description": "hypertools.hypertools.tools.describe",
        "peekOfCode": "def describe(x, reduce='IncrementalPCA', max_dims=None, show=True,\n             format_data=True):\n    \"\"\"\n    Create plot describing covariance with as a function of number of dimensions\n    This function correlates the raw data with reduced data to get a sense\n    for how well the data can be summarized with n dimensions.  Useful for\n    evaluating quality of dimensionality reduced plots.\n    Parameters\n    ----------\n    x : Numpy array, DataFrame or list of arrays/dfs",
        "detail": "hypertools.hypertools.tools.describe",
        "documentation": {}
    },
    {
        "label": "get_corr",
        "kind": 2,
        "importPath": "hypertools.hypertools.tools.describe",
        "description": "hypertools.hypertools.tools.describe",
        "peekOfCode": "def get_corr(reduced, alldims):\n    return pearsonr(alldims.ravel(), reduced.ravel())[0]\n@memoize\ndef get_cdist(x):\n    return cdist(x, x)",
        "detail": "hypertools.hypertools.tools.describe",
        "documentation": {}
    },
    {
        "label": "get_cdist",
        "kind": 2,
        "importPath": "hypertools.hypertools.tools.describe",
        "description": "hypertools.hypertools.tools.describe",
        "peekOfCode": "def get_cdist(x):\n    return cdist(x, x)",
        "detail": "hypertools.hypertools.tools.describe",
        "documentation": {}
    },
    {
        "label": "df2mat",
        "kind": 2,
        "importPath": "hypertools.hypertools.tools.df2mat",
        "description": "hypertools.hypertools.tools.df2mat",
        "peekOfCode": "def df2mat(data, return_labels=False):\n    \"\"\"\n    Transforms a Pandas DataFrame into a Numpy array with binarized text columns\n    This function transforms single-level df to an array so it can be plotted\n    with HyperTools.  Additionally, it uses the Pandas.Dataframe.get_dummies\n    function to transform text columns into binary vectors, or\n    'dummy variables'.\n    Parameters\n    ----------\n    data : A single-level Pandas DataFrame",
        "detail": "hypertools.hypertools.tools.df2mat",
        "documentation": {}
    },
    {
        "label": "format_data",
        "kind": 2,
        "importPath": "hypertools.hypertools.tools.format_data",
        "description": "hypertools.hypertools.tools.format_data",
        "peekOfCode": "def format_data(x, vectorizer='CountVectorizer',\n                semantic='LatentDirichletAllocation', corpus='wiki', ppca=True, text_align='hyper'):\n    \"\"\"\n    Formats data into a list of numpy arrays\n    This function is useful to identify rows of your array that contain missing\n    data or nans.  The returned indices can be used to remove the rows with\n    missing data, or label the missing data points that are interpolated\n    using PPCA.\n    Parameters\n    ----------",
        "detail": "hypertools.hypertools.tools.format_data",
        "documentation": {}
    },
    {
        "label": "fill_missing",
        "kind": 2,
        "importPath": "hypertools.hypertools.tools.format_data",
        "description": "hypertools.hypertools.tools.format_data",
        "peekOfCode": "def fill_missing(x):\n    \"\"\"Fill missing values using PPCA\"\"\"\n    # ppca if missing data\n    m = PPCA()\n    x_stacked = np.vstack(x)\n    m.fit(data=x_stacked)\n    x_pca = m.transform()\n    # if the whole row is missing, return nans\n    all_missing = [idx for idx, a in enumerate(x_stacked) if np.all(np.isnan(a))]\n    if len(all_missing)>0:",
        "detail": "hypertools.hypertools.tools.format_data",
        "documentation": {}
    },
    {
        "label": "load",
        "kind": 2,
        "importPath": "hypertools.hypertools.tools.load",
        "description": "hypertools.hypertools.tools.load",
        "peekOfCode": "def load(\n        dataset,\n        reduce=None,\n        ndims=None,\n        align=None,\n        normalize=None,\n        *,\n        legacy=False\n):\n    \"\"\"",
        "detail": "hypertools.hypertools.tools.load",
        "documentation": {}
    },
    {
        "label": "BASE_URL",
        "kind": 5,
        "importPath": "hypertools.hypertools.tools.load",
        "description": "hypertools.hypertools.tools.load",
        "peekOfCode": "BASE_URL = 'https://docs.google.com/uc?export=download'\nDATA_DIR = Path.home().joinpath('hypertools_data')\nEXAMPLE_DATA = {\n    'weights': '1ZXLao5Rxkr45KUMkv08Y1eAedTkpivsd',\n    'weights_avg': '1gfI1WB7QqogdYgdclqznhUfxsrhobueO',\n    'weights_sample': '1ub-xlYW1D_ASzbLcALcPJuhHUxRwHdIs',\n    'spiral': '1nHAusn2VsQinJk35xvJSd7CtWPC1uOwK',\n    'mushrooms': '12hmCIZp1tyUoPRHwpiAsm1GDBxiJS8ji',\n    'wiki': '1NUqm3svfu2rrFH04xmLbOh0u5WyTe9mh',\n    'sotus': '1J0MBhpRwdT2WChfWJ4HXYq6jU4XpyJPm',",
        "detail": "hypertools.hypertools.tools.load",
        "documentation": {}
    },
    {
        "label": "DATA_DIR",
        "kind": 5,
        "importPath": "hypertools.hypertools.tools.load",
        "description": "hypertools.hypertools.tools.load",
        "peekOfCode": "DATA_DIR = Path.home().joinpath('hypertools_data')\nEXAMPLE_DATA = {\n    'weights': '1ZXLao5Rxkr45KUMkv08Y1eAedTkpivsd',\n    'weights_avg': '1gfI1WB7QqogdYgdclqznhUfxsrhobueO',\n    'weights_sample': '1ub-xlYW1D_ASzbLcALcPJuhHUxRwHdIs',\n    'spiral': '1nHAusn2VsQinJk35xvJSd7CtWPC1uOwK',\n    'mushrooms': '12hmCIZp1tyUoPRHwpiAsm1GDBxiJS8ji',\n    'wiki': '1NUqm3svfu2rrFH04xmLbOh0u5WyTe9mh',\n    'sotus': '1J0MBhpRwdT2WChfWJ4HXYq6jU4XpyJPm',\n    'nips': '1FV7xT2hVgZ1sXfMvAdP1jRsK_dWhp49I',",
        "detail": "hypertools.hypertools.tools.load",
        "documentation": {}
    },
    {
        "label": "EXAMPLE_DATA",
        "kind": 5,
        "importPath": "hypertools.hypertools.tools.load",
        "description": "hypertools.hypertools.tools.load",
        "peekOfCode": "EXAMPLE_DATA = {\n    'weights': '1ZXLao5Rxkr45KUMkv08Y1eAedTkpivsd',\n    'weights_avg': '1gfI1WB7QqogdYgdclqznhUfxsrhobueO',\n    'weights_sample': '1ub-xlYW1D_ASzbLcALcPJuhHUxRwHdIs',\n    'spiral': '1nHAusn2VsQinJk35xvJSd7CtWPC1uOwK',\n    'mushrooms': '12hmCIZp1tyUoPRHwpiAsm1GDBxiJS8ji',\n    'wiki': '1NUqm3svfu2rrFH04xmLbOh0u5WyTe9mh',\n    'sotus': '1J0MBhpRwdT2WChfWJ4HXYq6jU4XpyJPm',\n    'nips': '1FV7xT2hVgZ1sXfMvAdP1jRsK_dWhp49I',\n    'wiki_model': '1T-UAU-6KVGUBcUWqz7yG59vXnThu9T0H',",
        "detail": "hypertools.hypertools.tools.load",
        "documentation": {}
    },
    {
        "label": "missing_inds",
        "kind": 2,
        "importPath": "hypertools.hypertools.tools.missing_inds",
        "description": "hypertools.hypertools.tools.missing_inds",
        "peekOfCode": "def missing_inds(x, format_data=True):\n    \"\"\"\n    Returns indices of missing data\n    This function is useful to identify rows of your array that contain missing\n    data or nans.  The returned indices can be used to remove the rows with\n    missing data, or label the missing data points that are interpolated\n    using PPCA.\n    Parameters\n    ----------\n    x : array or list of arrays",
        "detail": "hypertools.hypertools.tools.missing_inds",
        "documentation": {}
    },
    {
        "label": "normalize",
        "kind": 2,
        "importPath": "hypertools.hypertools.tools.normalize",
        "description": "hypertools.hypertools.tools.normalize",
        "peekOfCode": "def normalize(x, normalize='across', internal=False, format_data=True):\n    \"\"\"\n    Z-transform the columns or rows of an array, or list of arrays\n    This function normalizes the rows or columns of the input array(s).  This\n    can be useful because data reduction and machine learning techniques are\n    sensitive to scaling differences between features. By default, the function\n    is set to normalize 'across' the columns of all lists, but it can also\n    normalize the columns 'within' each individual list, or alternatively, for\n    each row in the array.\n    Parameters",
        "detail": "hypertools.hypertools.tools.normalize",
        "documentation": {}
    },
    {
        "label": "procrustes",
        "kind": 2,
        "importPath": "hypertools.hypertools.tools.procrustes",
        "description": "hypertools.hypertools.tools.procrustes",
        "peekOfCode": "def procrustes(source, target, scaling=True, reflection=True, reduction=False,\n               oblique=False, oblique_rcond=-1, format_data=True):\n    \"\"\"\n    Function to project from one space to another using Procrustean\n    transformation (shift + scaling + rotation + reflection).\n    The implementation of this function was based on the ProcrusteanMapper in\n    pyMVPA: https://github.com/PyMVPA/PyMVPA\n    See also: http://en.wikipedia.org/wiki/Procrustes_transformation\n    Parameters\n    ----------",
        "detail": "hypertools.hypertools.tools.procrustes",
        "documentation": {}
    },
    {
        "label": "reduce",
        "kind": 2,
        "importPath": "hypertools.hypertools.tools.reduce",
        "description": "hypertools.hypertools.tools.reduce",
        "peekOfCode": "def reduce(x, reduce='IncrementalPCA', ndims=None, normalize=None, align=None,\n           model=None, model_params=None, internal=False, format_data=True):\n    \"\"\"\n    Reduces dimensionality of an array, or list of arrays\n    Parameters\n    ----------\n    x : Numpy array or list of arrays\n        Dimensionality reduction using PCA is performed on this array.\n    reduce : str or dict\n        Decomposition/manifold learning model to use.  Models supported: PCA,",
        "detail": "hypertools.hypertools.tools.reduce",
        "documentation": {}
    },
    {
        "label": "reduce_list",
        "kind": 2,
        "importPath": "hypertools.hypertools.tools.reduce",
        "description": "hypertools.hypertools.tools.reduce",
        "peekOfCode": "def reduce_list(x, model):\n    \"\"\"Helper function to reduce a list of arrays\"\"\"\n    # Ensure all arrays are float64 for consistent handling\n    x = [np.asarray(arr, dtype=np.float64) for arr in x]\n    split = np.cumsum([len(xi) for xi in x])[:-1]\n    stacked = np.vstack(x)\n    # Handle potential NaN values\n    if np.any(np.isnan(stacked)):\n        warnings.warn('NaN values detected in input data. These may affect the reduction results.')\n    x_r = np.vsplit(model.fit_transform(stacked), split)",
        "detail": "hypertools.hypertools.tools.reduce",
        "documentation": {}
    },
    {
        "label": "models",
        "kind": 5,
        "importPath": "hypertools.hypertools.tools.reduce",
        "description": "hypertools.hypertools.tools.reduce",
        "peekOfCode": "models = {\n    'PCA': PCA,\n    'IncrementalPCA': IncrementalPCA,\n    'SparsePCA': SparsePCA,\n    'MiniBatchSparsePCA': MiniBatchSparsePCA,\n    'KernelPCA': KernelPCA,\n    'FastICA': FastICA,\n    'FactorAnalysis': FactorAnalysis,\n    'TruncatedSVD': TruncatedSVD,\n    'DictionaryLearning': DictionaryLearning,",
        "detail": "hypertools.hypertools.tools.reduce",
        "documentation": {}
    },
    {
        "label": "text2mat",
        "kind": 2,
        "importPath": "hypertools.hypertools.tools.text2mat",
        "description": "hypertools.hypertools.tools.text2mat",
        "peekOfCode": "def text2mat(data, vectorizer='CountVectorizer',\n             semantic='LatentDirichletAllocation', corpus='wiki'):\n    \"\"\"\n    Turns a list of text samples into a matrix using a vectorizer and a text model\n    Parameters\n    ----------\n    data : list (or list of lists) of text samples\n        The text data to transform\n    vectorizer : str, dict, class or class instance\n        The vectorizer to use. Built-in options are 'CountVectorizer' or",
        "detail": "hypertools.hypertools.tools.text2mat",
        "documentation": {}
    },
    {
        "label": "vectorizer_models",
        "kind": 5,
        "importPath": "hypertools.hypertools.tools.text2mat",
        "description": "hypertools.hypertools.tools.text2mat",
        "peekOfCode": "vectorizer_models = {\n    'CountVectorizer' : CountVectorizer,\n    'TfidfVectorizer' : TfidfVectorizer\n}\n# text models\ntexts = {\n    'LatentDirichletAllocation' : LatentDirichletAllocation,\n    'NMF' : NMF,\n}\n@memoize",
        "detail": "hypertools.hypertools.tools.text2mat",
        "documentation": {}
    },
    {
        "label": "texts",
        "kind": 5,
        "importPath": "hypertools.hypertools.tools.text2mat",
        "description": "hypertools.hypertools.tools.text2mat",
        "peekOfCode": "texts = {\n    'LatentDirichletAllocation' : LatentDirichletAllocation,\n    'NMF' : NMF,\n}\n@memoize\ndef text2mat(data, vectorizer='CountVectorizer',\n             semantic='LatentDirichletAllocation', corpus='wiki'):\n    \"\"\"\n    Turns a list of text samples into a matrix using a vectorizer and a text model\n    Parameters",
        "detail": "hypertools.hypertools.tools.text2mat",
        "documentation": {}
    },
    {
        "label": "__version__",
        "kind": 5,
        "importPath": "hypertools.hypertools.config",
        "description": "hypertools.hypertools.config",
        "peekOfCode": "__version__ = get_distribution('hypertools').version",
        "detail": "hypertools.hypertools.config",
        "documentation": {}
    },
    {
        "label": "DataGeometry",
        "kind": 6,
        "importPath": "hypertools.hypertools.datageometry",
        "description": "hypertools.hypertools.datageometry",
        "peekOfCode": "class DataGeometry(object):\n    \"\"\"\n    Hypertools data object class\n    A DataGeometry object contains the data, figure handles and transform\n    functions used to create a plot.  Note: this class should not be called\n    directly, but is used by the `hyp.plot` function to create a plot object.\n    Parameters\n    ----------\n    fig : matplotlib.Figure\n        The matplotlib figure handle for the plot",
        "detail": "hypertools.hypertools.datageometry",
        "documentation": {}
    },
    {
        "label": "test_procrustes",
        "kind": 2,
        "importPath": "hypertools.tests.test_align",
        "description": "hypertools.tests.test_align",
        "peekOfCode": "def test_procrustes():\n    rot = np.array([[-0.89433495, -0.44719485, -0.01348182],\n           [-0.43426149,  0.87492975, -0.21427761],\n           [-0.10761949,  0.18578133,  0.97667976]])\n    data2 = np.dot(data1, rot)\n    result = align([data1,data2])\n    assert np.allclose(result[0],result[1])\ndef test_hyper():\n    rot = np.array([[-0.89433495, -0.44719485, -0.01348182],\n           [-0.43426149,  0.87492975, -0.21427761],",
        "detail": "hypertools.tests.test_align",
        "documentation": {}
    },
    {
        "label": "test_hyper",
        "kind": 2,
        "importPath": "hypertools.tests.test_align",
        "description": "hypertools.tests.test_align",
        "peekOfCode": "def test_hyper():\n    rot = np.array([[-0.89433495, -0.44719485, -0.01348182],\n           [-0.43426149,  0.87492975, -0.21427761],\n           [-0.10761949,  0.18578133,  0.97667976]])\n    data2 = np.dot(data1, rot)\n    result = align([data1,data2], align='hyper')\n    assert np.allclose(result[0],result[1], rtol=1) #note: this tolerance is probably too high, but fails at anything lower\ndef test_SRM():\n    rot = np.array([[-0.89433495, -0.44719485, -0.01348182],\n           [-0.43426149,  0.87492975, -0.21427761],",
        "detail": "hypertools.tests.test_align",
        "documentation": {}
    },
    {
        "label": "test_SRM",
        "kind": 2,
        "importPath": "hypertools.tests.test_align",
        "description": "hypertools.tests.test_align",
        "peekOfCode": "def test_SRM():\n    rot = np.array([[-0.89433495, -0.44719485, -0.01348182],\n           [-0.43426149,  0.87492975, -0.21427761],\n           [-0.10761949,  0.18578133,  0.97667976]])\n    data2 = np.dot(data1, rot)\n    result = align([data1,data2], align='SRM')\n    assert np.allclose(result[0],result[1], rtol=1)\ndef test_align_shapes():\n    # Should return data with the same shape as input data\n    aligned = align(weights)",
        "detail": "hypertools.tests.test_align",
        "documentation": {}
    },
    {
        "label": "test_align_shapes",
        "kind": 2,
        "importPath": "hypertools.tests.test_align",
        "description": "hypertools.tests.test_align",
        "peekOfCode": "def test_align_shapes():\n    # Should return data with the same shape as input data\n    aligned = align(weights)\n    assert all(al.shape == wt.shape for al, wt in zip(aligned, weights))\ndef test_align_geo():\n    aligned = align(geo)\n    assert np.allclose(aligned[0], aligned[1])",
        "detail": "hypertools.tests.test_align",
        "documentation": {}
    },
    {
        "label": "test_align_geo",
        "kind": 2,
        "importPath": "hypertools.tests.test_align",
        "description": "hypertools.tests.test_align",
        "peekOfCode": "def test_align_geo():\n    aligned = align(geo)\n    assert np.allclose(aligned[0], aligned[1])",
        "detail": "hypertools.tests.test_align",
        "documentation": {}
    },
    {
        "label": "weights",
        "kind": 5,
        "importPath": "hypertools.tests.test_align",
        "description": "hypertools.tests.test_align",
        "peekOfCode": "weights = [np.random.rand(10, 300) for i in range(3)]\ngeo = load('spiral')\ndata1 = geo.get_data()[0]\ndef test_procrustes():\n    rot = np.array([[-0.89433495, -0.44719485, -0.01348182],\n           [-0.43426149,  0.87492975, -0.21427761],\n           [-0.10761949,  0.18578133,  0.97667976]])\n    data2 = np.dot(data1, rot)\n    result = align([data1,data2])\n    assert np.allclose(result[0],result[1])",
        "detail": "hypertools.tests.test_align",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.tests.test_align",
        "description": "hypertools.tests.test_align",
        "peekOfCode": "geo = load('spiral')\ndata1 = geo.get_data()[0]\ndef test_procrustes():\n    rot = np.array([[-0.89433495, -0.44719485, -0.01348182],\n           [-0.43426149,  0.87492975, -0.21427761],\n           [-0.10761949,  0.18578133,  0.97667976]])\n    data2 = np.dot(data1, rot)\n    result = align([data1,data2])\n    assert np.allclose(result[0],result[1])\ndef test_hyper():",
        "detail": "hypertools.tests.test_align",
        "documentation": {}
    },
    {
        "label": "data1",
        "kind": 5,
        "importPath": "hypertools.tests.test_align",
        "description": "hypertools.tests.test_align",
        "peekOfCode": "data1 = geo.get_data()[0]\ndef test_procrustes():\n    rot = np.array([[-0.89433495, -0.44719485, -0.01348182],\n           [-0.43426149,  0.87492975, -0.21427761],\n           [-0.10761949,  0.18578133,  0.97667976]])\n    data2 = np.dot(data1, rot)\n    result = align([data1,data2])\n    assert np.allclose(result[0],result[1])\ndef test_hyper():\n    rot = np.array([[-0.89433495, -0.44719485, -0.01348182],",
        "detail": "hypertools.tests.test_align",
        "documentation": {}
    },
    {
        "label": "test_cluster_n_clusters",
        "kind": 2,
        "importPath": "hypertools.tests.test_cluster",
        "description": "hypertools.tests.test_cluster",
        "peekOfCode": "def test_cluster_n_clusters():\n    assert len(set(labels))==2\ndef test_cluster_returns_list():\n    assert type(labels) is list\ndef test_cluster_hdbscan():\n    try:\n        from hdbscan import HDBSCAN\n        _has_hdbscan = True\n    except:\n        _has_hdbscan = False",
        "detail": "hypertools.tests.test_cluster",
        "documentation": {}
    },
    {
        "label": "test_cluster_returns_list",
        "kind": 2,
        "importPath": "hypertools.tests.test_cluster",
        "description": "hypertools.tests.test_cluster",
        "peekOfCode": "def test_cluster_returns_list():\n    assert type(labels) is list\ndef test_cluster_hdbscan():\n    try:\n        from hdbscan import HDBSCAN\n        _has_hdbscan = True\n    except:\n        _has_hdbscan = False\n    if _has_hdbscan:\n        hdbscan_labels = cluster(data, cluster='HDBSCAN')",
        "detail": "hypertools.tests.test_cluster",
        "documentation": {}
    },
    {
        "label": "test_cluster_hdbscan",
        "kind": 2,
        "importPath": "hypertools.tests.test_cluster",
        "description": "hypertools.tests.test_cluster",
        "peekOfCode": "def test_cluster_hdbscan():\n    try:\n        from hdbscan import HDBSCAN\n        _has_hdbscan = True\n    except:\n        _has_hdbscan = False\n    if _has_hdbscan:\n        hdbscan_labels = cluster(data, cluster='HDBSCAN')\n        assert len(set(hdbscan_labels)) == 2\n    else:",
        "detail": "hypertools.tests.test_cluster",
        "documentation": {}
    },
    {
        "label": "cluster1",
        "kind": 5,
        "importPath": "hypertools.tests.test_cluster",
        "description": "hypertools.tests.test_cluster",
        "peekOfCode": "cluster1 = np.random.multivariate_normal(np.zeros(3), np.eye(3), size=100)\ncluster2 = np.random.multivariate_normal(np.zeros(3)+100, np.eye(3), size=100)\ndata = np.vstack([cluster1, cluster2])\nlabels = cluster(data, n_clusters=2)\ndef test_cluster_n_clusters():\n    assert len(set(labels))==2\ndef test_cluster_returns_list():\n    assert type(labels) is list\ndef test_cluster_hdbscan():\n    try:",
        "detail": "hypertools.tests.test_cluster",
        "documentation": {}
    },
    {
        "label": "cluster2",
        "kind": 5,
        "importPath": "hypertools.tests.test_cluster",
        "description": "hypertools.tests.test_cluster",
        "peekOfCode": "cluster2 = np.random.multivariate_normal(np.zeros(3)+100, np.eye(3), size=100)\ndata = np.vstack([cluster1, cluster2])\nlabels = cluster(data, n_clusters=2)\ndef test_cluster_n_clusters():\n    assert len(set(labels))==2\ndef test_cluster_returns_list():\n    assert type(labels) is list\ndef test_cluster_hdbscan():\n    try:\n        from hdbscan import HDBSCAN",
        "detail": "hypertools.tests.test_cluster",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "hypertools.tests.test_cluster",
        "description": "hypertools.tests.test_cluster",
        "peekOfCode": "data = np.vstack([cluster1, cluster2])\nlabels = cluster(data, n_clusters=2)\ndef test_cluster_n_clusters():\n    assert len(set(labels))==2\ndef test_cluster_returns_list():\n    assert type(labels) is list\ndef test_cluster_hdbscan():\n    try:\n        from hdbscan import HDBSCAN\n        _has_hdbscan = True",
        "detail": "hypertools.tests.test_cluster",
        "documentation": {}
    },
    {
        "label": "labels",
        "kind": 5,
        "importPath": "hypertools.tests.test_cluster",
        "description": "hypertools.tests.test_cluster",
        "peekOfCode": "labels = cluster(data, n_clusters=2)\ndef test_cluster_n_clusters():\n    assert len(set(labels))==2\ndef test_cluster_returns_list():\n    assert type(labels) is list\ndef test_cluster_hdbscan():\n    try:\n        from hdbscan import HDBSCAN\n        _has_hdbscan = True\n    except:",
        "detail": "hypertools.tests.test_cluster",
        "documentation": {}
    },
    {
        "label": "test_describe_data_is_dict",
        "kind": 2,
        "importPath": "hypertools.tests.test_describe",
        "description": "hypertools.tests.test_describe",
        "peekOfCode": "def test_describe_data_is_dict():\n    result = describe(data, reduce='PCA', show=False)\n    assert type(result) is dict\ndef test_describe_geo():\n    geo = plot(data, show=False)\n    result = describe(geo, reduce='PCA', show=False)\n    assert type(result) is dict",
        "detail": "hypertools.tests.test_describe",
        "documentation": {}
    },
    {
        "label": "test_describe_geo",
        "kind": 2,
        "importPath": "hypertools.tests.test_describe",
        "description": "hypertools.tests.test_describe",
        "peekOfCode": "def test_describe_geo():\n    geo = plot(data, show=False)\n    result = describe(geo, reduce='PCA', show=False)\n    assert type(result) is dict",
        "detail": "hypertools.tests.test_describe",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "hypertools.tests.test_describe",
        "description": "hypertools.tests.test_describe",
        "peekOfCode": "data = np.random.multivariate_normal(np.zeros(10), np.eye(10), size=100)\ndef test_describe_data_is_dict():\n    result = describe(data, reduce='PCA', show=False)\n    assert type(result) is dict\ndef test_describe_geo():\n    geo = plot(data, show=False)\n    result = describe(geo, reduce='PCA', show=False)\n    assert type(result) is dict",
        "detail": "hypertools.tests.test_describe",
        "documentation": {}
    },
    {
        "label": "test_np_array",
        "kind": 2,
        "importPath": "hypertools.tests.test_format_data",
        "description": "hypertools.tests.test_format_data",
        "peekOfCode": "def test_np_array():\n    data = np.random.rand(100,10)\n    assert isinstance(format_data(data), list)\n    assert isinstance(format_data(data)[0], np.ndarray)\ndef test_df():\n    data = pd.DataFrame(np.random.rand(100,10))\n    assert isinstance(format_data(data), list)\n    assert isinstance(format_data(data)[0], np.ndarray)\ndef test_text():\n    data = ['here is some test text', 'and a little more', 'and more']",
        "detail": "hypertools.tests.test_format_data",
        "documentation": {}
    },
    {
        "label": "test_df",
        "kind": 2,
        "importPath": "hypertools.tests.test_format_data",
        "description": "hypertools.tests.test_format_data",
        "peekOfCode": "def test_df():\n    data = pd.DataFrame(np.random.rand(100,10))\n    assert isinstance(format_data(data), list)\n    assert isinstance(format_data(data)[0], np.ndarray)\ndef test_text():\n    data = ['here is some test text', 'and a little more', 'and more']\n    assert isinstance(format_data(data), list)\n    assert isinstance(format_data(data)[0], np.ndarray)\ndef test_str():\n    res = format_data('here is some test text')",
        "detail": "hypertools.tests.test_format_data",
        "documentation": {}
    },
    {
        "label": "test_text",
        "kind": 2,
        "importPath": "hypertools.tests.test_format_data",
        "description": "hypertools.tests.test_format_data",
        "peekOfCode": "def test_text():\n    data = ['here is some test text', 'and a little more', 'and more']\n    assert isinstance(format_data(data), list)\n    assert isinstance(format_data(data)[0], np.ndarray)\ndef test_str():\n    res = format_data('here is some test text')\n    assert isinstance(res, list)\n    assert isinstance(res[0], np.ndarray)\ndef test_mixed_list():\n    mat = np.random.rand(3,20)",
        "detail": "hypertools.tests.test_format_data",
        "documentation": {}
    },
    {
        "label": "test_str",
        "kind": 2,
        "importPath": "hypertools.tests.test_format_data",
        "description": "hypertools.tests.test_format_data",
        "peekOfCode": "def test_str():\n    res = format_data('here is some test text')\n    assert isinstance(res, list)\n    assert isinstance(res[0], np.ndarray)\ndef test_mixed_list():\n    mat = np.random.rand(3,20)\n    df = pd.DataFrame(np.random.rand(3,20))\n    text = ['here is some test text', 'and a little more', 'and more']\n    string = 'a string'\n    res = format_data([mat, df, text, string])",
        "detail": "hypertools.tests.test_format_data",
        "documentation": {}
    },
    {
        "label": "test_mixed_list",
        "kind": 2,
        "importPath": "hypertools.tests.test_format_data",
        "description": "hypertools.tests.test_format_data",
        "peekOfCode": "def test_mixed_list():\n    mat = np.random.rand(3,20)\n    df = pd.DataFrame(np.random.rand(3,20))\n    text = ['here is some test text', 'and a little more', 'and more']\n    string = 'a string'\n    res = format_data([mat, df, text, string])\n    assert isinstance(res, list)\n    assert all(map(lambda x: isinstance(x, np.ndarray), res))\ndef test_geo():\n    geo = plot(np.random.rand(100,10), show=False)",
        "detail": "hypertools.tests.test_format_data",
        "documentation": {}
    },
    {
        "label": "test_geo",
        "kind": 2,
        "importPath": "hypertools.tests.test_format_data",
        "description": "hypertools.tests.test_format_data",
        "peekOfCode": "def test_geo():\n    geo = plot(np.random.rand(100,10), show=False)\n    assert isinstance(format_data(geo), list)\n    assert isinstance(format_data(geo)[0], np.ndarray)\ndef test_missing_data():\n    data = np.random.rand(100,10)\n    data[0][0]=np.nan\n    geo = plot(data, show=False)\n    assert isinstance(format_data(geo), list)\n    assert isinstance(format_data(geo)[0], np.ndarray)",
        "detail": "hypertools.tests.test_format_data",
        "documentation": {}
    },
    {
        "label": "test_missing_data",
        "kind": 2,
        "importPath": "hypertools.tests.test_format_data",
        "description": "hypertools.tests.test_format_data",
        "peekOfCode": "def test_missing_data():\n    data = np.random.rand(100,10)\n    data[0][0]=np.nan\n    geo = plot(data, show=False)\n    assert isinstance(format_data(geo), list)\n    assert isinstance(format_data(geo)[0], np.ndarray)\ndef test_force_align():\n    mat = np.random.rand(4, 3)\n    df = pd.DataFrame(np.random.rand(4, 3))\n    text = ['here is some test text', 'and a little more', 'and more', 'just a bit more']",
        "detail": "hypertools.tests.test_format_data",
        "documentation": {}
    },
    {
        "label": "test_force_align",
        "kind": 2,
        "importPath": "hypertools.tests.test_format_data",
        "description": "hypertools.tests.test_format_data",
        "peekOfCode": "def test_force_align():\n    mat = np.random.rand(4, 3)\n    df = pd.DataFrame(np.random.rand(4, 3))\n    text = ['here is some test text', 'and a little more', 'and more', 'just a bit more']\n    res = format_data([mat, df, text])\n    assert isinstance(res, list)\n    assert all(map(lambda x: isinstance(x, np.ndarray), res))\n    assert all(map(lambda x: x.shape[1] == 50, res))",
        "detail": "hypertools.tests.test_format_data",
        "documentation": {}
    },
    {
        "label": "test_geo",
        "kind": 2,
        "importPath": "hypertools.tests.test_geo",
        "description": "hypertools.tests.test_geo",
        "peekOfCode": "def test_geo():\n    assert isinstance(geo, DataGeometry)\ndef test_geo_data():\n    assert isinstance(geo.data, list)\ndef test_geo_get_data():\n    assert np.array_equal(data[0], geo.get_data()[0])\ndef test_geo_get_formatted_data():\n    assert np.array_equal(data[0], geo.get_formatted_data()[0])\ndef test_geo_data_dims():\n    assert (geo.data[0].shape[0]==100) and (geo.data[0].shape[1]==4)",
        "detail": "hypertools.tests.test_geo",
        "documentation": {}
    },
    {
        "label": "test_geo_data",
        "kind": 2,
        "importPath": "hypertools.tests.test_geo",
        "description": "hypertools.tests.test_geo",
        "peekOfCode": "def test_geo_data():\n    assert isinstance(geo.data, list)\ndef test_geo_get_data():\n    assert np.array_equal(data[0], geo.get_data()[0])\ndef test_geo_get_formatted_data():\n    assert np.array_equal(data[0], geo.get_formatted_data()[0])\ndef test_geo_data_dims():\n    assert (geo.data[0].shape[0]==100) and (geo.data[0].shape[1]==4)\ndef test_geo_kwargs():\n    assert isinstance(geo.kwargs, dict)",
        "detail": "hypertools.tests.test_geo",
        "documentation": {}
    },
    {
        "label": "test_geo_get_data",
        "kind": 2,
        "importPath": "hypertools.tests.test_geo",
        "description": "hypertools.tests.test_geo",
        "peekOfCode": "def test_geo_get_data():\n    assert np.array_equal(data[0], geo.get_data()[0])\ndef test_geo_get_formatted_data():\n    assert np.array_equal(data[0], geo.get_formatted_data()[0])\ndef test_geo_data_dims():\n    assert (geo.data[0].shape[0]==100) and (geo.data[0].shape[1]==4)\ndef test_geo_kwargs():\n    assert isinstance(geo.kwargs, dict)\ndef test_geo_reduce():\n    assert isinstance(geo.reduce, dict)",
        "detail": "hypertools.tests.test_geo",
        "documentation": {}
    },
    {
        "label": "test_geo_get_formatted_data",
        "kind": 2,
        "importPath": "hypertools.tests.test_geo",
        "description": "hypertools.tests.test_geo",
        "peekOfCode": "def test_geo_get_formatted_data():\n    assert np.array_equal(data[0], geo.get_formatted_data()[0])\ndef test_geo_data_dims():\n    assert (geo.data[0].shape[0]==100) and (geo.data[0].shape[1]==4)\ndef test_geo_kwargs():\n    assert isinstance(geo.kwargs, dict)\ndef test_geo_reduce():\n    assert isinstance(geo.reduce, dict)\ndef test_geo_xform_data_dims1():\n    assert (geo.xform_data[0].shape[0]==100) and (geo.xform_data[0].shape[1]==3)",
        "detail": "hypertools.tests.test_geo",
        "documentation": {}
    },
    {
        "label": "test_geo_data_dims",
        "kind": 2,
        "importPath": "hypertools.tests.test_geo",
        "description": "hypertools.tests.test_geo",
        "peekOfCode": "def test_geo_data_dims():\n    assert (geo.data[0].shape[0]==100) and (geo.data[0].shape[1]==4)\ndef test_geo_kwargs():\n    assert isinstance(geo.kwargs, dict)\ndef test_geo_reduce():\n    assert isinstance(geo.reduce, dict)\ndef test_geo_xform_data_dims1():\n    assert (geo.xform_data[0].shape[0]==100) and (geo.xform_data[0].shape[1]==3)\ndef test_geo_xform_data_dims2():\n    geo = plot(data, ndims=4, show=False)",
        "detail": "hypertools.tests.test_geo",
        "documentation": {}
    },
    {
        "label": "test_geo_kwargs",
        "kind": 2,
        "importPath": "hypertools.tests.test_geo",
        "description": "hypertools.tests.test_geo",
        "peekOfCode": "def test_geo_kwargs():\n    assert isinstance(geo.kwargs, dict)\ndef test_geo_reduce():\n    assert isinstance(geo.reduce, dict)\ndef test_geo_xform_data_dims1():\n    assert (geo.xform_data[0].shape[0]==100) and (geo.xform_data[0].shape[1]==3)\ndef test_geo_xform_data_dims2():\n    geo = plot(data, ndims=4, show=False)\n    assert (geo.xform_data[0].shape[0]==100) and (geo.xform_data[0].shape[1]==4)\ndef test_geo_transform():",
        "detail": "hypertools.tests.test_geo",
        "documentation": {}
    },
    {
        "label": "test_geo_reduce",
        "kind": 2,
        "importPath": "hypertools.tests.test_geo",
        "description": "hypertools.tests.test_geo",
        "peekOfCode": "def test_geo_reduce():\n    assert isinstance(geo.reduce, dict)\ndef test_geo_xform_data_dims1():\n    assert (geo.xform_data[0].shape[0]==100) and (geo.xform_data[0].shape[1]==3)\ndef test_geo_xform_data_dims2():\n    geo = plot(data, ndims=4, show=False)\n    assert (geo.xform_data[0].shape[0]==100) and (geo.xform_data[0].shape[1]==4)\ndef test_geo_transform():\n    assert isinstance(geo.transform(data), list)\ndef test_geo_transform_dims():",
        "detail": "hypertools.tests.test_geo",
        "documentation": {}
    },
    {
        "label": "test_geo_xform_data_dims1",
        "kind": 2,
        "importPath": "hypertools.tests.test_geo",
        "description": "hypertools.tests.test_geo",
        "peekOfCode": "def test_geo_xform_data_dims1():\n    assert (geo.xform_data[0].shape[0]==100) and (geo.xform_data[0].shape[1]==3)\ndef test_geo_xform_data_dims2():\n    geo = plot(data, ndims=4, show=False)\n    assert (geo.xform_data[0].shape[0]==100) and (geo.xform_data[0].shape[1]==4)\ndef test_geo_transform():\n    assert isinstance(geo.transform(data), list)\ndef test_geo_transform_dims():\n    assert geo.transform(data)[0].shape[1]==3\ndef test_geo_plot():",
        "detail": "hypertools.tests.test_geo",
        "documentation": {}
    },
    {
        "label": "test_geo_xform_data_dims2",
        "kind": 2,
        "importPath": "hypertools.tests.test_geo",
        "description": "hypertools.tests.test_geo",
        "peekOfCode": "def test_geo_xform_data_dims2():\n    geo = plot(data, ndims=4, show=False)\n    assert (geo.xform_data[0].shape[0]==100) and (geo.xform_data[0].shape[1]==4)\ndef test_geo_transform():\n    assert isinstance(geo.transform(data), list)\ndef test_geo_transform_dims():\n    assert geo.transform(data)[0].shape[1]==3\ndef test_geo_plot():\n    assert isinstance(geo.plot(show=False), DataGeometry)\ndef test_geo_text_data():",
        "detail": "hypertools.tests.test_geo",
        "documentation": {}
    },
    {
        "label": "test_geo_transform",
        "kind": 2,
        "importPath": "hypertools.tests.test_geo",
        "description": "hypertools.tests.test_geo",
        "peekOfCode": "def test_geo_transform():\n    assert isinstance(geo.transform(data), list)\ndef test_geo_transform_dims():\n    assert geo.transform(data)[0].shape[1]==3\ndef test_geo_plot():\n    assert isinstance(geo.plot(show=False), DataGeometry)\ndef test_geo_text_data():\n    data = [['i like cats alot', 'cats r pretty cool', 'cats are better than dogs'],\n            ['dogs rule the haus', 'dogs are my jam', 'dogs are a mans best friend']]\n    geo = plot(data, show=False)",
        "detail": "hypertools.tests.test_geo",
        "documentation": {}
    },
    {
        "label": "test_geo_transform_dims",
        "kind": 2,
        "importPath": "hypertools.tests.test_geo",
        "description": "hypertools.tests.test_geo",
        "peekOfCode": "def test_geo_transform_dims():\n    assert geo.transform(data)[0].shape[1]==3\ndef test_geo_plot():\n    assert isinstance(geo.plot(show=False), DataGeometry)\ndef test_geo_text_data():\n    data = [['i like cats alot', 'cats r pretty cool', 'cats are better than dogs'],\n            ['dogs rule the haus', 'dogs are my jam', 'dogs are a mans best friend']]\n    geo = plot(data, show=False)\n    assert isinstance(geo, DataGeometry)\n    assert geo.transform(data)[0].shape[1]==3",
        "detail": "hypertools.tests.test_geo",
        "documentation": {}
    },
    {
        "label": "test_geo_plot",
        "kind": 2,
        "importPath": "hypertools.tests.test_geo",
        "description": "hypertools.tests.test_geo",
        "peekOfCode": "def test_geo_plot():\n    assert isinstance(geo.plot(show=False), DataGeometry)\ndef test_geo_text_data():\n    data = [['i like cats alot', 'cats r pretty cool', 'cats are better than dogs'],\n            ['dogs rule the haus', 'dogs are my jam', 'dogs are a mans best friend']]\n    geo = plot(data, show=False)\n    assert isinstance(geo, DataGeometry)\n    assert geo.transform(data)[0].shape[1]==3\n    assert geo.semantic == 'LatentDirichletAllocation'\n    assert isinstance(geo.plot(show=False), DataGeometry)",
        "detail": "hypertools.tests.test_geo",
        "documentation": {}
    },
    {
        "label": "test_geo_text_data",
        "kind": 2,
        "importPath": "hypertools.tests.test_geo",
        "description": "hypertools.tests.test_geo",
        "peekOfCode": "def test_geo_text_data():\n    data = [['i like cats alot', 'cats r pretty cool', 'cats are better than dogs'],\n            ['dogs rule the haus', 'dogs are my jam', 'dogs are a mans best friend']]\n    geo = plot(data, show=False)\n    assert isinstance(geo, DataGeometry)\n    assert geo.transform(data)[0].shape[1]==3\n    assert geo.semantic == 'LatentDirichletAllocation'\n    assert isinstance(geo.plot(show=False), DataGeometry)\ndef test_geo_text_data_marker():\n    data = [['i like cats alot', 'cats r pretty cool', 'cats are better than dogs'],",
        "detail": "hypertools.tests.test_geo",
        "documentation": {}
    },
    {
        "label": "test_geo_text_data_marker",
        "kind": 2,
        "importPath": "hypertools.tests.test_geo",
        "description": "hypertools.tests.test_geo",
        "peekOfCode": "def test_geo_text_data_marker():\n    data = [['i like cats alot', 'cats r pretty cool', 'cats are better than dogs'],\n            ['dogs rule the haus', 'dogs are my jam', 'dogs are a mans best friend']]\n    geo = plot(data, '.', show=False)\n    assert isinstance(geo, DataGeometry)\n    assert geo.transform(data)[0].shape[1]==3\n    assert geo.semantic == 'LatentDirichletAllocation'\n    assert isinstance(geo.plot(show=False), DataGeometry)",
        "detail": "hypertools.tests.test_geo",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "hypertools.tests.test_geo",
        "description": "hypertools.tests.test_geo",
        "peekOfCode": "data = [np.random.multivariate_normal(np.zeros(4), np.eye(4), size=100) for i\n        in range(2)]\ngeo = plot(data, show=False)\ndef test_geo():\n    assert isinstance(geo, DataGeometry)\ndef test_geo_data():\n    assert isinstance(geo.data, list)\ndef test_geo_get_data():\n    assert np.array_equal(data[0], geo.get_data()[0])\ndef test_geo_get_formatted_data():",
        "detail": "hypertools.tests.test_geo",
        "documentation": {}
    },
    {
        "label": "geo",
        "kind": 5,
        "importPath": "hypertools.tests.test_geo",
        "description": "hypertools.tests.test_geo",
        "peekOfCode": "geo = plot(data, show=False)\ndef test_geo():\n    assert isinstance(geo, DataGeometry)\ndef test_geo_data():\n    assert isinstance(geo.data, list)\ndef test_geo_get_data():\n    assert np.array_equal(data[0], geo.get_data()[0])\ndef test_geo_get_formatted_data():\n    assert np.array_equal(data[0], geo.get_formatted_data()[0])\ndef test_geo_data_dims():",
        "detail": "hypertools.tests.test_geo",
        "documentation": {}
    },
    {
        "label": "test_center",
        "kind": 2,
        "importPath": "hypertools.tests.test_helpers",
        "description": "hypertools.tests.test_helpers",
        "peekOfCode": "def test_center():\n    assert np.array_equal(helpers.center([np.array([[0,0,0],[1,1,1]])]),[np.array([[-0.5,-0.5,-0.5],[0.5,0.5,0.5]])])\ndef test_group_by_category_ints():\n    assert helpers.group_by_category([1, 1, 2, 3])==[0, 0, 1, 2]\ndef test_group_by_category_str():\n    assert helpers.group_by_category(['a', 'a', 'c', 'b'])==[0, 0, 1, 2]\ndef test_vals2colors_list():\n    assert np.allclose(helpers.vals2colors([0, .5, 1]),[(0.9629680891964629, 0.9860207612456747, 0.9360092272202999), (0.7944636678200693, 0.9194156093810073, 0.7700884275278739), (0.4740484429065744, 0.7953863898500577, 0.7713956170703576)])\ndef test_vals2colors_list_of_lists():\n    assert np.allclose(helpers.vals2colors([[0],[.5],[1]]),[(0.9629680891964629, 0.9860207612456747, 0.9360092272202999), (0.7944636678200693, 0.9194156093810073, 0.7700884275278739), (0.4740484429065744, 0.7953863898500577, 0.7713956170703576)])",
        "detail": "hypertools.tests.test_helpers",
        "documentation": {}
    },
    {
        "label": "test_group_by_category_ints",
        "kind": 2,
        "importPath": "hypertools.tests.test_helpers",
        "description": "hypertools.tests.test_helpers",
        "peekOfCode": "def test_group_by_category_ints():\n    assert helpers.group_by_category([1, 1, 2, 3])==[0, 0, 1, 2]\ndef test_group_by_category_str():\n    assert helpers.group_by_category(['a', 'a', 'c', 'b'])==[0, 0, 1, 2]\ndef test_vals2colors_list():\n    assert np.allclose(helpers.vals2colors([0, .5, 1]),[(0.9629680891964629, 0.9860207612456747, 0.9360092272202999), (0.7944636678200693, 0.9194156093810073, 0.7700884275278739), (0.4740484429065744, 0.7953863898500577, 0.7713956170703576)])\ndef test_vals2colors_list_of_lists():\n    assert np.allclose(helpers.vals2colors([[0],[.5],[1]]),[(0.9629680891964629, 0.9860207612456747, 0.9360092272202999), (0.7944636678200693, 0.9194156093810073, 0.7700884275278739), (0.4740484429065744, 0.7953863898500577, 0.7713956170703576)])\ndef test_vals2bins():\n    assert helpers.vals2bins([0,1,2])==[0, 33, 66]",
        "detail": "hypertools.tests.test_helpers",
        "documentation": {}
    },
    {
        "label": "test_group_by_category_str",
        "kind": 2,
        "importPath": "hypertools.tests.test_helpers",
        "description": "hypertools.tests.test_helpers",
        "peekOfCode": "def test_group_by_category_str():\n    assert helpers.group_by_category(['a', 'a', 'c', 'b'])==[0, 0, 1, 2]\ndef test_vals2colors_list():\n    assert np.allclose(helpers.vals2colors([0, .5, 1]),[(0.9629680891964629, 0.9860207612456747, 0.9360092272202999), (0.7944636678200693, 0.9194156093810073, 0.7700884275278739), (0.4740484429065744, 0.7953863898500577, 0.7713956170703576)])\ndef test_vals2colors_list_of_lists():\n    assert np.allclose(helpers.vals2colors([[0],[.5],[1]]),[(0.9629680891964629, 0.9860207612456747, 0.9360092272202999), (0.7944636678200693, 0.9194156093810073, 0.7700884275278739), (0.4740484429065744, 0.7953863898500577, 0.7713956170703576)])\ndef test_vals2bins():\n    assert helpers.vals2bins([0,1,2])==[0, 33, 66]\ndef test_interp_array():\n    assert np.allclose(helpers.interp_array(np.array([1,2,3])),np.linspace(1,2.9,20))",
        "detail": "hypertools.tests.test_helpers",
        "documentation": {}
    },
    {
        "label": "test_vals2colors_list",
        "kind": 2,
        "importPath": "hypertools.tests.test_helpers",
        "description": "hypertools.tests.test_helpers",
        "peekOfCode": "def test_vals2colors_list():\n    assert np.allclose(helpers.vals2colors([0, .5, 1]),[(0.9629680891964629, 0.9860207612456747, 0.9360092272202999), (0.7944636678200693, 0.9194156093810073, 0.7700884275278739), (0.4740484429065744, 0.7953863898500577, 0.7713956170703576)])\ndef test_vals2colors_list_of_lists():\n    assert np.allclose(helpers.vals2colors([[0],[.5],[1]]),[(0.9629680891964629, 0.9860207612456747, 0.9360092272202999), (0.7944636678200693, 0.9194156093810073, 0.7700884275278739), (0.4740484429065744, 0.7953863898500577, 0.7713956170703576)])\ndef test_vals2bins():\n    assert helpers.vals2bins([0,1,2])==[0, 33, 66]\ndef test_interp_array():\n    assert np.allclose(helpers.interp_array(np.array([1,2,3])),np.linspace(1,2.9,20))\ndef test_interp_array_list():\n    assert np.allclose(helpers.interp_array_list(np.array([[1,2,3],[1,2,3]])),[np.linspace(1,2.9,20)] * 2)",
        "detail": "hypertools.tests.test_helpers",
        "documentation": {}
    },
    {
        "label": "test_vals2colors_list_of_lists",
        "kind": 2,
        "importPath": "hypertools.tests.test_helpers",
        "description": "hypertools.tests.test_helpers",
        "peekOfCode": "def test_vals2colors_list_of_lists():\n    assert np.allclose(helpers.vals2colors([[0],[.5],[1]]),[(0.9629680891964629, 0.9860207612456747, 0.9360092272202999), (0.7944636678200693, 0.9194156093810073, 0.7700884275278739), (0.4740484429065744, 0.7953863898500577, 0.7713956170703576)])\ndef test_vals2bins():\n    assert helpers.vals2bins([0,1,2])==[0, 33, 66]\ndef test_interp_array():\n    assert np.allclose(helpers.interp_array(np.array([1,2,3])),np.linspace(1,2.9,20))\ndef test_interp_array_list():\n    assert np.allclose(helpers.interp_array_list(np.array([[1,2,3],[1,2,3]])),[np.linspace(1,2.9,20)] * 2)\ndef test_interp_array_list_interpval():\n    assert helpers.interp_array_list([np.array([[1,2,3],[1,2,3],[1,2,3]])],interp_val=10)[0].shape[0]==20",
        "detail": "hypertools.tests.test_helpers",
        "documentation": {}
    },
    {
        "label": "test_vals2bins",
        "kind": 2,
        "importPath": "hypertools.tests.test_helpers",
        "description": "hypertools.tests.test_helpers",
        "peekOfCode": "def test_vals2bins():\n    assert helpers.vals2bins([0,1,2])==[0, 33, 66]\ndef test_interp_array():\n    assert np.allclose(helpers.interp_array(np.array([1,2,3])),np.linspace(1,2.9,20))\ndef test_interp_array_list():\n    assert np.allclose(helpers.interp_array_list(np.array([[1,2,3],[1,2,3]])),[np.linspace(1,2.9,20)] * 2)\ndef test_interp_array_list_interpval():\n    assert helpers.interp_array_list([np.array([[1,2,3],[1,2,3],[1,2,3]])],interp_val=10)[0].shape[0]==20\n# def test_check_data_list_of_arrays():\n#     helpers.check_data([np.random.random((3,3))]*2)=='list'",
        "detail": "hypertools.tests.test_helpers",
        "documentation": {}
    },
    {
        "label": "test_interp_array",
        "kind": 2,
        "importPath": "hypertools.tests.test_helpers",
        "description": "hypertools.tests.test_helpers",
        "peekOfCode": "def test_interp_array():\n    assert np.allclose(helpers.interp_array(np.array([1,2,3])),np.linspace(1,2.9,20))\ndef test_interp_array_list():\n    assert np.allclose(helpers.interp_array_list(np.array([[1,2,3],[1,2,3]])),[np.linspace(1,2.9,20)] * 2)\ndef test_interp_array_list_interpval():\n    assert helpers.interp_array_list([np.array([[1,2,3],[1,2,3],[1,2,3]])],interp_val=10)[0].shape[0]==20\n# def test_check_data_list_of_arrays():\n#     helpers.check_data([np.random.random((3,3))]*2)=='list'\n#\n# def test_check_data_list_of_other():",
        "detail": "hypertools.tests.test_helpers",
        "documentation": {}
    },
    {
        "label": "test_interp_array_list",
        "kind": 2,
        "importPath": "hypertools.tests.test_helpers",
        "description": "hypertools.tests.test_helpers",
        "peekOfCode": "def test_interp_array_list():\n    assert np.allclose(helpers.interp_array_list(np.array([[1,2,3],[1,2,3]])),[np.linspace(1,2.9,20)] * 2)\ndef test_interp_array_list_interpval():\n    assert helpers.interp_array_list([np.array([[1,2,3],[1,2,3],[1,2,3]])],interp_val=10)[0].shape[0]==20\n# def test_check_data_list_of_arrays():\n#     helpers.check_data([np.random.random((3,3))]*2)=='list'\n#\n# def test_check_data_list_of_other():\n#     with pytest.raises(ValueError) as e_info:\n#         helpers.check_data([1,2,3])",
        "detail": "hypertools.tests.test_helpers",
        "documentation": {}
    },
    {
        "label": "test_interp_array_list_interpval",
        "kind": 2,
        "importPath": "hypertools.tests.test_helpers",
        "description": "hypertools.tests.test_helpers",
        "peekOfCode": "def test_interp_array_list_interpval():\n    assert helpers.interp_array_list([np.array([[1,2,3],[1,2,3],[1,2,3]])],interp_val=10)[0].shape[0]==20\n# def test_check_data_list_of_arrays():\n#     helpers.check_data([np.random.random((3,3))]*2)=='list'\n#\n# def test_check_data_list_of_other():\n#     with pytest.raises(ValueError) as e_info:\n#         helpers.check_data([1,2,3])\n#\n# def test_check_data_array():",
        "detail": "hypertools.tests.test_helpers",
        "documentation": {}
    },
    {
        "label": "test_parse_args_array",
        "kind": 2,
        "importPath": "hypertools.tests.test_helpers",
        "description": "hypertools.tests.test_helpers",
        "peekOfCode": "def test_parse_args_array():\n    x = [np.random.random((3,3))]\n    args=('o',)\n    assert helpers.parse_args(x, args)==[('o',)]\ndef test_parse_args_list():\n    x = [np.random.random((3,3))]*2\n    args=('o',)\n    assert helpers.parse_args(x, args)==[('o',),('o',)]\ndef test_parse_kwargs_array():\n    x = [np.random.random((3,3))]",
        "detail": "hypertools.tests.test_helpers",
        "documentation": {}
    },
    {
        "label": "test_parse_args_list",
        "kind": 2,
        "importPath": "hypertools.tests.test_helpers",
        "description": "hypertools.tests.test_helpers",
        "peekOfCode": "def test_parse_args_list():\n    x = [np.random.random((3,3))]*2\n    args=('o',)\n    assert helpers.parse_args(x, args)==[('o',),('o',)]\ndef test_parse_kwargs_array():\n    x = [np.random.random((3,3))]\n    kwargs={'label': ['Group A']}\n    assert helpers.parse_kwargs(x, kwargs)==[{'label': 'Group A'}]\ndef test_parse_kwargs_list():\n    x = [np.random.random((3,3))]*2",
        "detail": "hypertools.tests.test_helpers",
        "documentation": {}
    },
    {
        "label": "test_parse_kwargs_array",
        "kind": 2,
        "importPath": "hypertools.tests.test_helpers",
        "description": "hypertools.tests.test_helpers",
        "peekOfCode": "def test_parse_kwargs_array():\n    x = [np.random.random((3,3))]\n    kwargs={'label': ['Group A']}\n    assert helpers.parse_kwargs(x, kwargs)==[{'label': 'Group A'}]\ndef test_parse_kwargs_list():\n    x = [np.random.random((3,3))]*2\n    kwargs={'label': ['Group A', 'Group B']}\n    assert helpers.parse_kwargs(x, kwargs)==[{'label': 'Group A'}, {'label': 'Group B'}]\ndef test_reshape_data():\n    x = [[1,2],[3,4]]*2",
        "detail": "hypertools.tests.test_helpers",
        "documentation": {}
    },
    {
        "label": "test_parse_kwargs_list",
        "kind": 2,
        "importPath": "hypertools.tests.test_helpers",
        "description": "hypertools.tests.test_helpers",
        "peekOfCode": "def test_parse_kwargs_list():\n    x = [np.random.random((3,3))]*2\n    kwargs={'label': ['Group A', 'Group B']}\n    assert helpers.parse_kwargs(x, kwargs)==[{'label': 'Group A'}, {'label': 'Group B'}]\ndef test_reshape_data():\n    x = [[1,2],[3,4]]*2\n    labels = ['a','b','a','b']\n    assert np.array_equal(helpers.reshape_data(x, labels, labels)[0],[np.array([[1,2],[1,2]]),np.array([[3,4],[3,4]])])",
        "detail": "hypertools.tests.test_helpers",
        "documentation": {}
    },
    {
        "label": "test_reshape_data",
        "kind": 2,
        "importPath": "hypertools.tests.test_helpers",
        "description": "hypertools.tests.test_helpers",
        "peekOfCode": "def test_reshape_data():\n    x = [[1,2],[3,4]]*2\n    labels = ['a','b','a','b']\n    assert np.array_equal(helpers.reshape_data(x, labels, labels)[0],[np.array([[1,2],[1,2]]),np.array([[3,4],[3,4]])])",
        "detail": "hypertools.tests.test_helpers",
        "documentation": {}
    },
    {
        "label": "test_load_weights_avg",
        "kind": 2,
        "importPath": "hypertools.tests.test_load",
        "description": "hypertools.tests.test_load",
        "peekOfCode": "def test_load_weights_avg():\n    geo = load('weights_avg')\n    assert isinstance(geo, DataGeometry)\ndef test_load_weights_sample():\n    geo = load('weights_sample')\n    assert isinstance(geo, DataGeometry)\ndef test_load_weights():\n    geo = load('weights')\n    assert isinstance(geo, DataGeometry)\ndef test_load_mushrooms():",
        "detail": "hypertools.tests.test_load",
        "documentation": {}
    },
    {
        "label": "test_load_weights_sample",
        "kind": 2,
        "importPath": "hypertools.tests.test_load",
        "description": "hypertools.tests.test_load",
        "peekOfCode": "def test_load_weights_sample():\n    geo = load('weights_sample')\n    assert isinstance(geo, DataGeometry)\ndef test_load_weights():\n    geo = load('weights')\n    assert isinstance(geo, DataGeometry)\ndef test_load_mushrooms():\n    geo = load('mushrooms')\n    assert isinstance(geo, DataGeometry)\ndef test_load_spiral():",
        "detail": "hypertools.tests.test_load",
        "documentation": {}
    },
    {
        "label": "test_load_weights",
        "kind": 2,
        "importPath": "hypertools.tests.test_load",
        "description": "hypertools.tests.test_load",
        "peekOfCode": "def test_load_weights():\n    geo = load('weights')\n    assert isinstance(geo, DataGeometry)\ndef test_load_mushrooms():\n    geo = load('mushrooms')\n    assert isinstance(geo, DataGeometry)\ndef test_load_spiral():\n    geo = load('spiral')\n    assert isinstance(geo, DataGeometry)\ndef test_weights():",
        "detail": "hypertools.tests.test_load",
        "documentation": {}
    },
    {
        "label": "test_load_mushrooms",
        "kind": 2,
        "importPath": "hypertools.tests.test_load",
        "description": "hypertools.tests.test_load",
        "peekOfCode": "def test_load_mushrooms():\n    geo = load('mushrooms')\n    assert isinstance(geo, DataGeometry)\ndef test_load_spiral():\n    geo = load('spiral')\n    assert isinstance(geo, DataGeometry)\ndef test_weights():\n    geo = load('weights_sample')\n    assert all(wt.shape == (300, 100) for wt in geo.get_data())\ndef test_weights_ndim3():",
        "detail": "hypertools.tests.test_load",
        "documentation": {}
    },
    {
        "label": "test_load_spiral",
        "kind": 2,
        "importPath": "hypertools.tests.test_load",
        "description": "hypertools.tests.test_load",
        "peekOfCode": "def test_load_spiral():\n    geo = load('spiral')\n    assert isinstance(geo, DataGeometry)\ndef test_weights():\n    geo = load('weights_sample')\n    assert all(wt.shape == (300, 100) for wt in geo.get_data())\ndef test_weights_ndim3():\n    # Should return 3 dimensional data\n    geo = load('weights_avg', reduce='PCA', ndims=3)\n    print(geo.transform()[0].shape)",
        "detail": "hypertools.tests.test_load",
        "documentation": {}
    },
    {
        "label": "test_weights",
        "kind": 2,
        "importPath": "hypertools.tests.test_load",
        "description": "hypertools.tests.test_load",
        "peekOfCode": "def test_weights():\n    geo = load('weights_sample')\n    assert all(wt.shape == (300, 100) for wt in geo.get_data())\ndef test_weights_ndim3():\n    # Should return 3 dimensional data\n    geo = load('weights_avg', reduce='PCA', ndims=3)\n    print(geo.transform()[0].shape)\n    assert all(wt.shape == (100, 3) for wt in geo.transform())\ndef test_weights_ndim2():\n    # Should return 2 dimensional data",
        "detail": "hypertools.tests.test_load",
        "documentation": {}
    },
    {
        "label": "test_weights_ndim3",
        "kind": 2,
        "importPath": "hypertools.tests.test_load",
        "description": "hypertools.tests.test_load",
        "peekOfCode": "def test_weights_ndim3():\n    # Should return 3 dimensional data\n    geo = load('weights_avg', reduce='PCA', ndims=3)\n    print(geo.transform()[0].shape)\n    assert all(wt.shape == (100, 3) for wt in geo.transform())\ndef test_weights_ndim2():\n    # Should return 2 dimensional data\n    geo = load('weights_avg', reduce='PCA', ndims=2)\n    assert all(wt.shape == (100, 2) for wt in geo.transform())\ndef test_weights_ndim1():",
        "detail": "hypertools.tests.test_load",
        "documentation": {}
    },
    {
        "label": "test_weights_ndim2",
        "kind": 2,
        "importPath": "hypertools.tests.test_load",
        "description": "hypertools.tests.test_load",
        "peekOfCode": "def test_weights_ndim2():\n    # Should return 2 dimensional data\n    geo = load('weights_avg', reduce='PCA', ndims=2)\n    assert all(wt.shape == (100, 2) for wt in geo.transform())\ndef test_weights_ndim1():\n    # Should return 1 dimensional data\n    geo = load('weights_avg', reduce='PCA', ndims=1)\n    assert all(wt.shape == (100, 1) for wt in geo.transform())\ndef test_weights_ndim3_align():\n    # Should return aligned 3 dimensional data",
        "detail": "hypertools.tests.test_load",
        "documentation": {}
    },
    {
        "label": "test_weights_ndim1",
        "kind": 2,
        "importPath": "hypertools.tests.test_load",
        "description": "hypertools.tests.test_load",
        "peekOfCode": "def test_weights_ndim1():\n    # Should return 1 dimensional data\n    geo = load('weights_avg', reduce='PCA', ndims=1)\n    assert all(wt.shape == (100, 1) for wt in geo.transform())\ndef test_weights_ndim3_align():\n    # Should return aligned 3 dimensional data\n    geo = load('weights_avg', reduce='PCA', ndims=3, align=True)\n    assert all(wt.shape == (100, 3) for wt in geo.transform())\ndef test_weights_ndim2_align():\n    # Should return aligned 2 dimensional data",
        "detail": "hypertools.tests.test_load",
        "documentation": {}
    },
    {
        "label": "test_weights_ndim3_align",
        "kind": 2,
        "importPath": "hypertools.tests.test_load",
        "description": "hypertools.tests.test_load",
        "peekOfCode": "def test_weights_ndim3_align():\n    # Should return aligned 3 dimensional data\n    geo = load('weights_avg', reduce='PCA', ndims=3, align=True)\n    assert all(wt.shape == (100, 3) for wt in geo.transform())\ndef test_weights_ndim2_align():\n    # Should return aligned 2 dimensional data\n    geo = load('weights_avg', reduce='PCA', ndims=2, align=True)\n    assert all(wt.shape == (100, 2) for wt in geo.transform())\ndef test_weights_ndim1_align():\n    # Should return aligned 1 dimensional data",
        "detail": "hypertools.tests.test_load",
        "documentation": {}
    },
    {
        "label": "test_weights_ndim2_align",
        "kind": 2,
        "importPath": "hypertools.tests.test_load",
        "description": "hypertools.tests.test_load",
        "peekOfCode": "def test_weights_ndim2_align():\n    # Should return aligned 2 dimensional data\n    geo = load('weights_avg', reduce='PCA', ndims=2, align=True)\n    assert all(wt.shape == (100, 2) for wt in geo.transform())\ndef test_weights_ndim1_align():\n    # Should return aligned 1 dimensional data\n    geo = load('weights_avg', reduce='PCA', ndims=1, align=True)\n    assert all(wt.shape == (100, 1) for wt in geo.transform())",
        "detail": "hypertools.tests.test_load",
        "documentation": {}
    },
    {
        "label": "test_weights_ndim1_align",
        "kind": 2,
        "importPath": "hypertools.tests.test_load",
        "description": "hypertools.tests.test_load",
        "peekOfCode": "def test_weights_ndim1_align():\n    # Should return aligned 1 dimensional data\n    geo = load('weights_avg', reduce='PCA', ndims=1, align=True)\n    assert all(wt.shape == (100, 1) for wt in geo.transform())",
        "detail": "hypertools.tests.test_load",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "hypertools.tests.test_missing_inds",
        "description": "hypertools.tests.test_missing_inds",
        "peekOfCode": "data = np.random.multivariate_normal(np.zeros(2), np.eye(2), size=10)\ndata[3,0]=np.nan\ndata[9,1]=np.nan",
        "detail": "hypertools.tests.test_missing_inds",
        "documentation": {}
    },
    {
        "label": "test_normalize_returns_list",
        "kind": 2,
        "importPath": "hypertools.tests.test_normalize",
        "description": "hypertools.tests.test_normalize",
        "peekOfCode": "def test_normalize_returns_list():\n    assert type(normalize(data)) is list\ndef test_normalize_across():\n    norm_data = normalize(data, normalize='across')\n    assert np.allclose(np.mean(np.vstack(norm_data),axis=0),0)\ndef test_normalize_within():\n    norm_data = normalize(data, normalize='within')\n    assert np.allclose([np.mean(i,axis=0) for i in norm_data],0)\ndef test_normalize_row():\n    norm_data = normalize(data, normalize='row')",
        "detail": "hypertools.tests.test_normalize",
        "documentation": {}
    },
    {
        "label": "test_normalize_across",
        "kind": 2,
        "importPath": "hypertools.tests.test_normalize",
        "description": "hypertools.tests.test_normalize",
        "peekOfCode": "def test_normalize_across():\n    norm_data = normalize(data, normalize='across')\n    assert np.allclose(np.mean(np.vstack(norm_data),axis=0),0)\ndef test_normalize_within():\n    norm_data = normalize(data, normalize='within')\n    assert np.allclose([np.mean(i,axis=0) for i in norm_data],0)\ndef test_normalize_row():\n    norm_data = normalize(data, normalize='row')\n    assert np.allclose(np.mean(np.vstack(norm_data), axis=1),0)\ndef test_normalize_geo():",
        "detail": "hypertools.tests.test_normalize",
        "documentation": {}
    },
    {
        "label": "test_normalize_within",
        "kind": 2,
        "importPath": "hypertools.tests.test_normalize",
        "description": "hypertools.tests.test_normalize",
        "peekOfCode": "def test_normalize_within():\n    norm_data = normalize(data, normalize='within')\n    assert np.allclose([np.mean(i,axis=0) for i in norm_data],0)\ndef test_normalize_row():\n    norm_data = normalize(data, normalize='row')\n    assert np.allclose(np.mean(np.vstack(norm_data), axis=1),0)\ndef test_normalize_geo():\n    geo = plot(data, show=False)\n    norm_data = normalize(geo, normalize='row')\n    assert np.allclose(np.mean(np.vstack(norm_data), axis=1),0)",
        "detail": "hypertools.tests.test_normalize",
        "documentation": {}
    },
    {
        "label": "test_normalize_row",
        "kind": 2,
        "importPath": "hypertools.tests.test_normalize",
        "description": "hypertools.tests.test_normalize",
        "peekOfCode": "def test_normalize_row():\n    norm_data = normalize(data, normalize='row')\n    assert np.allclose(np.mean(np.vstack(norm_data), axis=1),0)\ndef test_normalize_geo():\n    geo = plot(data, show=False)\n    norm_data = normalize(geo, normalize='row')\n    assert np.allclose(np.mean(np.vstack(norm_data), axis=1),0)",
        "detail": "hypertools.tests.test_normalize",
        "documentation": {}
    },
    {
        "label": "test_normalize_geo",
        "kind": 2,
        "importPath": "hypertools.tests.test_normalize",
        "description": "hypertools.tests.test_normalize",
        "peekOfCode": "def test_normalize_geo():\n    geo = plot(data, show=False)\n    norm_data = normalize(geo, normalize='row')\n    assert np.allclose(np.mean(np.vstack(norm_data), axis=1),0)",
        "detail": "hypertools.tests.test_normalize",
        "documentation": {}
    },
    {
        "label": "cluster1",
        "kind": 5,
        "importPath": "hypertools.tests.test_normalize",
        "description": "hypertools.tests.test_normalize",
        "peekOfCode": "cluster1 = np.random.multivariate_normal(np.zeros(3), np.eye(3), size=100)\ncluster2 = np.random.multivariate_normal(np.zeros(3)+100, np.eye(3), size=100)\ndata = [cluster1, cluster2]\ndef test_normalize_returns_list():\n    assert type(normalize(data)) is list\ndef test_normalize_across():\n    norm_data = normalize(data, normalize='across')\n    assert np.allclose(np.mean(np.vstack(norm_data),axis=0),0)\ndef test_normalize_within():\n    norm_data = normalize(data, normalize='within')",
        "detail": "hypertools.tests.test_normalize",
        "documentation": {}
    },
    {
        "label": "cluster2",
        "kind": 5,
        "importPath": "hypertools.tests.test_normalize",
        "description": "hypertools.tests.test_normalize",
        "peekOfCode": "cluster2 = np.random.multivariate_normal(np.zeros(3)+100, np.eye(3), size=100)\ndata = [cluster1, cluster2]\ndef test_normalize_returns_list():\n    assert type(normalize(data)) is list\ndef test_normalize_across():\n    norm_data = normalize(data, normalize='across')\n    assert np.allclose(np.mean(np.vstack(norm_data),axis=0),0)\ndef test_normalize_within():\n    norm_data = normalize(data, normalize='within')\n    assert np.allclose([np.mean(i,axis=0) for i in norm_data],0)",
        "detail": "hypertools.tests.test_normalize",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "hypertools.tests.test_normalize",
        "description": "hypertools.tests.test_normalize",
        "peekOfCode": "data = [cluster1, cluster2]\ndef test_normalize_returns_list():\n    assert type(normalize(data)) is list\ndef test_normalize_across():\n    norm_data = normalize(data, normalize='across')\n    assert np.allclose(np.mean(np.vstack(norm_data),axis=0),0)\ndef test_normalize_within():\n    norm_data = normalize(data, normalize='within')\n    assert np.allclose([np.mean(i,axis=0) for i in norm_data],0)\ndef test_normalize_row():",
        "detail": "hypertools.tests.test_normalize",
        "documentation": {}
    },
    {
        "label": "test_df2mat",
        "kind": 2,
        "importPath": "hypertools.tests.test_pandas_to_matrix",
        "description": "hypertools.tests.test_pandas_to_matrix",
        "peekOfCode": "def test_df2mat():\n    df = pd.DataFrame(['a','b'])\n    assert np.array_equal(df2mat(df),np.array([[1,0],[0,1]]))",
        "detail": "hypertools.tests.test_pandas_to_matrix",
        "documentation": {}
    },
    {
        "label": "test_plot_1d",
        "kind": 2,
        "importPath": "hypertools.tests.test_plot",
        "description": "hypertools.tests.test_plot",
        "peekOfCode": "def test_plot_1d():\n    data_reduced_1d = reducer(data, ndims=1)\n    geo = plot.plot(data_reduced_1d, show=False)\n    assert all([i.shape[1]==1 for i in geo.data])\ndef test_plot_2d():\n    data_reduced_2d = reducer(data, ndims=2)\n    geo = plot.plot(data_reduced_2d, show=False)\n    assert all([i.shape[1]==2 for i in geo.data])\ndef test_plot_3d():\n    data_reduced_3d = reducer(data, ndims=3)",
        "detail": "hypertools.tests.test_plot",
        "documentation": {}
    },
    {
        "label": "test_plot_2d",
        "kind": 2,
        "importPath": "hypertools.tests.test_plot",
        "description": "hypertools.tests.test_plot",
        "peekOfCode": "def test_plot_2d():\n    data_reduced_2d = reducer(data, ndims=2)\n    geo = plot.plot(data_reduced_2d, show=False)\n    assert all([i.shape[1]==2 for i in geo.data])\ndef test_plot_3d():\n    data_reduced_3d = reducer(data, ndims=3)\n    geo = plot.plot(data_reduced_3d, show=False)\n    assert all([i.shape[1]==3 for i in geo.data])\ndef test_plot_reduce_none():\n    # Should return same dimensional data if ndims is None",
        "detail": "hypertools.tests.test_plot",
        "documentation": {}
    },
    {
        "label": "test_plot_3d",
        "kind": 2,
        "importPath": "hypertools.tests.test_plot",
        "description": "hypertools.tests.test_plot",
        "peekOfCode": "def test_plot_3d():\n    data_reduced_3d = reducer(data, ndims=3)\n    geo = plot.plot(data_reduced_3d, show=False)\n    assert all([i.shape[1]==3 for i in geo.data])\ndef test_plot_reduce_none():\n    # Should return same dimensional data if ndims is None\n    geo = plot.plot(data, show=False)\n    assert all([i.shape[1] == d.shape[1] for i, d in zip(geo.data, data)])\ndef test_plot_reduce3d():\n    # should return 3d data since ndims=3",
        "detail": "hypertools.tests.test_plot",
        "documentation": {}
    },
    {
        "label": "test_plot_reduce_none",
        "kind": 2,
        "importPath": "hypertools.tests.test_plot",
        "description": "hypertools.tests.test_plot",
        "peekOfCode": "def test_plot_reduce_none():\n    # Should return same dimensional data if ndims is None\n    geo = plot.plot(data, show=False)\n    assert all([i.shape[1] == d.shape[1] for i, d in zip(geo.data, data)])\ndef test_plot_reduce3d():\n    # should return 3d data since ndims=3\n    geo = plot.plot(data, ndims=3, show=False)\n    assert all([i.shape[1] == 3 for i in geo.xform_data])\ndef test_plot_reduce2d():\n    # should return 2d data since ndims=2",
        "detail": "hypertools.tests.test_plot",
        "documentation": {}
    },
    {
        "label": "test_plot_reduce3d",
        "kind": 2,
        "importPath": "hypertools.tests.test_plot",
        "description": "hypertools.tests.test_plot",
        "peekOfCode": "def test_plot_reduce3d():\n    # should return 3d data since ndims=3\n    geo = plot.plot(data, ndims=3, show=False)\n    assert all([i.shape[1] == 3 for i in geo.xform_data])\ndef test_plot_reduce2d():\n    # should return 2d data since ndims=2\n    geo = plot.plot(data, ndims=2, show=False)\n    assert all([i.shape[1] == 2 for i in geo.xform_data])\ndef test_plot_reduce1d():\n    # should return 1d data since ndims=1",
        "detail": "hypertools.tests.test_plot",
        "documentation": {}
    },
    {
        "label": "test_plot_reduce2d",
        "kind": 2,
        "importPath": "hypertools.tests.test_plot",
        "description": "hypertools.tests.test_plot",
        "peekOfCode": "def test_plot_reduce2d():\n    # should return 2d data since ndims=2\n    geo = plot.plot(data, ndims=2, show=False)\n    assert all([i.shape[1] == 2 for i in geo.xform_data])\ndef test_plot_reduce1d():\n    # should return 1d data since ndims=1\n    geo = plot.plot(data, ndims=1, show=False)\n    assert all([i.shape[1] == 1 for i in geo.xform_data])\ndef test_plot_reduce_align5d():\n    # should return 5d data since ndims=5",
        "detail": "hypertools.tests.test_plot",
        "documentation": {}
    },
    {
        "label": "test_plot_reduce1d",
        "kind": 2,
        "importPath": "hypertools.tests.test_plot",
        "description": "hypertools.tests.test_plot",
        "peekOfCode": "def test_plot_reduce1d():\n    # should return 1d data since ndims=1\n    geo = plot.plot(data, ndims=1, show=False)\n    assert all([i.shape[1] == 1 for i in geo.xform_data])\ndef test_plot_reduce_align5d():\n    # should return 5d data since ndims=5\n    geo = plot.plot(weights, ndims=5, align=True, show=False)\n    assert all([i.shape[1] == 5 for i in geo.xform_data])\ndef test_plot_reduce10d():\n    # should return 10d data since ndims=10",
        "detail": "hypertools.tests.test_plot",
        "documentation": {}
    },
    {
        "label": "test_plot_reduce_align5d",
        "kind": 2,
        "importPath": "hypertools.tests.test_plot",
        "description": "hypertools.tests.test_plot",
        "peekOfCode": "def test_plot_reduce_align5d():\n    # should return 5d data since ndims=5\n    geo = plot.plot(weights, ndims=5, align=True, show=False)\n    assert all([i.shape[1] == 5 for i in geo.xform_data])\ndef test_plot_reduce10d():\n    # should return 10d data since ndims=10\n    geo = plot.plot(weights, ndims=10, show=False)\n    assert all([i.shape[1] == 10 for i in geo.xform_data])\ndef test_plot_model_dict():\n    # should return 10d data since ndims=10",
        "detail": "hypertools.tests.test_plot",
        "documentation": {}
    },
    {
        "label": "test_plot_reduce10d",
        "kind": 2,
        "importPath": "hypertools.tests.test_plot",
        "description": "hypertools.tests.test_plot",
        "peekOfCode": "def test_plot_reduce10d():\n    # should return 10d data since ndims=10\n    geo = plot.plot(weights, ndims=10, show=False)\n    assert all([i.shape[1] == 10 for i in geo.xform_data])\ndef test_plot_model_dict():\n    # should return 10d data since ndims=10\n    geo = plot.plot(weights, reduce={'model' : 'PCA', 'params' : {'whiten' : True}}, show=False)\n    assert isinstance(geo, DataGeometry)\ndef test_plot_cluster_str():\n    # should return 10d data since ndims=10",
        "detail": "hypertools.tests.test_plot",
        "documentation": {}
    },
    {
        "label": "test_plot_model_dict",
        "kind": 2,
        "importPath": "hypertools.tests.test_plot",
        "description": "hypertools.tests.test_plot",
        "peekOfCode": "def test_plot_model_dict():\n    # should return 10d data since ndims=10\n    geo = plot.plot(weights, reduce={'model' : 'PCA', 'params' : {'whiten' : True}}, show=False)\n    assert isinstance(geo, DataGeometry)\ndef test_plot_cluster_str():\n    # should return 10d data since ndims=10\n    geo = plot.plot(weights, cluster='KMeans', show=False)\n    assert isinstance(geo, DataGeometry)\ndef test_plot_cluster_dict():\n    # should return 10d data since ndims=10",
        "detail": "hypertools.tests.test_plot",
        "documentation": {}
    },
    {
        "label": "test_plot_cluster_str",
        "kind": 2,
        "importPath": "hypertools.tests.test_plot",
        "description": "hypertools.tests.test_plot",
        "peekOfCode": "def test_plot_cluster_str():\n    # should return 10d data since ndims=10\n    geo = plot.plot(weights, cluster='KMeans', show=False)\n    assert isinstance(geo, DataGeometry)\ndef test_plot_cluster_dict():\n    # should return 10d data since ndims=10\n    geo = plot.plot(weights, cluster={'model' : 'KMeans', 'params' : {'n_clusters' : 3}}, show=False)\n    assert isinstance(geo, DataGeometry)\ndef test_plot_cluster_n_clusters():\n    # should return 10d data since ndims=10",
        "detail": "hypertools.tests.test_plot",
        "documentation": {}
    },
    {
        "label": "test_plot_cluster_dict",
        "kind": 2,
        "importPath": "hypertools.tests.test_plot",
        "description": "hypertools.tests.test_plot",
        "peekOfCode": "def test_plot_cluster_dict():\n    # should return 10d data since ndims=10\n    geo = plot.plot(weights, cluster={'model' : 'KMeans', 'params' : {'n_clusters' : 3}}, show=False)\n    assert isinstance(geo, DataGeometry)\ndef test_plot_cluster_n_clusters():\n    # should return 10d data since ndims=10\n    geo = plot.plot(weights, n_clusters=3, show=False)\n    assert isinstance(geo, DataGeometry)\ndef test_plot_nd():\n    geo  = plot.plot(data, show=False)",
        "detail": "hypertools.tests.test_plot",
        "documentation": {}
    },
    {
        "label": "test_plot_cluster_n_clusters",
        "kind": 2,
        "importPath": "hypertools.tests.test_plot",
        "description": "hypertools.tests.test_plot",
        "peekOfCode": "def test_plot_cluster_n_clusters():\n    # should return 10d data since ndims=10\n    geo = plot.plot(weights, n_clusters=3, show=False)\n    assert isinstance(geo, DataGeometry)\ndef test_plot_nd():\n    geo  = plot.plot(data, show=False)\n    assert all([i.shape[1]==d.shape[1] for i, d in zip(geo.data, data)])\ndef test_plot_data_is_list():\n    geo  = plot.plot(data, show=False)\n    assert type(geo.data) is list",
        "detail": "hypertools.tests.test_plot",
        "documentation": {}
    },
    {
        "label": "test_plot_nd",
        "kind": 2,
        "importPath": "hypertools.tests.test_plot",
        "description": "hypertools.tests.test_plot",
        "peekOfCode": "def test_plot_nd():\n    geo  = plot.plot(data, show=False)\n    assert all([i.shape[1]==d.shape[1] for i, d in zip(geo.data, data)])\ndef test_plot_data_is_list():\n    geo  = plot.plot(data, show=False)\n    assert type(geo.data) is list\ndef test_plot_check_fig():\n    geo  = plot.plot(data, show=False)\n    assert isinstance(geo.fig, mpl.figure.Figure)\ndef test_plot_check_ax():",
        "detail": "hypertools.tests.test_plot",
        "documentation": {}
    },
    {
        "label": "test_plot_data_is_list",
        "kind": 2,
        "importPath": "hypertools.tests.test_plot",
        "description": "hypertools.tests.test_plot",
        "peekOfCode": "def test_plot_data_is_list():\n    geo  = plot.plot(data, show=False)\n    assert type(geo.data) is list\ndef test_plot_check_fig():\n    geo  = plot.plot(data, show=False)\n    assert isinstance(geo.fig, mpl.figure.Figure)\ndef test_plot_check_ax():\n    geo  = plot.plot(data, show=False)\n    assert isinstance(geo.ax, mpl.axes._axes.Axes)\ndef test_plot_text():",
        "detail": "hypertools.tests.test_plot",
        "documentation": {}
    },
    {
        "label": "test_plot_check_fig",
        "kind": 2,
        "importPath": "hypertools.tests.test_plot",
        "description": "hypertools.tests.test_plot",
        "peekOfCode": "def test_plot_check_fig():\n    geo  = plot.plot(data, show=False)\n    assert isinstance(geo.fig, mpl.figure.Figure)\ndef test_plot_check_ax():\n    geo  = plot.plot(data, show=False)\n    assert isinstance(geo.ax, mpl.axes._axes.Axes)\ndef test_plot_text():\n    text_data = [['i like cats alot', 'cats r pretty cool', 'cats are better than dogs'],\n            ['dogs rule the haus', 'dogs are my jam', 'dogs are a mans best friend']]\n    geo = plot.plot(text_data, show=False)",
        "detail": "hypertools.tests.test_plot",
        "documentation": {}
    },
    {
        "label": "test_plot_check_ax",
        "kind": 2,
        "importPath": "hypertools.tests.test_plot",
        "description": "hypertools.tests.test_plot",
        "peekOfCode": "def test_plot_check_ax():\n    geo  = plot.plot(data, show=False)\n    assert isinstance(geo.ax, mpl.axes._axes.Axes)\ndef test_plot_text():\n    text_data = [['i like cats alot', 'cats r pretty cool', 'cats are better than dogs'],\n            ['dogs rule the haus', 'dogs are my jam', 'dogs are a mans best friend']]\n    geo = plot.plot(text_data, show=False)\n    assert isinstance(geo, DataGeometry)\ndef test_plot_ax():\n    fig = plt.figure()",
        "detail": "hypertools.tests.test_plot",
        "documentation": {}
    },
    {
        "label": "test_plot_text",
        "kind": 2,
        "importPath": "hypertools.tests.test_plot",
        "description": "hypertools.tests.test_plot",
        "peekOfCode": "def test_plot_text():\n    text_data = [['i like cats alot', 'cats r pretty cool', 'cats are better than dogs'],\n            ['dogs rule the haus', 'dogs are my jam', 'dogs are a mans best friend']]\n    geo = plot.plot(text_data, show=False)\n    assert isinstance(geo, DataGeometry)\ndef test_plot_ax():\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection='3d')\n    geo = plot.plot(data, ax=ax, show=False)\n    assert isinstance(geo, DataGeometry)",
        "detail": "hypertools.tests.test_plot",
        "documentation": {}
    },
    {
        "label": "test_plot_ax",
        "kind": 2,
        "importPath": "hypertools.tests.test_plot",
        "description": "hypertools.tests.test_plot",
        "peekOfCode": "def test_plot_ax():\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection='3d')\n    geo = plot.plot(data, ax=ax, show=False)\n    assert isinstance(geo, DataGeometry)\ndef test_plot_ax_2d():\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    geo = plot.plot(data, ax=ax, show=False, ndims=2)\n    assert isinstance(geo, DataGeometry)",
        "detail": "hypertools.tests.test_plot",
        "documentation": {}
    },
    {
        "label": "test_plot_ax_2d",
        "kind": 2,
        "importPath": "hypertools.tests.test_plot",
        "description": "hypertools.tests.test_plot",
        "peekOfCode": "def test_plot_ax_2d():\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    geo = plot.plot(data, ax=ax, show=False, ndims=2)\n    assert isinstance(geo, DataGeometry)\ndef test_plot_ax_error():\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    with pytest.raises(ValueError) as e_info:\n        geo = plot.plot(data, ax=ax, show=False)",
        "detail": "hypertools.tests.test_plot",
        "documentation": {}
    },
    {
        "label": "test_plot_ax_error",
        "kind": 2,
        "importPath": "hypertools.tests.test_plot",
        "description": "hypertools.tests.test_plot",
        "peekOfCode": "def test_plot_ax_error():\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    with pytest.raises(ValueError) as e_info:\n        geo = plot.plot(data, ax=ax, show=False)\ndef test_plot_geo():\n    geo = plot.plot(data, show=False)\n    geo = plot.plot(geo, show=False)\n    assert isinstance(geo, DataGeometry)\n# ## ANIMATED ##",
        "detail": "hypertools.tests.test_plot",
        "documentation": {}
    },
    {
        "label": "test_plot_geo",
        "kind": 2,
        "importPath": "hypertools.tests.test_plot",
        "description": "hypertools.tests.test_plot",
        "peekOfCode": "def test_plot_geo():\n    geo = plot.plot(data, show=False)\n    geo = plot.plot(geo, show=False)\n    assert isinstance(geo, DataGeometry)\n# ## ANIMATED ##\ndef test_plot_1d_animate():\n    d = reducer(data, ndims=1)\n    with pytest.raises(Exception) as e_info:\n        plot.plot(d, animate=True, show=False)\ndef test_plot_2d_animate():",
        "detail": "hypertools.tests.test_plot",
        "documentation": {}
    },
    {
        "label": "test_plot_1d_animate",
        "kind": 2,
        "importPath": "hypertools.tests.test_plot",
        "description": "hypertools.tests.test_plot",
        "peekOfCode": "def test_plot_1d_animate():\n    d = reducer(data, ndims=1)\n    with pytest.raises(Exception) as e_info:\n        plot.plot(d, animate=True, show=False)\ndef test_plot_2d_animate():\n    data_reduced_2d = reducer(data, ndims=2)\n    with pytest.raises(Exception) as e_info:\n        plot.plot(data_reduced_2d, animate=True, show=False)\ndef test_plot_3d_animate():\n    data_reduced_3d = reducer(data,ndims=3)",
        "detail": "hypertools.tests.test_plot",
        "documentation": {}
    },
    {
        "label": "test_plot_2d_animate",
        "kind": 2,
        "importPath": "hypertools.tests.test_plot",
        "description": "hypertools.tests.test_plot",
        "peekOfCode": "def test_plot_2d_animate():\n    data_reduced_2d = reducer(data, ndims=2)\n    with pytest.raises(Exception) as e_info:\n        plot.plot(data_reduced_2d, animate=True, show=False)\ndef test_plot_3d_animate():\n    data_reduced_3d = reducer(data,ndims=3)\n    geo = plot.plot(data_reduced_3d, animate=True, show=False)\n    assert all([i.shape[1]==3 for i in geo.data])\ndef test_plot_nd_animate():\n    geo = plot.plot(data, animate=True, show=False)",
        "detail": "hypertools.tests.test_plot",
        "documentation": {}
    },
    {
        "label": "test_plot_3d_animate",
        "kind": 2,
        "importPath": "hypertools.tests.test_plot",
        "description": "hypertools.tests.test_plot",
        "peekOfCode": "def test_plot_3d_animate():\n    data_reduced_3d = reducer(data,ndims=3)\n    geo = plot.plot(data_reduced_3d, animate=True, show=False)\n    assert all([i.shape[1]==3 for i in geo.data])\ndef test_plot_nd_animate():\n    geo = plot.plot(data, animate=True, show=False)\n    assert all([i.shape[1]==d.shape[1] for i, d in zip(geo.data, data)])\ndef test_plot_data_animate_is_list():\n    geo = plot.plot(data, animate=True, show=False)\n    assert type(geo.data) is list",
        "detail": "hypertools.tests.test_plot",
        "documentation": {}
    },
    {
        "label": "test_plot_nd_animate",
        "kind": 2,
        "importPath": "hypertools.tests.test_plot",
        "description": "hypertools.tests.test_plot",
        "peekOfCode": "def test_plot_nd_animate():\n    geo = plot.plot(data, animate=True, show=False)\n    assert all([i.shape[1]==d.shape[1] for i, d in zip(geo.data, data)])\ndef test_plot_data_animate_is_list():\n    geo = plot.plot(data, animate=True, show=False)\n    assert type(geo.data) is list\ndef test_plot_animate_check_fig():\n    geo = plot.plot(data, animate=True, show=False)\n    assert isinstance(geo.fig, mpl.figure.Figure)\ndef test_plot_animate_check_ax():",
        "detail": "hypertools.tests.test_plot",
        "documentation": {}
    },
    {
        "label": "test_plot_data_animate_is_list",
        "kind": 2,
        "importPath": "hypertools.tests.test_plot",
        "description": "hypertools.tests.test_plot",
        "peekOfCode": "def test_plot_data_animate_is_list():\n    geo = plot.plot(data, animate=True, show=False)\n    assert type(geo.data) is list\ndef test_plot_animate_check_fig():\n    geo = plot.plot(data, animate=True, show=False)\n    assert isinstance(geo.fig, mpl.figure.Figure)\ndef test_plot_animate_check_ax():\n    geo = plot.plot(data, animate=True, show=False)\n    assert isinstance(geo.ax, mpl.axes._axes.Axes)\ndef test_plot_animate_check_line_ani():",
        "detail": "hypertools.tests.test_plot",
        "documentation": {}
    },
    {
        "label": "test_plot_animate_check_fig",
        "kind": 2,
        "importPath": "hypertools.tests.test_plot",
        "description": "hypertools.tests.test_plot",
        "peekOfCode": "def test_plot_animate_check_fig():\n    geo = plot.plot(data, animate=True, show=False)\n    assert isinstance(geo.fig, mpl.figure.Figure)\ndef test_plot_animate_check_ax():\n    geo = plot.plot(data, animate=True, show=False)\n    assert isinstance(geo.ax, mpl.axes._axes.Axes)\ndef test_plot_animate_check_line_ani():\n    geo = plot.plot(data, animate=True, show=False)\n    assert isinstance(geo.line_ani, mpl.animation.FuncAnimation)",
        "detail": "hypertools.tests.test_plot",
        "documentation": {}
    },
    {
        "label": "test_plot_animate_check_ax",
        "kind": 2,
        "importPath": "hypertools.tests.test_plot",
        "description": "hypertools.tests.test_plot",
        "peekOfCode": "def test_plot_animate_check_ax():\n    geo = plot.plot(data, animate=True, show=False)\n    assert isinstance(geo.ax, mpl.axes._axes.Axes)\ndef test_plot_animate_check_line_ani():\n    geo = plot.plot(data, animate=True, show=False)\n    assert isinstance(geo.line_ani, mpl.animation.FuncAnimation)",
        "detail": "hypertools.tests.test_plot",
        "documentation": {}
    },
    {
        "label": "test_plot_animate_check_line_ani",
        "kind": 2,
        "importPath": "hypertools.tests.test_plot",
        "description": "hypertools.tests.test_plot",
        "peekOfCode": "def test_plot_animate_check_line_ani():\n    geo = plot.plot(data, animate=True, show=False)\n    assert isinstance(geo.line_ani, mpl.animation.FuncAnimation)",
        "detail": "hypertools.tests.test_plot",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "hypertools.tests.test_plot",
        "description": "hypertools.tests.test_plot",
        "peekOfCode": "data = [np.random.multivariate_normal(np.zeros(4), np.eye(4), size=100) for i\n        in range(2)]\nweights = load('weights_avg').get_data()\n# To prevent warning about 20+ figs being open\nmpl.rcParams['figure.max_open_warning'] = 25\n## STATIC ##\ndef test_plot_1d():\n    data_reduced_1d = reducer(data, ndims=1)\n    geo = plot.plot(data_reduced_1d, show=False)\n    assert all([i.shape[1]==1 for i in geo.data])",
        "detail": "hypertools.tests.test_plot",
        "documentation": {}
    },
    {
        "label": "weights",
        "kind": 5,
        "importPath": "hypertools.tests.test_plot",
        "description": "hypertools.tests.test_plot",
        "peekOfCode": "weights = load('weights_avg').get_data()\n# To prevent warning about 20+ figs being open\nmpl.rcParams['figure.max_open_warning'] = 25\n## STATIC ##\ndef test_plot_1d():\n    data_reduced_1d = reducer(data, ndims=1)\n    geo = plot.plot(data_reduced_1d, show=False)\n    assert all([i.shape[1]==1 for i in geo.data])\ndef test_plot_2d():\n    data_reduced_2d = reducer(data, ndims=2)",
        "detail": "hypertools.tests.test_plot",
        "documentation": {}
    },
    {
        "label": "mpl.rcParams['figure.max_open_warning']",
        "kind": 5,
        "importPath": "hypertools.tests.test_plot",
        "description": "hypertools.tests.test_plot",
        "peekOfCode": "mpl.rcParams['figure.max_open_warning'] = 25\n## STATIC ##\ndef test_plot_1d():\n    data_reduced_1d = reducer(data, ndims=1)\n    geo = plot.plot(data_reduced_1d, show=False)\n    assert all([i.shape[1]==1 for i in geo.data])\ndef test_plot_2d():\n    data_reduced_2d = reducer(data, ndims=2)\n    geo = plot.plot(data_reduced_2d, show=False)\n    assert all([i.shape[1]==2 for i in geo.data])",
        "detail": "hypertools.tests.test_plot",
        "documentation": {}
    },
    {
        "label": "test_procrustes_func",
        "kind": 2,
        "importPath": "hypertools.tests.test_procrustes",
        "description": "hypertools.tests.test_procrustes",
        "peekOfCode": "def test_procrustes_func():\n    target = load('spiral').get_data()[0]\n    rot = np.array([[-0.89433495, -0.44719485, -0.01348182],\n           [-0.43426149,  0.87492975, -0.21427761],\n           [-0.10761949,  0.18578133,  0.97667976]])\n    source = np.dot(target, rot)\n    source_aligned = procrustes(source,target)\n    assert np.allclose(target,source_aligned)",
        "detail": "hypertools.tests.test_procrustes",
        "documentation": {}
    },
    {
        "label": "test_reduce_is_list",
        "kind": 2,
        "importPath": "hypertools.tests.test_reduce",
        "description": "hypertools.tests.test_reduce",
        "peekOfCode": "def test_reduce_is_list():\n    reduced_data_3d = reducer(data)\n    assert type(reduced_data_3d) is list\ndef test_reduce_is_array():\n    reduced_data_3d = reducer(data, ndims=3)\n    assert isinstance(reduced_data_3d[0],np.ndarray)\ndef test_reduce_dims_3d():\n    reduced_data_3d = reducer(data, ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_dims_2d():",
        "detail": "hypertools.tests.test_reduce",
        "documentation": {}
    },
    {
        "label": "test_reduce_is_array",
        "kind": 2,
        "importPath": "hypertools.tests.test_reduce",
        "description": "hypertools.tests.test_reduce",
        "peekOfCode": "def test_reduce_is_array():\n    reduced_data_3d = reducer(data, ndims=3)\n    assert isinstance(reduced_data_3d[0],np.ndarray)\ndef test_reduce_dims_3d():\n    reduced_data_3d = reducer(data, ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_dims_2d():\n    reduced_data_2d = reducer(data, ndims=2)\n    assert reduced_data_2d[0].shape==(10,2)\ndef test_reduce_dims_1d():",
        "detail": "hypertools.tests.test_reduce",
        "documentation": {}
    },
    {
        "label": "test_reduce_dims_3d",
        "kind": 2,
        "importPath": "hypertools.tests.test_reduce",
        "description": "hypertools.tests.test_reduce",
        "peekOfCode": "def test_reduce_dims_3d():\n    reduced_data_3d = reducer(data, ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_dims_2d():\n    reduced_data_2d = reducer(data, ndims=2)\n    assert reduced_data_2d[0].shape==(10,2)\ndef test_reduce_dims_1d():\n    reduced_data_1d = reducer(data, ndims=1)\n    assert reduced_data_1d[0].shape==(10,1)\ndef test_reduce_geo():",
        "detail": "hypertools.tests.test_reduce",
        "documentation": {}
    },
    {
        "label": "test_reduce_dims_2d",
        "kind": 2,
        "importPath": "hypertools.tests.test_reduce",
        "description": "hypertools.tests.test_reduce",
        "peekOfCode": "def test_reduce_dims_2d():\n    reduced_data_2d = reducer(data, ndims=2)\n    assert reduced_data_2d[0].shape==(10,2)\ndef test_reduce_dims_1d():\n    reduced_data_1d = reducer(data, ndims=1)\n    assert reduced_data_1d[0].shape==(10,1)\ndef test_reduce_geo():\n    geo = plot(data, show=False)\n    reduced_data_3d = reducer(geo, ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)",
        "detail": "hypertools.tests.test_reduce",
        "documentation": {}
    },
    {
        "label": "test_reduce_dims_1d",
        "kind": 2,
        "importPath": "hypertools.tests.test_reduce",
        "description": "hypertools.tests.test_reduce",
        "peekOfCode": "def test_reduce_dims_1d():\n    reduced_data_1d = reducer(data, ndims=1)\n    assert reduced_data_1d[0].shape==(10,1)\ndef test_reduce_geo():\n    geo = plot(data, show=False)\n    reduced_data_3d = reducer(geo, ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_PCA():\n    reduced_data_3d = reducer(data, reduce='PCA', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)",
        "detail": "hypertools.tests.test_reduce",
        "documentation": {}
    },
    {
        "label": "test_reduce_geo",
        "kind": 2,
        "importPath": "hypertools.tests.test_reduce",
        "description": "hypertools.tests.test_reduce",
        "peekOfCode": "def test_reduce_geo():\n    geo = plot(data, show=False)\n    reduced_data_3d = reducer(geo, ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_PCA():\n    reduced_data_3d = reducer(data, reduce='PCA', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_IncrementalPCA():\n    reduced_data_3d = reducer(data, reduce='IncrementalPCA', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)",
        "detail": "hypertools.tests.test_reduce",
        "documentation": {}
    },
    {
        "label": "test_reduce_PCA",
        "kind": 2,
        "importPath": "hypertools.tests.test_reduce",
        "description": "hypertools.tests.test_reduce",
        "peekOfCode": "def test_reduce_PCA():\n    reduced_data_3d = reducer(data, reduce='PCA', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_IncrementalPCA():\n    reduced_data_3d = reducer(data, reduce='IncrementalPCA', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_SparsePCA():\n    reduced_data_3d = reducer(data, reduce='SparsePCA', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_MiniBatchSparsePCA():",
        "detail": "hypertools.tests.test_reduce",
        "documentation": {}
    },
    {
        "label": "test_reduce_IncrementalPCA",
        "kind": 2,
        "importPath": "hypertools.tests.test_reduce",
        "description": "hypertools.tests.test_reduce",
        "peekOfCode": "def test_reduce_IncrementalPCA():\n    reduced_data_3d = reducer(data, reduce='IncrementalPCA', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_SparsePCA():\n    reduced_data_3d = reducer(data, reduce='SparsePCA', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_MiniBatchSparsePCA():\n    reduced_data_3d = reducer(data, reduce='MiniBatchSparsePCA', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_KernelPCA():",
        "detail": "hypertools.tests.test_reduce",
        "documentation": {}
    },
    {
        "label": "test_reduce_SparsePCA",
        "kind": 2,
        "importPath": "hypertools.tests.test_reduce",
        "description": "hypertools.tests.test_reduce",
        "peekOfCode": "def test_reduce_SparsePCA():\n    reduced_data_3d = reducer(data, reduce='SparsePCA', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_MiniBatchSparsePCA():\n    reduced_data_3d = reducer(data, reduce='MiniBatchSparsePCA', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_KernelPCA():\n    reduced_data_3d = reducer(data, reduce='KernelPCA', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_FastICA():",
        "detail": "hypertools.tests.test_reduce",
        "documentation": {}
    },
    {
        "label": "test_reduce_MiniBatchSparsePCA",
        "kind": 2,
        "importPath": "hypertools.tests.test_reduce",
        "description": "hypertools.tests.test_reduce",
        "peekOfCode": "def test_reduce_MiniBatchSparsePCA():\n    reduced_data_3d = reducer(data, reduce='MiniBatchSparsePCA', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_KernelPCA():\n    reduced_data_3d = reducer(data, reduce='KernelPCA', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_FastICA():\n    reduced_data_3d = reducer(data, reduce='FastICA', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_FactorAnalysis():",
        "detail": "hypertools.tests.test_reduce",
        "documentation": {}
    },
    {
        "label": "test_reduce_KernelPCA",
        "kind": 2,
        "importPath": "hypertools.tests.test_reduce",
        "description": "hypertools.tests.test_reduce",
        "peekOfCode": "def test_reduce_KernelPCA():\n    reduced_data_3d = reducer(data, reduce='KernelPCA', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_FastICA():\n    reduced_data_3d = reducer(data, reduce='FastICA', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_FactorAnalysis():\n    reduced_data_3d = reducer(data, reduce='FactorAnalysis', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_TruncatedSVD():",
        "detail": "hypertools.tests.test_reduce",
        "documentation": {}
    },
    {
        "label": "test_reduce_FastICA",
        "kind": 2,
        "importPath": "hypertools.tests.test_reduce",
        "description": "hypertools.tests.test_reduce",
        "peekOfCode": "def test_reduce_FastICA():\n    reduced_data_3d = reducer(data, reduce='FastICA', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_FactorAnalysis():\n    reduced_data_3d = reducer(data, reduce='FactorAnalysis', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_TruncatedSVD():\n    reduced_data_3d = reducer(data, reduce='TruncatedSVD', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_DictionaryLearning():",
        "detail": "hypertools.tests.test_reduce",
        "documentation": {}
    },
    {
        "label": "test_reduce_FactorAnalysis",
        "kind": 2,
        "importPath": "hypertools.tests.test_reduce",
        "description": "hypertools.tests.test_reduce",
        "peekOfCode": "def test_reduce_FactorAnalysis():\n    reduced_data_3d = reducer(data, reduce='FactorAnalysis', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_TruncatedSVD():\n    reduced_data_3d = reducer(data, reduce='TruncatedSVD', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_DictionaryLearning():\n    reduced_data_3d = reducer(data, reduce='DictionaryLearning', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_MiniBatchDictionaryLearning():",
        "detail": "hypertools.tests.test_reduce",
        "documentation": {}
    },
    {
        "label": "test_reduce_TruncatedSVD",
        "kind": 2,
        "importPath": "hypertools.tests.test_reduce",
        "description": "hypertools.tests.test_reduce",
        "peekOfCode": "def test_reduce_TruncatedSVD():\n    reduced_data_3d = reducer(data, reduce='TruncatedSVD', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_DictionaryLearning():\n    reduced_data_3d = reducer(data, reduce='DictionaryLearning', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_MiniBatchDictionaryLearning():\n    reduced_data_3d = reducer(data, reduce='MiniBatchDictionaryLearning', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_TSNE():",
        "detail": "hypertools.tests.test_reduce",
        "documentation": {}
    },
    {
        "label": "test_reduce_DictionaryLearning",
        "kind": 2,
        "importPath": "hypertools.tests.test_reduce",
        "description": "hypertools.tests.test_reduce",
        "peekOfCode": "def test_reduce_DictionaryLearning():\n    reduced_data_3d = reducer(data, reduce='DictionaryLearning', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_MiniBatchDictionaryLearning():\n    reduced_data_3d = reducer(data, reduce='MiniBatchDictionaryLearning', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_TSNE():\n    reduced_data_3d = reducer(data, reduce='TSNE', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_Isomap():",
        "detail": "hypertools.tests.test_reduce",
        "documentation": {}
    },
    {
        "label": "test_reduce_MiniBatchDictionaryLearning",
        "kind": 2,
        "importPath": "hypertools.tests.test_reduce",
        "description": "hypertools.tests.test_reduce",
        "peekOfCode": "def test_reduce_MiniBatchDictionaryLearning():\n    reduced_data_3d = reducer(data, reduce='MiniBatchDictionaryLearning', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_TSNE():\n    reduced_data_3d = reducer(data, reduce='TSNE', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_Isomap():\n    reduced_data_3d = reducer(data, reduce='Isomap', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_SpectralEmbedding():",
        "detail": "hypertools.tests.test_reduce",
        "documentation": {}
    },
    {
        "label": "test_reduce_TSNE",
        "kind": 2,
        "importPath": "hypertools.tests.test_reduce",
        "description": "hypertools.tests.test_reduce",
        "peekOfCode": "def test_reduce_TSNE():\n    reduced_data_3d = reducer(data, reduce='TSNE', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_Isomap():\n    reduced_data_3d = reducer(data, reduce='Isomap', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_SpectralEmbedding():\n    reduced_data_3d = reducer(data, reduce='SpectralEmbedding', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_LocallyLinearEmbedding():",
        "detail": "hypertools.tests.test_reduce",
        "documentation": {}
    },
    {
        "label": "test_reduce_Isomap",
        "kind": 2,
        "importPath": "hypertools.tests.test_reduce",
        "description": "hypertools.tests.test_reduce",
        "peekOfCode": "def test_reduce_Isomap():\n    reduced_data_3d = reducer(data, reduce='Isomap', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_SpectralEmbedding():\n    reduced_data_3d = reducer(data, reduce='SpectralEmbedding', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_LocallyLinearEmbedding():\n    reduced_data_3d = reducer(data, reduce='LocallyLinearEmbedding', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_MDS():",
        "detail": "hypertools.tests.test_reduce",
        "documentation": {}
    },
    {
        "label": "test_reduce_SpectralEmbedding",
        "kind": 2,
        "importPath": "hypertools.tests.test_reduce",
        "description": "hypertools.tests.test_reduce",
        "peekOfCode": "def test_reduce_SpectralEmbedding():\n    reduced_data_3d = reducer(data, reduce='SpectralEmbedding', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_LocallyLinearEmbedding():\n    reduced_data_3d = reducer(data, reduce='LocallyLinearEmbedding', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_MDS():\n    reduced_data_3d = reducer(data, reduce='MDS', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_UMAP():",
        "detail": "hypertools.tests.test_reduce",
        "documentation": {}
    },
    {
        "label": "test_reduce_LocallyLinearEmbedding",
        "kind": 2,
        "importPath": "hypertools.tests.test_reduce",
        "description": "hypertools.tests.test_reduce",
        "peekOfCode": "def test_reduce_LocallyLinearEmbedding():\n    reduced_data_3d = reducer(data, reduce='LocallyLinearEmbedding', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_MDS():\n    reduced_data_3d = reducer(data, reduce='MDS', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_UMAP():\n    reduced_data_3d = reducer(data, reduce='UMAP', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_params_UMAP():",
        "detail": "hypertools.tests.test_reduce",
        "documentation": {}
    },
    {
        "label": "test_reduce_MDS",
        "kind": 2,
        "importPath": "hypertools.tests.test_reduce",
        "description": "hypertools.tests.test_reduce",
        "peekOfCode": "def test_reduce_MDS():\n    reduced_data_3d = reducer(data, reduce='MDS', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_UMAP():\n    reduced_data_3d = reducer(data, reduce='UMAP', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_params_UMAP():\n    from umap import UMAP\n    data1 = np.random.rand(20, 10)\n    params = {'n_neighbors': 5, 'n_components': 2, 'metric': 'correlation', 'random_state': 1234}",
        "detail": "hypertools.tests.test_reduce",
        "documentation": {}
    },
    {
        "label": "test_reduce_UMAP",
        "kind": 2,
        "importPath": "hypertools.tests.test_reduce",
        "description": "hypertools.tests.test_reduce",
        "peekOfCode": "def test_reduce_UMAP():\n    reduced_data_3d = reducer(data, reduce='UMAP', ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)\ndef test_reduce_params_UMAP():\n    from umap import UMAP\n    data1 = np.random.rand(20, 10)\n    params = {'n_neighbors': 5, 'n_components': 2, 'metric': 'correlation', 'random_state': 1234}\n    # testing override of n_dims by n_components. Should raise UserWarning due to conflict\n    hyp_data = reducer(data1, reduce={'model': 'UMAP', 'params': params}, ndims=3)\n    umap_data = UMAP(**params).fit_transform(data1)",
        "detail": "hypertools.tests.test_reduce",
        "documentation": {}
    },
    {
        "label": "test_reduce_params_UMAP",
        "kind": 2,
        "importPath": "hypertools.tests.test_reduce",
        "description": "hypertools.tests.test_reduce",
        "peekOfCode": "def test_reduce_params_UMAP():\n    from umap import UMAP\n    data1 = np.random.rand(20, 10)\n    params = {'n_neighbors': 5, 'n_components': 2, 'metric': 'correlation', 'random_state': 1234}\n    # testing override of n_dims by n_components. Should raise UserWarning due to conflict\n    hyp_data = reducer(data1, reduce={'model': 'UMAP', 'params': params}, ndims=3)\n    umap_data = UMAP(**params).fit_transform(data1)\n    np.testing.assert_array_equal(hyp_data, umap_data)",
        "detail": "hypertools.tests.test_reduce",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "hypertools.tests.test_reduce",
        "description": "hypertools.tests.test_reduce",
        "peekOfCode": "data = [np.random.multivariate_normal(np.zeros(4), np.eye(4), size=10) for i in range(2)]\nreduced_data_2d = reducer(data,ndims=2)\nreduced_data_1d = reducer(data,ndims=1)\ndef test_reduce_is_list():\n    reduced_data_3d = reducer(data)\n    assert type(reduced_data_3d) is list\ndef test_reduce_is_array():\n    reduced_data_3d = reducer(data, ndims=3)\n    assert isinstance(reduced_data_3d[0],np.ndarray)\ndef test_reduce_dims_3d():",
        "detail": "hypertools.tests.test_reduce",
        "documentation": {}
    },
    {
        "label": "reduced_data_2d",
        "kind": 5,
        "importPath": "hypertools.tests.test_reduce",
        "description": "hypertools.tests.test_reduce",
        "peekOfCode": "reduced_data_2d = reducer(data,ndims=2)\nreduced_data_1d = reducer(data,ndims=1)\ndef test_reduce_is_list():\n    reduced_data_3d = reducer(data)\n    assert type(reduced_data_3d) is list\ndef test_reduce_is_array():\n    reduced_data_3d = reducer(data, ndims=3)\n    assert isinstance(reduced_data_3d[0],np.ndarray)\ndef test_reduce_dims_3d():\n    reduced_data_3d = reducer(data, ndims=3)",
        "detail": "hypertools.tests.test_reduce",
        "documentation": {}
    },
    {
        "label": "reduced_data_1d",
        "kind": 5,
        "importPath": "hypertools.tests.test_reduce",
        "description": "hypertools.tests.test_reduce",
        "peekOfCode": "reduced_data_1d = reducer(data,ndims=1)\ndef test_reduce_is_list():\n    reduced_data_3d = reducer(data)\n    assert type(reduced_data_3d) is list\ndef test_reduce_is_array():\n    reduced_data_3d = reducer(data, ndims=3)\n    assert isinstance(reduced_data_3d[0],np.ndarray)\ndef test_reduce_dims_3d():\n    reduced_data_3d = reducer(data, ndims=3)\n    assert reduced_data_3d[0].shape==(10,3)",
        "detail": "hypertools.tests.test_reduce",
        "documentation": {}
    },
    {
        "label": "test_transform_text",
        "kind": 2,
        "importPath": "hypertools.tests.test_text2mat",
        "description": "hypertools.tests.test_text2mat",
        "peekOfCode": "def test_transform_text():\n    assert isinstance(text2mat(data)[0], np.ndarray)\ndef test_count_LDA():\n    isinstance(text2mat(data, vectorizer='CountVectorizer',\n                        semantic='LatentDirichletAllocation', corpus=data)[0], np.ndarray)\ndef test_tfidf_LDA():\n    isinstance(text2mat(data, vectorizer='TfidfVectorizer',\n                        semantic='LatentDirichletAllocation', corpus=data)[0], np.ndarray)\ndef test_count_NMF():\n    isinstance(text2mat(data, vectorizer='CountVectorizer', semantic='NMF', corpus=data)[0], np.ndarray)",
        "detail": "hypertools.tests.test_text2mat",
        "documentation": {}
    },
    {
        "label": "test_count_LDA",
        "kind": 2,
        "importPath": "hypertools.tests.test_text2mat",
        "description": "hypertools.tests.test_text2mat",
        "peekOfCode": "def test_count_LDA():\n    isinstance(text2mat(data, vectorizer='CountVectorizer',\n                        semantic='LatentDirichletAllocation', corpus=data)[0], np.ndarray)\ndef test_tfidf_LDA():\n    isinstance(text2mat(data, vectorizer='TfidfVectorizer',\n                        semantic='LatentDirichletAllocation', corpus=data)[0], np.ndarray)\ndef test_count_NMF():\n    isinstance(text2mat(data, vectorizer='CountVectorizer', semantic='NMF', corpus=data)[0], np.ndarray)\ndef test_tfidf_NMF():\n    isinstance(text2mat(data, vectorizer='TfidfVectorizer', semantic='NMF', corpus=data)[0], np.ndarray)",
        "detail": "hypertools.tests.test_text2mat",
        "documentation": {}
    },
    {
        "label": "test_tfidf_LDA",
        "kind": 2,
        "importPath": "hypertools.tests.test_text2mat",
        "description": "hypertools.tests.test_text2mat",
        "peekOfCode": "def test_tfidf_LDA():\n    isinstance(text2mat(data, vectorizer='TfidfVectorizer',\n                        semantic='LatentDirichletAllocation', corpus=data)[0], np.ndarray)\ndef test_count_NMF():\n    isinstance(text2mat(data, vectorizer='CountVectorizer', semantic='NMF', corpus=data)[0], np.ndarray)\ndef test_tfidf_NMF():\n    isinstance(text2mat(data, vectorizer='TfidfVectorizer', semantic='NMF', corpus=data)[0], np.ndarray)\ndef test_transform_no_text_model():\n    assert isinstance(text2mat(data, semantic=None, corpus=data)[0], np.ndarray)\ndef test_text_model_params():",
        "detail": "hypertools.tests.test_text2mat",
        "documentation": {}
    },
    {
        "label": "test_count_NMF",
        "kind": 2,
        "importPath": "hypertools.tests.test_text2mat",
        "description": "hypertools.tests.test_text2mat",
        "peekOfCode": "def test_count_NMF():\n    isinstance(text2mat(data, vectorizer='CountVectorizer', semantic='NMF', corpus=data)[0], np.ndarray)\ndef test_tfidf_NMF():\n    isinstance(text2mat(data, vectorizer='TfidfVectorizer', semantic='NMF', corpus=data)[0], np.ndarray)\ndef test_transform_no_text_model():\n    assert isinstance(text2mat(data, semantic=None, corpus=data)[0], np.ndarray)\ndef test_text_model_params():\n    assert isinstance(text2mat(data, semantic={\n        'model' : 'LatentDirichletAllocation',\n        'params' : {",
        "detail": "hypertools.tests.test_text2mat",
        "documentation": {}
    },
    {
        "label": "test_tfidf_NMF",
        "kind": 2,
        "importPath": "hypertools.tests.test_text2mat",
        "description": "hypertools.tests.test_text2mat",
        "peekOfCode": "def test_tfidf_NMF():\n    isinstance(text2mat(data, vectorizer='TfidfVectorizer', semantic='NMF', corpus=data)[0], np.ndarray)\ndef test_transform_no_text_model():\n    assert isinstance(text2mat(data, semantic=None, corpus=data)[0], np.ndarray)\ndef test_text_model_params():\n    assert isinstance(text2mat(data, semantic={\n        'model' : 'LatentDirichletAllocation',\n        'params' : {\n            'learning_method' : 'batch'\n            }}",
        "detail": "hypertools.tests.test_text2mat",
        "documentation": {}
    },
    {
        "label": "test_transform_no_text_model",
        "kind": 2,
        "importPath": "hypertools.tests.test_text2mat",
        "description": "hypertools.tests.test_text2mat",
        "peekOfCode": "def test_transform_no_text_model():\n    assert isinstance(text2mat(data, semantic=None, corpus=data)[0], np.ndarray)\ndef test_text_model_params():\n    assert isinstance(text2mat(data, semantic={\n        'model' : 'LatentDirichletAllocation',\n        'params' : {\n            'learning_method' : 'batch'\n            }}\n        , corpus=data)[0], np.ndarray)\ndef test_vectorizer_params():",
        "detail": "hypertools.tests.test_text2mat",
        "documentation": {}
    },
    {
        "label": "test_text_model_params",
        "kind": 2,
        "importPath": "hypertools.tests.test_text2mat",
        "description": "hypertools.tests.test_text2mat",
        "peekOfCode": "def test_text_model_params():\n    assert isinstance(text2mat(data, semantic={\n        'model' : 'LatentDirichletAllocation',\n        'params' : {\n            'learning_method' : 'batch'\n            }}\n        , corpus=data)[0], np.ndarray)\ndef test_vectorizer_params():\n    assert text2mat(data, vectorizer={\n        'model' : 'CountVectorizer',",
        "detail": "hypertools.tests.test_text2mat",
        "documentation": {}
    },
    {
        "label": "test_vectorizer_params",
        "kind": 2,
        "importPath": "hypertools.tests.test_text2mat",
        "description": "hypertools.tests.test_text2mat",
        "peekOfCode": "def test_vectorizer_params():\n    assert text2mat(data, vectorizer={\n        'model' : 'CountVectorizer',\n        'params': {\n        'max_features' : 2\n        }}, corpus=data)[0].shape[1]==20\ndef test_LDA_class():\n    assert text2mat(data, semantic=LatentDirichletAllocation, corpus=data)[0].shape[1]==10\ndef test_LDA_class_instance():\n    user_model = LatentDirichletAllocation(n_components=15)",
        "detail": "hypertools.tests.test_text2mat",
        "documentation": {}
    },
    {
        "label": "test_LDA_class",
        "kind": 2,
        "importPath": "hypertools.tests.test_text2mat",
        "description": "hypertools.tests.test_text2mat",
        "peekOfCode": "def test_LDA_class():\n    assert text2mat(data, semantic=LatentDirichletAllocation, corpus=data)[0].shape[1]==10\ndef test_LDA_class_instance():\n    user_model = LatentDirichletAllocation(n_components=15)\n    assert text2mat(data, semantic=user_model, corpus=data)[0].shape[1]==15\ndef test_corpus():\n    assert text2mat(data, corpus=data)[0].shape[1]==20",
        "detail": "hypertools.tests.test_text2mat",
        "documentation": {}
    },
    {
        "label": "test_LDA_class_instance",
        "kind": 2,
        "importPath": "hypertools.tests.test_text2mat",
        "description": "hypertools.tests.test_text2mat",
        "peekOfCode": "def test_LDA_class_instance():\n    user_model = LatentDirichletAllocation(n_components=15)\n    assert text2mat(data, semantic=user_model, corpus=data)[0].shape[1]==15\ndef test_corpus():\n    assert text2mat(data, corpus=data)[0].shape[1]==20",
        "detail": "hypertools.tests.test_text2mat",
        "documentation": {}
    },
    {
        "label": "test_corpus",
        "kind": 2,
        "importPath": "hypertools.tests.test_text2mat",
        "description": "hypertools.tests.test_text2mat",
        "peekOfCode": "def test_corpus():\n    assert text2mat(data, corpus=data)[0].shape[1]==20",
        "detail": "hypertools.tests.test_text2mat",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "hypertools.tests.test_text2mat",
        "description": "hypertools.tests.test_text2mat",
        "peekOfCode": "data = [['i like cats alot', 'cats r pretty cool', 'cats are better than dogs'],\n        ['dogs rule the haus', 'dogs are my jam', 'dogs are a mans best friend']]\ndef test_transform_text():\n    assert isinstance(text2mat(data)[0], np.ndarray)\ndef test_count_LDA():\n    isinstance(text2mat(data, vectorizer='CountVectorizer',\n                        semantic='LatentDirichletAllocation', corpus=data)[0], np.ndarray)\ndef test_tfidf_LDA():\n    isinstance(text2mat(data, vectorizer='TfidfVectorizer',\n                        semantic='LatentDirichletAllocation', corpus=data)[0], np.ndarray)",
        "detail": "hypertools.tests.test_text2mat",
        "documentation": {}
    },
    {
        "label": "os.environ[\"MPLCONFIGDIR\"]",
        "kind": 5,
        "importPath": "hypertools.setup",
        "description": "hypertools.setup",
        "peekOfCode": "os.environ[\"MPLCONFIGDIR\"] = \".\"\nNAME = 'hypertools'\nVERSION = '0.8.0'\nAUTHOR = 'Contextual Dynamics Lab'\nAUTHOR_EMAIL = 'contextualdynamics@gmail.com'\nURL = 'https://github.com/ContextLab/hypertools'\nDOWNLOAD_URL = URL\nLICENSE = 'MIT'\nREQUIRES_PYTHON = '>=3.9'\nPACKAGES = find_packages(exclude=('images', 'examples', 'tests'))",
        "detail": "hypertools.setup",
        "documentation": {}
    },
    {
        "label": "NAME",
        "kind": 5,
        "importPath": "hypertools.setup",
        "description": "hypertools.setup",
        "peekOfCode": "NAME = 'hypertools'\nVERSION = '0.8.0'\nAUTHOR = 'Contextual Dynamics Lab'\nAUTHOR_EMAIL = 'contextualdynamics@gmail.com'\nURL = 'https://github.com/ContextLab/hypertools'\nDOWNLOAD_URL = URL\nLICENSE = 'MIT'\nREQUIRES_PYTHON = '>=3.9'\nPACKAGES = find_packages(exclude=('images', 'examples', 'tests'))\nwith open('requirements.txt', 'r') as f:",
        "detail": "hypertools.setup",
        "documentation": {}
    },
    {
        "label": "VERSION",
        "kind": 5,
        "importPath": "hypertools.setup",
        "description": "hypertools.setup",
        "peekOfCode": "VERSION = '0.8.0'\nAUTHOR = 'Contextual Dynamics Lab'\nAUTHOR_EMAIL = 'contextualdynamics@gmail.com'\nURL = 'https://github.com/ContextLab/hypertools'\nDOWNLOAD_URL = URL\nLICENSE = 'MIT'\nREQUIRES_PYTHON = '>=3.9'\nPACKAGES = find_packages(exclude=('images', 'examples', 'tests'))\nwith open('requirements.txt', 'r') as f:\n    REQUIREMENTS = f.read().splitlines()",
        "detail": "hypertools.setup",
        "documentation": {}
    },
    {
        "label": "AUTHOR",
        "kind": 5,
        "importPath": "hypertools.setup",
        "description": "hypertools.setup",
        "peekOfCode": "AUTHOR = 'Contextual Dynamics Lab'\nAUTHOR_EMAIL = 'contextualdynamics@gmail.com'\nURL = 'https://github.com/ContextLab/hypertools'\nDOWNLOAD_URL = URL\nLICENSE = 'MIT'\nREQUIRES_PYTHON = '>=3.9'\nPACKAGES = find_packages(exclude=('images', 'examples', 'tests'))\nwith open('requirements.txt', 'r') as f:\n    REQUIREMENTS = f.read().splitlines()\nDESCRIPTION = 'A python package for visualizing and manipulating high-dimensional data'",
        "detail": "hypertools.setup",
        "documentation": {}
    },
    {
        "label": "AUTHOR_EMAIL",
        "kind": 5,
        "importPath": "hypertools.setup",
        "description": "hypertools.setup",
        "peekOfCode": "AUTHOR_EMAIL = 'contextualdynamics@gmail.com'\nURL = 'https://github.com/ContextLab/hypertools'\nDOWNLOAD_URL = URL\nLICENSE = 'MIT'\nREQUIRES_PYTHON = '>=3.9'\nPACKAGES = find_packages(exclude=('images', 'examples', 'tests'))\nwith open('requirements.txt', 'r') as f:\n    REQUIREMENTS = f.read().splitlines()\nDESCRIPTION = 'A python package for visualizing and manipulating high-dimensional data'\nLONG_DESCRIPTION = \"\"\"\\",
        "detail": "hypertools.setup",
        "documentation": {}
    },
    {
        "label": "URL",
        "kind": 5,
        "importPath": "hypertools.setup",
        "description": "hypertools.setup",
        "peekOfCode": "URL = 'https://github.com/ContextLab/hypertools'\nDOWNLOAD_URL = URL\nLICENSE = 'MIT'\nREQUIRES_PYTHON = '>=3.9'\nPACKAGES = find_packages(exclude=('images', 'examples', 'tests'))\nwith open('requirements.txt', 'r') as f:\n    REQUIREMENTS = f.read().splitlines()\nDESCRIPTION = 'A python package for visualizing and manipulating high-dimensional data'\nLONG_DESCRIPTION = \"\"\"\\\nHyperTools is a library for visualizing and manipulating high-dimensional data in Python. It is built on top of matplotlib (for plotting), seaborn (for plot styling), and scikit-learn (for data manipulation).",
        "detail": "hypertools.setup",
        "documentation": {}
    },
    {
        "label": "DOWNLOAD_URL",
        "kind": 5,
        "importPath": "hypertools.setup",
        "description": "hypertools.setup",
        "peekOfCode": "DOWNLOAD_URL = URL\nLICENSE = 'MIT'\nREQUIRES_PYTHON = '>=3.9'\nPACKAGES = find_packages(exclude=('images', 'examples', 'tests'))\nwith open('requirements.txt', 'r') as f:\n    REQUIREMENTS = f.read().splitlines()\nDESCRIPTION = 'A python package for visualizing and manipulating high-dimensional data'\nLONG_DESCRIPTION = \"\"\"\\\nHyperTools is a library for visualizing and manipulating high-dimensional data in Python. It is built on top of matplotlib (for plotting), seaborn (for plot styling), and scikit-learn (for data manipulation).\nFor sample Jupyter notebooks using the package: https://github.com/ContextLab/hypertools-paper-notebooks",
        "detail": "hypertools.setup",
        "documentation": {}
    },
    {
        "label": "LICENSE",
        "kind": 5,
        "importPath": "hypertools.setup",
        "description": "hypertools.setup",
        "peekOfCode": "LICENSE = 'MIT'\nREQUIRES_PYTHON = '>=3.9'\nPACKAGES = find_packages(exclude=('images', 'examples', 'tests'))\nwith open('requirements.txt', 'r') as f:\n    REQUIREMENTS = f.read().splitlines()\nDESCRIPTION = 'A python package for visualizing and manipulating high-dimensional data'\nLONG_DESCRIPTION = \"\"\"\\\nHyperTools is a library for visualizing and manipulating high-dimensional data in Python. It is built on top of matplotlib (for plotting), seaborn (for plot styling), and scikit-learn (for data manipulation).\nFor sample Jupyter notebooks using the package: https://github.com/ContextLab/hypertools-paper-notebooks\nFor more examples: https://github.com/ContextLab/hypertools/tree/master/examples",
        "detail": "hypertools.setup",
        "documentation": {}
    },
    {
        "label": "REQUIRES_PYTHON",
        "kind": 5,
        "importPath": "hypertools.setup",
        "description": "hypertools.setup",
        "peekOfCode": "REQUIRES_PYTHON = '>=3.9'\nPACKAGES = find_packages(exclude=('images', 'examples', 'tests'))\nwith open('requirements.txt', 'r') as f:\n    REQUIREMENTS = f.read().splitlines()\nDESCRIPTION = 'A python package for visualizing and manipulating high-dimensional data'\nLONG_DESCRIPTION = \"\"\"\\\nHyperTools is a library for visualizing and manipulating high-dimensional data in Python. It is built on top of matplotlib (for plotting), seaborn (for plot styling), and scikit-learn (for data manipulation).\nFor sample Jupyter notebooks using the package: https://github.com/ContextLab/hypertools-paper-notebooks\nFor more examples: https://github.com/ContextLab/hypertools/tree/master/examples\nSome key features of HyperTools are:",
        "detail": "hypertools.setup",
        "documentation": {}
    },
    {
        "label": "PACKAGES",
        "kind": 5,
        "importPath": "hypertools.setup",
        "description": "hypertools.setup",
        "peekOfCode": "PACKAGES = find_packages(exclude=('images', 'examples', 'tests'))\nwith open('requirements.txt', 'r') as f:\n    REQUIREMENTS = f.read().splitlines()\nDESCRIPTION = 'A python package for visualizing and manipulating high-dimensional data'\nLONG_DESCRIPTION = \"\"\"\\\nHyperTools is a library for visualizing and manipulating high-dimensional data in Python. It is built on top of matplotlib (for plotting), seaborn (for plot styling), and scikit-learn (for data manipulation).\nFor sample Jupyter notebooks using the package: https://github.com/ContextLab/hypertools-paper-notebooks\nFor more examples: https://github.com/ContextLab/hypertools/tree/master/examples\nSome key features of HyperTools are:\n- Functions for plotting high-dimensional datasets in 2/3D.",
        "detail": "hypertools.setup",
        "documentation": {}
    },
    {
        "label": "DESCRIPTION",
        "kind": 5,
        "importPath": "hypertools.setup",
        "description": "hypertools.setup",
        "peekOfCode": "DESCRIPTION = 'A python package for visualizing and manipulating high-dimensional data'\nLONG_DESCRIPTION = \"\"\"\\\nHyperTools is a library for visualizing and manipulating high-dimensional data in Python. It is built on top of matplotlib (for plotting), seaborn (for plot styling), and scikit-learn (for data manipulation).\nFor sample Jupyter notebooks using the package: https://github.com/ContextLab/hypertools-paper-notebooks\nFor more examples: https://github.com/ContextLab/hypertools/tree/master/examples\nSome key features of HyperTools are:\n- Functions for plotting high-dimensional datasets in 2/3D.\n- Static and animated plots\n- Simple API for customizing plot styles\n- A set of powerful data manipulation tools including hyperalignment, k-means clustering, normalizing and more.",
        "detail": "hypertools.setup",
        "documentation": {}
    },
    {
        "label": "LONG_DESCRIPTION",
        "kind": 5,
        "importPath": "hypertools.setup",
        "description": "hypertools.setup",
        "peekOfCode": "LONG_DESCRIPTION = \"\"\"\\\nHyperTools is a library for visualizing and manipulating high-dimensional data in Python. It is built on top of matplotlib (for plotting), seaborn (for plot styling), and scikit-learn (for data manipulation).\nFor sample Jupyter notebooks using the package: https://github.com/ContextLab/hypertools-paper-notebooks\nFor more examples: https://github.com/ContextLab/hypertools/tree/master/examples\nSome key features of HyperTools are:\n- Functions for plotting high-dimensional datasets in 2/3D.\n- Static and animated plots\n- Simple API for customizing plot styles\n- A set of powerful data manipulation tools including hyperalignment, k-means clustering, normalizing and more.\n- Support for lists of Numpy arrays, Pandas dataframes, String, Geos or mixed lists.",
        "detail": "hypertools.setup",
        "documentation": {}
    },
    {
        "label": "CLASSIFIERS",
        "kind": 5,
        "importPath": "hypertools.setup",
        "description": "hypertools.setup",
        "peekOfCode": "CLASSIFIERS = [\n    'Intended Audience :: Science/Research',\n    'Programming Language :: Python :: 3.9',\n    'Programming Language :: Python :: 3.10',\n    'Programming Language :: Python :: 3.11',\n    'Programming Language :: Python :: 3.12',\n    'Topic :: Scientific/Engineering :: Visualization',\n    'Topic :: Multimedia :: Graphics',\n    'Operating System :: POSIX',\n    'Operating System :: Unix',",
        "detail": "hypertools.setup",
        "documentation": {}
    },
    {
        "label": "create_celestial_rules",
        "kind": 2,
        "importPath": "src.word_manifold.automata.additional_rules",
        "description": "src.word_manifold.automata.additional_rules",
        "peekOfCode": "def create_celestial_rules() -> Dict[str, CellularRule]:\n    \"\"\"\n    Create rules based on celestial bodies and higher spiritual archetypes.\n    These rules complement the base rule set by adding transformations\n    related to cosmic forces and stellar/planetary influences.\n    Returns:\n        Dictionary mapping rule names to CellularRule objects\n    \"\"\"\n    rules = {}",
        "detail": "src.word_manifold.automata.additional_rules",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "src.word_manifold.automata.additional_rules",
        "description": "src.word_manifold.automata.additional_rules",
        "peekOfCode": "logger = logging.getLogger(__name__)\ndef create_celestial_rules() -> Dict[str, CellularRule]:\n    \"\"\"\n    Create rules based on celestial bodies and higher spiritual archetypes.\n    These rules complement the base rule set by adding transformations\n    related to cosmic forces and stellar/planetary influences.\n    Returns:\n        Dictionary mapping rule names to CellularRule objects\n    \"\"\"\n    rules = {}",
        "detail": "src.word_manifold.automata.additional_rules",
        "documentation": {}
    },
    {
        "label": "HermeticPrinciple",
        "kind": 6,
        "importPath": "src.word_manifold.automata.cellular_rules",
        "description": "src.word_manifold.automata.cellular_rules",
        "peekOfCode": "class HermeticPrinciple(Enum):\n    \"\"\"The seven Hermetic principles that govern transformation rules.\"\"\"\n    MENTALISM = auto()         # \"THE ALL is MIND; The Universe is Mental.\"\n    CORRESPONDENCE = auto()    # \"As above, so below; as below, so above.\"\n    VIBRATION = auto()         # \"Nothing rests; everything moves; everything vibrates.\"\n    POLARITY = auto()          # \"Everything is Dual; everything has poles.\"\n    RHYTHM = auto()            # \"Everything flows, out and in; everything has its tides.\"\n    CAUSE_EFFECT = auto()      # \"Every Cause has its Effect; Every Effect has its Cause.\"\n    GENDER = auto()            # \"Gender is in everything; everything has its Masculine and Feminine.\"\nclass ElementalForce(Enum):",
        "detail": "src.word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "ElementalForce",
        "kind": 6,
        "importPath": "src.word_manifold.automata.cellular_rules",
        "description": "src.word_manifold.automata.cellular_rules",
        "peekOfCode": "class ElementalForce(Enum):\n    \"\"\"The four elemental forces that influence transformation.\"\"\"\n    EARTH = auto()  # Stability, materiality, resistance to change\n    AIR = auto()    # Intellect, communication, adaptability\n    FIRE = auto()   # Energy, transformation, creation/destruction\n    WATER = auto()  # Emotion, intuition, connection\nclass VibrationDirection(Enum):\n    \"\"\"Possible directions of vibrational change in the vector space.\"\"\"\n    ASCENDING = auto()  # Moving towards higher vibration (complexity, abstraction)\n    DESCENDING = auto() # Moving towards lower vibration (simplicity, concreteness)",
        "detail": "src.word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "VibrationDirection",
        "kind": 6,
        "importPath": "src.word_manifold.automata.cellular_rules",
        "description": "src.word_manifold.automata.cellular_rules",
        "peekOfCode": "class VibrationDirection(Enum):\n    \"\"\"Possible directions of vibrational change in the vector space.\"\"\"\n    ASCENDING = auto()  # Moving towards higher vibration (complexity, abstraction)\n    DESCENDING = auto() # Moving towards lower vibration (simplicity, concreteness)\n    EXPANDING = auto()  # Increasing in scope or influence\n    CONTRACTING = auto() # Decreasing in scope or influence\n    HARMONIZING = auto() # Moving towards balance with neighbors\n    POLARIZING = auto()  # Moving away from neighbors, increasing distinction\n@dataclass\nclass RuleParameterSet:",
        "detail": "src.word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "RuleParameterSet",
        "kind": 6,
        "importPath": "src.word_manifold.automata.cellular_rules",
        "description": "src.word_manifold.automata.cellular_rules",
        "peekOfCode": "class RuleParameterSet:\n    \"\"\"Parameters that define how a transformation rule behaves.\"\"\"\n    magnitude: float = 1.0                  # Base strength of transformation\n    principle: HermeticPrinciple = HermeticPrinciple.CORRESPONDENCE\n    elemental_influence: Dict[ElementalForce, float] = None  # Influence of each element\n    numerological_weights: Dict[int, float] = None  # Weights by numerological value\n    cell_type_weights: Dict[CellType, float] = None  # Weights by cell type\n    vibration_direction: VibrationDirection = VibrationDirection.HARMONIZING\n    def __init__(self, magnitude=1.0, principle=None, vibration_direction=None,\n                 numerological_weights=None, elemental_influence=None, cell_type_weights=None):",
        "detail": "src.word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "CellularRule",
        "kind": 6,
        "importPath": "src.word_manifold.automata.cellular_rules",
        "description": "src.word_manifold.automata.cellular_rules",
        "peekOfCode": "class CellularRule:\n    \"\"\"\n    A rule that defines how cells transform in the vector space.\n    Each rule embodies one or more hermetic principles and governs \n    the evolution of the cellular automata system.\n    \"\"\"\n    def __init__(\n        self, \n        name: str, \n        description: str,",
        "detail": "src.word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "RuleSequence",
        "kind": 6,
        "importPath": "src.word_manifold.automata.cellular_rules",
        "description": "src.word_manifold.automata.cellular_rules",
        "peekOfCode": "class RuleSequence:\n    \"\"\"\n    A sequence of cellular automata rules to be applied in a specific order.\n    The sequence can be applied in different ways:\n    - Sequentially (default): Rules are applied in order\n    - Conditionally: Rules are applied based on conditions\n    - With branching: Different paths can be taken based on state\n    The sequence also supports:\n    - Dependencies between rules\n    - Conditions for rule application",
        "detail": "src.word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "create_predefined_rules",
        "kind": 2,
        "importPath": "src.word_manifold.automata.cellular_rules",
        "description": "src.word_manifold.automata.cellular_rules",
        "peekOfCode": "def create_predefined_rules() -> Dict[str, CellularRule]:\n    \"\"\"\n    Create a set of predefined cellular automata rules based on\n    hermetic principles and occult correspondences.\n    Returns:\n        Dictionary mapping rule names to CellularRule objects\n    \"\"\"\n    rules = {}\n    # The Great Work Rule - Based on alchemical transformation\n    great_work_params = RuleParameterSet(",
        "detail": "src.word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "create_predefined_sequences",
        "kind": 2,
        "importPath": "src.word_manifold.automata.cellular_rules",
        "description": "src.word_manifold.automata.cellular_rules",
        "peekOfCode": "def create_predefined_sequences() -> Dict[str, RuleSequence]:\n    \"\"\"\n    Create a set of predefined rule sequences based on\n    magical rituals and occult correspondences.\n    Returns:\n        Dictionary mapping sequence names to RuleSequence objects\n    \"\"\"\n    rules = create_predefined_rules()\n    sequences = {}\n    # The Great Work Sequence - Alchemical transformation from base to divine",
        "detail": "src.word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "src.word_manifold.automata.cellular_rules",
        "description": "src.word_manifold.automata.cellular_rules",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass HermeticPrinciple(Enum):\n    \"\"\"The seven Hermetic principles that govern transformation rules.\"\"\"\n    MENTALISM = auto()         # \"THE ALL is MIND; The Universe is Mental.\"\n    CORRESPONDENCE = auto()    # \"As above, so below; as below, so above.\"\n    VIBRATION = auto()         # \"Nothing rests; everything moves; everything vibrates.\"\n    POLARITY = auto()          # \"Everything is Dual; everything has poles.\"\n    RHYTHM = auto()            # \"Everything flows, out and in; everything has its tides.\"\n    CAUSE_EFFECT = auto()      # \"Every Cause has its Effect; Every Effect has its Cause.\"\n    GENDER = auto()            # \"Gender is in everything; everything has its Masculine and Feminine.\"",
        "detail": "src.word_manifold.automata.cellular_rules",
        "documentation": {}
    },
    {
        "label": "HermeticPrinciple",
        "kind": 6,
        "importPath": "src.word_manifold.automata.hermetic_principles",
        "description": "src.word_manifold.automata.hermetic_principles",
        "peekOfCode": "class HermeticPrinciple(Enum):\n    \"\"\"The seven hermetic principles from the Kybalion.\"\"\"\n    MENTALISM = auto()      # \"The All is Mind; The Universe is Mental.\"\n    CORRESPONDENCE = auto() # \"As above, so below; as below, so above.\"\n    VIBRATION = auto()     # \"Nothing rests; everything moves; everything vibrates.\"\n    POLARITY = auto()      # \"Everything is dual; everything has poles.\"\n    RHYTHM = auto()        # \"Everything flows, out and in; everything has its tides.\"\n    CAUSATION = auto()     # \"Every cause has its effect; every effect has its cause.\"\n    GENDER = auto()        # \"Gender is in everything; everything has its masculine and feminine principles.\"\n# Principle associations and correspondences",
        "detail": "src.word_manifold.automata.hermetic_principles",
        "documentation": {}
    },
    {
        "label": "EvolutionPattern",
        "kind": 6,
        "importPath": "src.word_manifold.automata.system",
        "description": "src.word_manifold.automata.system",
        "peekOfCode": "class EvolutionPattern(Enum):\n    \"\"\"Patterns of evolution that the automata system can follow.\"\"\"\n    LINEAR = auto()      # Sequential application of rules\n    CYCLIC = auto()      # Repeated application of rules in a cycle\n    SPIRAL = auto()      # Cyclic with increasing intensity\n    CHAOTIC = auto()     # Random selection of rules\n    THELEMIC = auto()    # Rules selected based on True Will principle\n    KABBALISTIC = auto() # Rules follow Tree of Life pattern\n@dataclass\nclass SystemState:",
        "detail": "src.word_manifold.automata.system",
        "documentation": {}
    },
    {
        "label": "SystemState",
        "kind": 6,
        "importPath": "src.word_manifold.automata.system",
        "description": "src.word_manifold.automata.system",
        "peekOfCode": "class SystemState:\n    \"\"\"State of the automata system at a point in time.\"\"\"\n    generation: int                # Current generation number\n    active_rules: List[str]        # Names of rules currently active\n    manifold_state: Dict[str, Any] # State snapshot of the manifold\n    timestamp: float               # Unix timestamp when state was captured\n    metrics: Dict[str, float]      # Metrics about the system's state\nclass AutomataSystem:\n    \"\"\"\n    A system that orchestrates the application of cellular automata rules",
        "detail": "src.word_manifold.automata.system",
        "documentation": {}
    },
    {
        "label": "AutomataSystem",
        "kind": 6,
        "importPath": "src.word_manifold.automata.system",
        "description": "src.word_manifold.automata.system",
        "peekOfCode": "class AutomataSystem:\n    \"\"\"\n    A system that orchestrates the application of cellular automata rules\n    to a word vector manifold according to hermetic principles.\n    This class manages the evolution of the manifold through generations,\n    applying rules according to specified patterns and tracking the system's\n    state over time.\n    \"\"\"\n    def __init__(\n        self,",
        "detail": "src.word_manifold.automata.system",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "src.word_manifold.automata.system",
        "description": "src.word_manifold.automata.system",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass EvolutionPattern(Enum):\n    \"\"\"Patterns of evolution that the automata system can follow.\"\"\"\n    LINEAR = auto()      # Sequential application of rules\n    CYCLIC = auto()      # Repeated application of rules in a cycle\n    SPIRAL = auto()      # Cyclic with increasing intensity\n    CHAOTIC = auto()     # Random selection of rules\n    THELEMIC = auto()    # Rules selected based on True Will principle\n    KABBALISTIC = auto() # Rules follow Tree of Life pattern\n@dataclass",
        "detail": "src.word_manifold.automata.system",
        "documentation": {}
    },
    {
        "label": "PhraseEmbedding",
        "kind": 6,
        "importPath": "src.word_manifold.embeddings.phrase_embeddings",
        "description": "src.word_manifold.embeddings.phrase_embeddings",
        "peekOfCode": "class PhraseEmbedding:\n    \"\"\"\n    A class representing the embedding of a phrase or sentence,\n    including both its semantic content and structural shape.\n    \"\"\"\n    def __init__(self, text: str, embedding: np.ndarray, shape_params: Dict):\n        self.text = text\n        self.embedding = embedding\n        self.shape_params = shape_params\n    def __repr__(self) -> str:",
        "detail": "src.word_manifold.embeddings.phrase_embeddings",
        "documentation": {}
    },
    {
        "label": "PhraseEmbedder",
        "kind": 6,
        "importPath": "src.word_manifold.embeddings.phrase_embeddings",
        "description": "src.word_manifold.embeddings.phrase_embeddings",
        "peekOfCode": "class PhraseEmbedder:\n    \"\"\"\n    A class for embedding phrases and sentences into a semantic manifold,\n    extracting both meaning and structural patterns.\n    \"\"\"\n    def __init__(\n        self,\n        model_name: str = \"BAAI/bge-large-en-v1.5\",  # Updated to use a more recent model\n        emotion_model_name: str = \"SamLowe/roberta-base-go_emotions\",\n        cache_size: int = 1000,",
        "detail": "src.word_manifold.embeddings.phrase_embeddings",
        "documentation": {}
    },
    {
        "label": "load_spacy_model",
        "kind": 2,
        "importPath": "src.word_manifold.embeddings.phrase_embeddings",
        "description": "src.word_manifold.embeddings.phrase_embeddings",
        "peekOfCode": "def load_spacy_model(model_name: str = 'en_core_web_lg') -> spacy.language.Language:\n    \"\"\"Load spaCy model with fallback options.\"\"\"\n    try:\n        logger.info(f\"Loading spaCy model '{model_name}'\")\n        return spacy.load(model_name)\n    except OSError:\n        logger.warning(f\"spaCy model '{model_name}' not found, downloading...\")\n        try:\n            spacy.cli.download(model_name)\n            return spacy.load(model_name)",
        "detail": "src.word_manifold.embeddings.phrase_embeddings",
        "documentation": {}
    },
    {
        "label": "get_emotion_vector",
        "kind": 2,
        "importPath": "src.word_manifold.embeddings.phrase_embeddings",
        "description": "src.word_manifold.embeddings.phrase_embeddings",
        "peekOfCode": "def get_emotion_vector(emotion: str) -> np.ndarray:\n    \"\"\"Get cached emotion vector for a category.\"\"\"\n    words = EMOTION_CATEGORIES[emotion]\n    vectors = []\n    # Try each word in the category\n    for word in words:\n        token = nlp(word)[0]\n        if token.has_vector:\n            vectors.append(token.vector)\n    if not vectors:",
        "detail": "src.word_manifold.embeddings.phrase_embeddings",
        "documentation": {}
    },
    {
        "label": "BACKUP_MODEL",
        "kind": 5,
        "importPath": "src.word_manifold.embeddings.phrase_embeddings",
        "description": "src.word_manifold.embeddings.phrase_embeddings",
        "peekOfCode": "BACKUP_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n# Configure module logger\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.DEBUG)\n# Create formatters and handlers if they don't exist\nif not logger.handlers:\n    # Create console handler with formatting\n    console_handler = logging.StreamHandler()\n    console_handler.setLevel(logging.INFO)\n    console_formatter = logging.Formatter(",
        "detail": "src.word_manifold.embeddings.phrase_embeddings",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "src.word_manifold.embeddings.phrase_embeddings",
        "description": "src.word_manifold.embeddings.phrase_embeddings",
        "peekOfCode": "logger = logging.getLogger(__name__)\nlogger.setLevel(logging.DEBUG)\n# Create formatters and handlers if they don't exist\nif not logger.handlers:\n    # Create console handler with formatting\n    console_handler = logging.StreamHandler()\n    console_handler.setLevel(logging.INFO)\n    console_formatter = logging.Formatter(\n        '%(asctime)s - %(name)s - [%(levelname)s] - %(message)s'\n    )",
        "detail": "src.word_manifold.embeddings.phrase_embeddings",
        "documentation": {}
    },
    {
        "label": "nlp",
        "kind": 5,
        "importPath": "src.word_manifold.embeddings.phrase_embeddings",
        "description": "src.word_manifold.embeddings.phrase_embeddings",
        "peekOfCode": "nlp = load_spacy_model()\n# Enhanced emotion anchors with more nuanced categories\nEMOTION_CATEGORIES = {\n    'joy': ['happy', 'joyful', 'delighted', 'elated', 'ecstatic', 'content', 'pleased'],\n    'sadness': ['sad', 'depressed', 'gloomy', 'melancholy', 'heartbroken', 'grieving', 'unhappy'],\n    'anger': ['angry', 'furious', 'enraged', 'hostile', 'irritated', 'outraged', 'mad'],\n    'fear': ['afraid', 'scared', 'terrified', 'anxious', 'panicked', 'worried', 'frightened'],\n    'surprise': ['surprised', 'amazed', 'astonished', 'shocked', 'startled', 'stunned', 'unexpected'],\n    'disgust': ['disgusted', 'repulsed', 'revolted', 'appalled', 'nauseated', 'offended', 'gross'],\n    'trust': ['trusting', 'confident', 'secure', 'reliable', 'faithful', 'assured', 'believing'],",
        "detail": "src.word_manifold.embeddings.phrase_embeddings",
        "documentation": {}
    },
    {
        "label": "EMOTION_CATEGORIES",
        "kind": 5,
        "importPath": "src.word_manifold.embeddings.phrase_embeddings",
        "description": "src.word_manifold.embeddings.phrase_embeddings",
        "peekOfCode": "EMOTION_CATEGORIES = {\n    'joy': ['happy', 'joyful', 'delighted', 'elated', 'ecstatic', 'content', 'pleased'],\n    'sadness': ['sad', 'depressed', 'gloomy', 'melancholy', 'heartbroken', 'grieving', 'unhappy'],\n    'anger': ['angry', 'furious', 'enraged', 'hostile', 'irritated', 'outraged', 'mad'],\n    'fear': ['afraid', 'scared', 'terrified', 'anxious', 'panicked', 'worried', 'frightened'],\n    'surprise': ['surprised', 'amazed', 'astonished', 'shocked', 'startled', 'stunned', 'unexpected'],\n    'disgust': ['disgusted', 'repulsed', 'revolted', 'appalled', 'nauseated', 'offended', 'gross'],\n    'trust': ['trusting', 'confident', 'secure', 'reliable', 'faithful', 'assured', 'believing'],\n    'anticipation': ['expectant', 'eager', 'excited', 'hopeful', 'optimistic', 'ready', 'awaiting']\n}",
        "detail": "src.word_manifold.embeddings.phrase_embeddings",
        "documentation": {}
    },
    {
        "label": "EMOTION_ANCHORS",
        "kind": 5,
        "importPath": "src.word_manifold.embeddings.phrase_embeddings",
        "description": "src.word_manifold.embeddings.phrase_embeddings",
        "peekOfCode": "EMOTION_ANCHORS = {}\nfor emotion in EMOTION_CATEGORIES:\n    vector = get_emotion_vector(emotion)\n    if np.any(vector):  # Only add emotions with non-zero vectors\n        EMOTION_ANCHORS[emotion] = vector\nclass PhraseEmbedding:\n    \"\"\"\n    A class representing the embedding of a phrase or sentence,\n    including both its semantic content and structural shape.\n    \"\"\"",
        "detail": "src.word_manifold.embeddings.phrase_embeddings",
        "documentation": {}
    },
    {
        "label": "WordEmbeddings",
        "kind": 6,
        "importPath": "src.word_manifold.embeddings.word_embeddings",
        "description": "src.word_manifold.embeddings.word_embeddings",
        "peekOfCode": "class WordEmbeddings:\n    \"\"\"\n    A class for managing word embeddings and related operations.\n    Uses state-of-the-art GTE models for high-quality embeddings with\n    support for long sequences and multilingual content.\n    \"\"\"\n    DEFAULT_MODEL = DEFAULT_MODEL\n    BACKUP_MODEL = BACKUP_MODEL\n    def __init__(self, model_name: str = DEFAULT_MODEL, cache_size: int = 1000):\n        \"\"\"",
        "detail": "src.word_manifold.embeddings.word_embeddings",
        "documentation": {}
    },
    {
        "label": "os.environ[\"TOKENIZERS_PARALLELISM\"]",
        "kind": 5,
        "importPath": "src.word_manifold.embeddings.word_embeddings",
        "description": "src.word_manifold.embeddings.word_embeddings",
        "peekOfCode": "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n# Configure logging\nlogging.basicConfig(level=logging.INFO,\n                   format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger(__name__)\n# Default models\nDEFAULT_MODEL = 'Alibaba-NLP/gte-Qwen2-7B-instruct'\nBACKUP_MODEL = 'Alibaba-NLP/gte-Qwen2-1.5B-instruct'\nclass WordEmbeddings:\n    \"\"\"",
        "detail": "src.word_manifold.embeddings.word_embeddings",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "src.word_manifold.embeddings.word_embeddings",
        "description": "src.word_manifold.embeddings.word_embeddings",
        "peekOfCode": "logger = logging.getLogger(__name__)\n# Default models\nDEFAULT_MODEL = 'Alibaba-NLP/gte-Qwen2-7B-instruct'\nBACKUP_MODEL = 'Alibaba-NLP/gte-Qwen2-1.5B-instruct'\nclass WordEmbeddings:\n    \"\"\"\n    A class for managing word embeddings and related operations.\n    Uses state-of-the-art GTE models for high-quality embeddings with\n    support for long sequences and multilingual content.\n    \"\"\"",
        "detail": "src.word_manifold.embeddings.word_embeddings",
        "documentation": {}
    },
    {
        "label": "DEFAULT_MODEL",
        "kind": 5,
        "importPath": "src.word_manifold.embeddings.word_embeddings",
        "description": "src.word_manifold.embeddings.word_embeddings",
        "peekOfCode": "DEFAULT_MODEL = 'Alibaba-NLP/gte-Qwen2-7B-instruct'\nBACKUP_MODEL = 'Alibaba-NLP/gte-Qwen2-1.5B-instruct'\nclass WordEmbeddings:\n    \"\"\"\n    A class for managing word embeddings and related operations.\n    Uses state-of-the-art GTE models for high-quality embeddings with\n    support for long sequences and multilingual content.\n    \"\"\"\n    DEFAULT_MODEL = DEFAULT_MODEL\n    BACKUP_MODEL = BACKUP_MODEL",
        "detail": "src.word_manifold.embeddings.word_embeddings",
        "documentation": {}
    },
    {
        "label": "BACKUP_MODEL",
        "kind": 5,
        "importPath": "src.word_manifold.embeddings.word_embeddings",
        "description": "src.word_manifold.embeddings.word_embeddings",
        "peekOfCode": "BACKUP_MODEL = 'Alibaba-NLP/gte-Qwen2-1.5B-instruct'\nclass WordEmbeddings:\n    \"\"\"\n    A class for managing word embeddings and related operations.\n    Uses state-of-the-art GTE models for high-quality embeddings with\n    support for long sequences and multilingual content.\n    \"\"\"\n    DEFAULT_MODEL = DEFAULT_MODEL\n    BACKUP_MODEL = BACKUP_MODEL\n    def __init__(self, model_name: str = DEFAULT_MODEL, cache_size: int = 1000):",
        "detail": "src.word_manifold.embeddings.word_embeddings",
        "documentation": {}
    },
    {
        "label": "ForceFieldDemo",
        "kind": 6,
        "importPath": "src.word_manifold.examples.force_field_demo",
        "description": "src.word_manifold.examples.force_field_demo",
        "peekOfCode": "class ForceFieldDemo:\n    def __init__(self, n_dimensions=3):\n        \"\"\"Initialize the force field demonstration.\n        Args:\n            n_dimensions (int): Number of dimensions for the semantic space\n        \"\"\"\n        self.n_dimensions = n_dimensions\n        self.embeddings = None\n        self.manifold = None\n        self.visualizer = None",
        "detail": "src.word_manifold.examples.force_field_demo",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "src.word_manifold.examples.force_field_demo",
        "description": "src.word_manifold.examples.force_field_demo",
        "peekOfCode": "def main():\n    \"\"\"Run the force field visualization demo.\"\"\"\n    # Create and run simulation\n    demo = ForceFieldDemo(n_dimensions=3)\n    demo.prepare_components()\n    viz_path = demo.simulate_force_field()\n    logger.info(f\"\"\"\n    Force field visualization complete!\n    This demonstration shows how concepts move through a semantic force field:\n    - Red points are attractors (positive concepts)",
        "detail": "src.word_manifold.examples.force_field_demo",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "src.word_manifold.examples.force_field_demo",
        "description": "src.word_manifold.examples.force_field_demo",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass ForceFieldDemo:\n    def __init__(self, n_dimensions=3):\n        \"\"\"Initialize the force field demonstration.\n        Args:\n            n_dimensions (int): Number of dimensions for the semantic space\n        \"\"\"\n        self.n_dimensions = n_dimensions\n        self.embeddings = None\n        self.manifold = None",
        "detail": "src.word_manifold.examples.force_field_demo",
        "documentation": {}
    },
    {
        "label": "HyperdimensionalRitual",
        "kind": 6,
        "importPath": "src.word_manifold.examples.hyperdimensional_ritual",
        "description": "src.word_manifold.examples.hyperdimensional_ritual",
        "peekOfCode": "class HyperdimensionalRitual:\n    \"\"\"\n    A class demonstrating hyperdimensional visualization of Thelemic rituals.\n    \"\"\"\n    def __init__(\n        self,\n        n_dimensions: int = 5,  # We'll use 5D for richer semantic representation\n        output_dir: str = \"visualizations/hyperdimensional\"\n    ):\n        self.n_dimensions = n_dimensions",
        "detail": "src.word_manifold.examples.hyperdimensional_ritual",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "src.word_manifold.examples.hyperdimensional_ritual",
        "description": "src.word_manifold.examples.hyperdimensional_ritual",
        "peekOfCode": "def main():\n    \"\"\"Run the hyperdimensional ritual visualization example.\"\"\"\n    # Create and prepare the ritual\n    ritual = HyperdimensionalRitual(n_dimensions=5)\n    ritual.prepare_components()\n    # Create visualization\n    viz_path = ritual.visualize_ritual_transformation()\n    logger.info(f\"\"\"\n    Hyperdimensional ritual visualization complete!\n    The visualization shows the evolution of Thelemic concepts through a 5-dimensional",
        "detail": "src.word_manifold.examples.hyperdimensional_ritual",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "src.word_manifold.examples.hyperdimensional_ritual",
        "description": "src.word_manifold.examples.hyperdimensional_ritual",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass HyperdimensionalRitual:\n    \"\"\"\n    A class demonstrating hyperdimensional visualization of Thelemic rituals.\n    \"\"\"\n    def __init__(\n        self,\n        n_dimensions: int = 5,  # We'll use 5D for richer semantic representation\n        output_dir: str = \"visualizations/hyperdimensional\"\n    ):",
        "detail": "src.word_manifold.examples.hyperdimensional_ritual",
        "documentation": {}
    },
    {
        "label": "RitualWorking",
        "kind": 6,
        "importPath": "src.word_manifold.examples.ritual_evolution",
        "description": "src.word_manifold.examples.ritual_evolution",
        "peekOfCode": "class RitualWorking:\n    \"\"\"\n    A class that implements a complete magical working in word vector space.\n    \"\"\"\n    def _create_evolution_animation(self, key_terms):\n        \"\"\"\n        Create an animation of the evolution of machinic desires using fluid visual transformations and emergent patterns.\n        Args:\n            key_terms: List of key terms to highlight in the animation description\n        Returns:",
        "detail": "src.word_manifold.examples.ritual_evolution",
        "documentation": {}
    },
    {
        "label": "memoize",
        "kind": 2,
        "importPath": "src.word_manifold.examples.ritual_evolution",
        "description": "src.word_manifold.examples.ritual_evolution",
        "peekOfCode": "def memoize(func):\n    \"\"\"\n    Decorator for memoizing function results.\n    Results are cached in memory and on disk for persistence between runs.\n    \"\"\"\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        # Create a unique key based on function name and arguments\n        key_parts = [func.__name__]\n        # Add class name if it's a method",
        "detail": "src.word_manifold.examples.ritual_evolution",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "src.word_manifold.examples.ritual_evolution",
        "description": "src.word_manifold.examples.ritual_evolution",
        "peekOfCode": "def main():\n    \"\"\" Demonstrate the ritual evolution process. \"\"\"\n    ritual = RitualWorking(\n        ritual_name=\"True Will Discovery\",\n        ritual_intent=\"To discover and align with one's True Will through semantic transformation\"\n    )\n    # Prepare components\n    ritual.prepare_components()\n    # Perform the ritual\n    ritual.perform_ritual()",
        "detail": "src.word_manifold.examples.ritual_evolution",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "src.word_manifold.examples.ritual_evolution",
        "description": "src.word_manifold.examples.ritual_evolution",
        "peekOfCode": "logger = logging.getLogger(\"ritual_evolution\")\n# Directory for saving outputs\nOUTPUT_DIR = Path(\"ritual_outputs\")\nCACHE_DIR = Path(\".ritual_cache\")\n# Create cache directory if it doesn't exist\nCACHE_DIR.mkdir(exist_ok=True)\n# Function cache decorator with key based on function arguments\ndef memoize(func):\n    \"\"\"\n    Decorator for memoizing function results.",
        "detail": "src.word_manifold.examples.ritual_evolution",
        "documentation": {}
    },
    {
        "label": "OUTPUT_DIR",
        "kind": 5,
        "importPath": "src.word_manifold.examples.ritual_evolution",
        "description": "src.word_manifold.examples.ritual_evolution",
        "peekOfCode": "OUTPUT_DIR = Path(\"ritual_outputs\")\nCACHE_DIR = Path(\".ritual_cache\")\n# Create cache directory if it doesn't exist\nCACHE_DIR.mkdir(exist_ok=True)\n# Function cache decorator with key based on function arguments\ndef memoize(func):\n    \"\"\"\n    Decorator for memoizing function results.\n    Results are cached in memory and on disk for persistence between runs.\n    \"\"\"",
        "detail": "src.word_manifold.examples.ritual_evolution",
        "documentation": {}
    },
    {
        "label": "CACHE_DIR",
        "kind": 5,
        "importPath": "src.word_manifold.examples.ritual_evolution",
        "description": "src.word_manifold.examples.ritual_evolution",
        "peekOfCode": "CACHE_DIR = Path(\".ritual_cache\")\n# Create cache directory if it doesn't exist\nCACHE_DIR.mkdir(exist_ok=True)\n# Function cache decorator with key based on function arguments\ndef memoize(func):\n    \"\"\"\n    Decorator for memoizing function results.\n    Results are cached in memory and on disk for persistence between runs.\n    \"\"\"\n    @functools.wraps(func)",
        "detail": "src.word_manifold.examples.ritual_evolution",
        "documentation": {}
    },
    {
        "label": "ReadingStep",
        "kind": 6,
        "importPath": "src.word_manifold.examples.semantic_crystallization",
        "description": "src.word_manifold.examples.semantic_crystallization",
        "peekOfCode": "class ReadingStep:\n    \"\"\"Represents a single step in the reading sequence.\"\"\"\n    card: str  # The card or concept being integrated\n    keywords: List[str]  # Associated keywords/meanings\n    position: str  # Position or aspect in the reading (e.g., \"past\", \"present\", \"future\")\n    influence: float = 1.0  # Relative influence of this step (0-1)\nterms=[\n                # Major Arcana\n                \"fool\", \"magician\", \"priestess\", \"empress\", \"emperor\",\n                \"hierophant\", \"lovers\", \"chariot\", \"strength\", \"hermit\",",
        "detail": "src.word_manifold.examples.semantic_crystallization",
        "documentation": {}
    },
    {
        "label": "SemanticCrystallization",
        "kind": 6,
        "importPath": "src.word_manifold.examples.semantic_crystallization",
        "description": "src.word_manifold.examples.semantic_crystallization",
        "peekOfCode": "class SemanticCrystallization:\n    \"\"\"\n    Visualizes the crystallization of meaning during a reading sequence.\n    This class tracks how semantic space transforms as each new card or concept\n    is integrated, showing the accumulation and crystallization of meaning over time.\n    \"\"\"\n    def __init__(\n        self,\n        n_dimensions: int = 5,\n        output_dir: str = \"visualizations/crystallization\",",
        "detail": "src.word_manifold.examples.semantic_crystallization",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "src.word_manifold.examples.semantic_crystallization",
        "description": "src.word_manifold.examples.semantic_crystallization",
        "peekOfCode": "def main():\n    \"\"\"Run the semantic crystallization example.\"\"\"\n    # Create and prepare crystallization viewer\n    crystal = SemanticCrystallization(n_dimensions=5)\n    crystal.prepare_components()\n    # Example Celtic Cross reading sequence\n    reading_sequence = [\n        # Central cross\n        (\"present\", \"tower\", [\"disruption\", \"awakening\", \"revelation\"]),\n        (\"challenge\", \"death\", [\"transformation\", \"ending\", \"rebirth\"]),",
        "detail": "src.word_manifold.examples.semantic_crystallization",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "src.word_manifold.examples.semantic_crystallization",
        "description": "src.word_manifold.examples.semantic_crystallization",
        "peekOfCode": "logger = logging.getLogger(__name__)\n@dataclass\nclass ReadingStep:\n    \"\"\"Represents a single step in the reading sequence.\"\"\"\n    card: str  # The card or concept being integrated\n    keywords: List[str]  # Associated keywords/meanings\n    position: str  # Position or aspect in the reading (e.g., \"past\", \"present\", \"future\")\n    influence: float = 1.0  # Relative influence of this step (0-1)\nterms=[\n                # Major Arcana",
        "detail": "src.word_manifold.examples.semantic_crystallization",
        "documentation": {}
    },
    {
        "label": "ThelemaMetrics",
        "kind": 6,
        "importPath": "src.word_manifold.examples.thelemic_evolution",
        "description": "src.word_manifold.examples.thelemic_evolution",
        "peekOfCode": "class ThelemaMetrics:\n    \"\"\"\n    A class to calculate and track metrics for the Thelemic evolution of a word manifold.\n    Metrics include:\n    - Semantic entropy: Measure of semantic diversity\n    - Numerological alignment: Correspondence between numerological values\n    - Will manifestation: How closely the system follows its \"True Will\"\n    - Transmutation index: Degree of alchemical transformation\n    \"\"\"\n    def __init__(self):",
        "detail": "src.word_manifold.examples.thelemic_evolution",
        "documentation": {}
    },
    {
        "label": "BasicVisualizer",
        "kind": 6,
        "importPath": "src.word_manifold.examples.thelemic_evolution",
        "description": "src.word_manifold.examples.thelemic_evolution",
        "peekOfCode": "class BasicVisualizer:\n    \"\"\"\n    A basic visualization class for when the full visualizer is not available.\n    This creates simple 2D plots of the manifold's reduced representation.\n    \"\"\"\n    def __init__(self, manifold: VectorManifold, save_path: str):\n        \"\"\"\n        Initialize the basic visualizer.\n        Args:\n            manifold: The vector manifold to visualize",
        "detail": "src.word_manifold.examples.thelemic_evolution",
        "documentation": {}
    },
    {
        "label": "run_thelemic_evolution",
        "kind": 2,
        "importPath": "src.word_manifold.examples.thelemic_evolution",
        "description": "src.word_manifold.examples.thelemic_evolution",
        "peekOfCode": "def run_thelemic_evolution(\n    generations: int = 22,  # One for each Major Arcana\n    save_path: str = None,\n    model_name: str = \"bert-base-uncased\",\n    n_cells: int = 22,\n    random_state: int = 93  # Significant in Thelema/Crowley's work\n):\n    \"\"\"\n    Run the Thelemic evolution of the word manifold.\n    Args:",
        "detail": "src.word_manifold.examples.thelemic_evolution",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "src.word_manifold.examples.thelemic_evolution",
        "description": "src.word_manifold.examples.thelemic_evolution",
        "peekOfCode": "logger = logging.getLogger(__name__)\n# Add the project root to the Python path if running as a script\nif __name__ == \"__main__\":\n    project_root = str(Path(__file__).resolve().parents[3])\n    sys.path.insert(0, project_root)\n# Import Word Manifold components\nfrom word_manifold.embeddings.word_embeddings import WordEmbeddings\nfrom word_manifold.manifold.vector_manifold import VectorManifold, CellType\nfrom word_manifold.automata.cellular_rules import create_predefined_rules\nfrom word_manifold.automata.system import AutomataSystem, EvolutionPattern, SystemState",
        "detail": "src.word_manifold.examples.thelemic_evolution",
        "documentation": {}
    },
    {
        "label": "ShapePoint",
        "kind": 6,
        "importPath": "src.word_manifold.manifold.semantic_shape",
        "description": "src.word_manifold.manifold.semantic_shape",
        "peekOfCode": "class ShapePoint:\n    \"\"\"A point in the semantic shape with its associated properties.\"\"\"\n    position: np.ndarray\n    intensity: float  # Emotional/semantic intensity\n    direction: np.ndarray  # Flow direction\n    properties: Dict  # Additional shape properties\nclass SemanticShape:\n    \"\"\"\n    A class representing the shape of meaning in semantic space.\n    This captures both the geometric form and the dynamic properties",
        "detail": "src.word_manifold.manifold.semantic_shape",
        "documentation": {}
    },
    {
        "label": "SemanticShape",
        "kind": 6,
        "importPath": "src.word_manifold.manifold.semantic_shape",
        "description": "src.word_manifold.manifold.semantic_shape",
        "peekOfCode": "class SemanticShape:\n    \"\"\"\n    A class representing the shape of meaning in semantic space.\n    This captures both the geometric form and the dynamic properties\n    of a semantic expression (phrase, sentence, or text chunk).\n    \"\"\"\n    def __init__(\n        self,\n        phrase_embedding: PhraseEmbedding,\n        n_control_points: int = 10",
        "detail": "src.word_manifold.manifold.semantic_shape",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "src.word_manifold.manifold.semantic_shape",
        "description": "src.word_manifold.manifold.semantic_shape",
        "peekOfCode": "logger = logging.getLogger(__name__)\n@dataclass\nclass ShapePoint:\n    \"\"\"A point in the semantic shape with its associated properties.\"\"\"\n    position: np.ndarray\n    intensity: float  # Emotional/semantic intensity\n    direction: np.ndarray  # Flow direction\n    properties: Dict  # Additional shape properties\nclass SemanticShape:\n    \"\"\"",
        "detail": "src.word_manifold.manifold.semantic_shape",
        "documentation": {}
    },
    {
        "label": "Cell",
        "kind": 6,
        "importPath": "src.word_manifold.manifold.vector_manifold",
        "description": "src.word_manifold.manifold.vector_manifold",
        "peekOfCode": "class Cell:\n    \"\"\"\n    A cell in the manifold representing a region in the vector space.\n    \"\"\"\n    id: int\n    terms: Set[str]  # Words or phrases that belong to this cell\n    centroid: np.ndarray  # Center point of the cell in embedding space\n    type: CellType  # Type of cell with occult significance\n    numerological_value: int  # Numerological value of the cell\n    boundary_points: Optional[np.ndarray] = None  # Points defining the boundary (if available)",
        "detail": "src.word_manifold.manifold.vector_manifold",
        "documentation": {}
    },
    {
        "label": "ManifoldReducedState",
        "kind": 6,
        "importPath": "src.word_manifold.manifold.vector_manifold",
        "description": "src.word_manifold.manifold.vector_manifold",
        "peekOfCode": "class ManifoldReducedState(NamedTuple):\n    \"\"\"State of the reduced manifold for visualization and cellular operations.\"\"\"\n    points: np.ndarray         # 2D or 3D points\n    labels: List[int]          # Cell labels for each point\n    cell_centroids: np.ndarray # Reduced centroids\n    boundaries: Any            # Boundary representations (e.g., Voronoi)\nclass VectorManifold:\n    \"\"\"\n    A class representing a manifold in vector space for word and phrase embeddings.\n    This class handles the geometric relationships between embeddings,",
        "detail": "src.word_manifold.manifold.vector_manifold",
        "documentation": {}
    },
    {
        "label": "VectorManifold",
        "kind": 6,
        "importPath": "src.word_manifold.manifold.vector_manifold",
        "description": "src.word_manifold.manifold.vector_manifold",
        "peekOfCode": "class VectorManifold:\n    \"\"\"\n    A class representing a manifold in vector space for word and phrase embeddings.\n    This class handles the geometric relationships between embeddings,\n    including Voronoi tessellation and neighborhood calculations.\n    \"\"\"\n    def __init__(\n        self,\n        embeddings: Union[WordEmbeddings, PhraseEmbedding],\n        n_cells: int = 22,  # Default to 22 cells (major arcana)",
        "detail": "src.word_manifold.manifold.vector_manifold",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "src.word_manifold.manifold.vector_manifold",
        "description": "src.word_manifold.manifold.vector_manifold",
        "peekOfCode": "logger = logging.getLogger(__name__)\n@dataclass\nclass Cell:\n    \"\"\"\n    A cell in the manifold representing a region in the vector space.\n    \"\"\"\n    id: int\n    terms: Set[str]  # Words or phrases that belong to this cell\n    centroid: np.ndarray  # Center point of the cell in embedding space\n    type: CellType  # Type of cell with occult significance",
        "detail": "src.word_manifold.manifold.vector_manifold",
        "documentation": {}
    },
    {
        "label": "cli",
        "kind": 2,
        "importPath": "src.word_manifold.visualization.cli",
        "description": "src.word_manifold.visualization.cli",
        "peekOfCode": "def cli():\n    \"\"\"Word Manifold visualization tools.\"\"\"\n    pass\n@cli.command()\n@click.option('--interactive/--no-interactive', default=True, help='Enable/disable interactive mode')\n@click.option('--output-dir', default='visualizations', help='Output directory for visualizations')\n@click.option('--dimensions', default=3, help='Number of dimensions for visualization')\n@click.option('--model', default='glove-wiki-gigaword-300', help='model to use for embeddings')\ndef visualize(interactive, output_dir, dimensions, model):\n    \"\"\"Create visualizations of the word manifold.\"\"\"",
        "detail": "src.word_manifold.visualization.cli",
        "documentation": {}
    },
    {
        "label": "visualize",
        "kind": 2,
        "importPath": "src.word_manifold.visualization.cli",
        "description": "src.word_manifold.visualization.cli",
        "peekOfCode": "def visualize(interactive, output_dir, dimensions, model):\n    \"\"\"Create visualizations of the word manifold.\"\"\"\n    try:\n        # Initialize embeddings and manifold\n        embeddings = WordEmbeddings(model_name=model)\n        # Define example terms\n        terms = [\n            \"light\", \"darkness\", \"wisdom\", \"understanding\",\n            \"beauty\", \"strength\", \"mercy\", \"severity\"\n        ]",
        "detail": "src.word_manifold.visualization.cli",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "src.word_manifold.visualization.cli",
        "description": "src.word_manifold.visualization.cli",
        "peekOfCode": "logger = logging.getLogger(__name__)\n@click.group()\ndef cli():\n    \"\"\"Word Manifold visualization tools.\"\"\"\n    pass\n@cli.command()\n@click.option('--interactive/--no-interactive', default=True, help='Enable/disable interactive mode')\n@click.option('--output-dir', default='visualizations', help='Output directory for visualizations')\n@click.option('--dimensions', default=3, help='Number of dimensions for visualization')\n@click.option('--model', default='glove-wiki-gigaword-300', help='model to use for embeddings')",
        "detail": "src.word_manifold.visualization.cli",
        "documentation": {}
    },
    {
        "label": "VisualizationLayer",
        "kind": 6,
        "importPath": "src.word_manifold.visualization.hypertools_visualizer",
        "description": "src.word_manifold.visualization.hypertools_visualizer",
        "peekOfCode": "class VisualizationLayer:\n    \"\"\"A layer in the visualization stack.\"\"\"\n    def __init__(self, name: str, visible: bool = True):\n        self.name = name\n        self.visible = visible\n        self.data = {}\n        self.style = {}\n    def update(self, data: Dict[str, Any]) -> None:\n        \"\"\"Update layer data.\"\"\"\n        self.data.update(data)",
        "detail": "src.word_manifold.visualization.hypertools_visualizer",
        "documentation": {}
    },
    {
        "label": "HyperToolsVisualizer",
        "kind": 6,
        "importPath": "src.word_manifold.visualization.hypertools_visualizer",
        "description": "src.word_manifold.visualization.hypertools_visualizer",
        "peekOfCode": "class HyperToolsVisualizer:\n    \"\"\"Visualizer for high-dimensional data using HyperTools.\"\"\"\n    def __init__(self, \n                 word_embeddings: WordEmbeddings,\n                 output_dir: str = \"visualizations/hypertools\",\n                 interactive: bool = False,\n                 n_dimensions: int = 3,\n                 reduction_method: str = \"UMAP\",\n                 enable_sacred_geometry: bool = True,\n                 enable_audio: bool = False):",
        "detail": "src.word_manifold.visualization.hypertools_visualizer",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "src.word_manifold.visualization.hypertools_visualizer",
        "description": "src.word_manifold.visualization.hypertools_visualizer",
        "peekOfCode": "logger = logging.getLogger(__name__)\n# Filter specific warnings\nwarnings.filterwarnings('ignore', category=FutureWarning, module='sklearn')\nwarnings.filterwarnings('ignore', category=UserWarning, module='umap')\nclass VisualizationLayer:\n    \"\"\"A layer in the visualization stack.\"\"\"\n    def __init__(self, name: str, visible: bool = True):\n        self.name = name\n        self.visible = visible\n        self.data = {}",
        "detail": "src.word_manifold.visualization.hypertools_visualizer",
        "documentation": {}
    },
    {
        "label": "RitualPhase",
        "kind": 6,
        "importPath": "src.word_manifold.visualization.ritual_visualizer",
        "description": "src.word_manifold.visualization.ritual_visualizer",
        "peekOfCode": "class RitualPhase(Enum):\n    \"\"\"Phases of ritual transformation.\"\"\"\n    PREPARATION = auto()\n    INVOCATION = auto()\n    TRANSFORMATION = auto()\n    INTEGRATION = auto()\n    COMPLETION = auto()\n@dataclass\nclass RitualState:\n    \"\"\"Represents the current state of a ritual transformation.\"\"\"",
        "detail": "src.word_manifold.visualization.ritual_visualizer",
        "documentation": {}
    },
    {
        "label": "RitualState",
        "kind": 6,
        "importPath": "src.word_manifold.visualization.ritual_visualizer",
        "description": "src.word_manifold.visualization.ritual_visualizer",
        "peekOfCode": "class RitualState:\n    \"\"\"Represents the current state of a ritual transformation.\"\"\"\n    phase: RitualPhase\n    active_terms: Set[str]\n    transformed_terms: Set[str]\n    energy_level: float\n    resonance_pattern: Dict[HermeticPrinciple, float]\n    dominant_principle: HermeticPrinciple\n    timestamp: datetime\nclass RitualVisualizer:",
        "detail": "src.word_manifold.visualization.ritual_visualizer",
        "documentation": {}
    },
    {
        "label": "RitualVisualizer",
        "kind": 6,
        "importPath": "src.word_manifold.visualization.ritual_visualizer",
        "description": "src.word_manifold.visualization.ritual_visualizer",
        "peekOfCode": "class RitualVisualizer:\n    \"\"\"\n    Visualizes ritual transformations by combining semantic, geometric,\n    and energetic aspects into cohesive visual representations.\n    \"\"\"\n    def __init__(\n        self,\n        word_embeddings: WordEmbeddings,\n        output_dir: str = \"visualizations/rituals\",\n        n_dims: int = 3,",
        "detail": "src.word_manifold.visualization.ritual_visualizer",
        "documentation": {}
    },
    {
        "label": "SemanticNode",
        "kind": 6,
        "importPath": "src.word_manifold.visualization.semantic_tree_visualizer",
        "description": "src.word_manifold.visualization.semantic_tree_visualizer",
        "peekOfCode": "class SemanticNode:\n    \"\"\"Represents a node in the semantic tree with hierarchical relationships.\"\"\"\n    def __init__(self, text: str, embedding: np.ndarray):\n        \"\"\"\n        Initialize a semantic node.\n        Args:\n            text: The text content of the node\n            embedding: The vector embedding of the text\n        \"\"\"\n        self.text = text",
        "detail": "src.word_manifold.visualization.semantic_tree_visualizer",
        "documentation": {}
    },
    {
        "label": "SemanticTreeVisualizer",
        "kind": 6,
        "importPath": "src.word_manifold.visualization.semantic_tree_visualizer",
        "description": "src.word_manifold.visualization.semantic_tree_visualizer",
        "peekOfCode": "class SemanticTreeVisualizer:\n    \"\"\"Visualizer for semantic trees with customizable appearance and layout.\"\"\"\n    def __init__(\n        self,\n        output_dir: str = \"visualizations/semantic_trees\",\n        model_name: str = \"sentence-transformers/all-mpnet-base-v2\",\n        color_scheme: str = \"viridis\",\n        node_size_base: int = 1000,\n        min_similarity: float = 0.3\n    ):",
        "detail": "src.word_manifold.visualization.semantic_tree_visualizer",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "src.word_manifold.visualization.semantic_tree_visualizer",
        "description": "src.word_manifold.visualization.semantic_tree_visualizer",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass SemanticNode:\n    \"\"\"Represents a node in the semantic tree with hierarchical relationships.\"\"\"\n    def __init__(self, text: str, embedding: np.ndarray):\n        \"\"\"\n        Initialize a semantic node.\n        Args:\n            text: The text content of the node\n            embedding: The vector embedding of the text\n        \"\"\"",
        "detail": "src.word_manifold.visualization.semantic_tree_visualizer",
        "documentation": {}
    },
    {
        "label": "ExportConfig",
        "kind": 6,
        "importPath": "src.word_manifold.visualization.shape_visualizer",
        "description": "src.word_manifold.visualization.shape_visualizer",
        "peekOfCode": "class ExportConfig:\n    \"\"\"Configuration for exporting visualizations.\"\"\"\n    def __init__(\n        self,\n        format: str = \"mp4\",\n        dpi: int = 300,\n        fps: int = 60,\n        bitrate: int = 2000,\n        save_frames: bool = True,\n        output_dir: Optional[str] = None",
        "detail": "src.word_manifold.visualization.shape_visualizer",
        "documentation": {}
    },
    {
        "label": "ShapeVisualizer",
        "kind": 6,
        "importPath": "src.word_manifold.visualization.shape_visualizer",
        "description": "src.word_manifold.visualization.shape_visualizer",
        "peekOfCode": "class ShapeVisualizer:\n    \"\"\"\n    Advanced visualization class for semantic shapes with enhanced visual encoding.\n    \"\"\"\n    def __init__(\n        self,\n        color_scheme: str = \"semantic\",\n        use_textures: bool = True,\n        export_config: Optional[ExportConfig] = None\n    ):",
        "detail": "src.word_manifold.visualization.shape_visualizer",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "src.word_manifold.visualization.shape_visualizer",
        "description": "src.word_manifold.visualization.shape_visualizer",
        "peekOfCode": "logger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)  # Default to INFO level\n# Create formatters and handlers if they don't exist\nif not logger.handlers:\n    # Create console handler with formatting\n    console_handler = logging.StreamHandler()\n    console_handler.setLevel(logging.INFO)\n    console_formatter = logging.Formatter(\n        '%(asctime)s - %(name)s - [%(levelname)s] - %(message)s'\n    )",
        "detail": "src.word_manifold.visualization.shape_visualizer",
        "documentation": {}
    },
    {
        "label": "SymbolicPattern",
        "kind": 6,
        "importPath": "src.word_manifold.visualization.symbolic_visualizer",
        "description": "src.word_manifold.visualization.symbolic_visualizer",
        "peekOfCode": "class SymbolicPattern:\n    \"\"\"A pattern of symbols that can transform.\"\"\"\n    base_symbols: str  # Core symbols that make up the pattern\n    transformations: List[str]  # Sequence of transformation states\n    meaning: str  # Semantic meaning of the pattern\n    energy: float  # Current energy level (affects transformation rate)\n    resonance: Set[str]  # Terms that resonate with this pattern\nclass SymbolicVisualizer:\n    \"\"\"Creates living ASCII mandalas from semantic spaces.\"\"\"\n    # Symbol sets for different semantic qualities",
        "detail": "src.word_manifold.visualization.symbolic_visualizer",
        "documentation": {}
    },
    {
        "label": "SymbolicVisualizer",
        "kind": 6,
        "importPath": "src.word_manifold.visualization.symbolic_visualizer",
        "description": "src.word_manifold.visualization.symbolic_visualizer",
        "peekOfCode": "class SymbolicVisualizer:\n    \"\"\"Creates living ASCII mandalas from semantic spaces.\"\"\"\n    # Symbol sets for different semantic qualities\n    ABSTRACT_SYMBOLS = \"\"  # Abstract concepts\n    ORGANIC_SYMBOLS = \"~\"    # Natural/flowing concepts\n    TECH_SYMBOLS = \"\"       # Technological concepts\n    SACRED_SYMBOLS = \"\"      # Spiritual concepts\n    EMOTIONAL_SYMBOLS = \"\"    # Emotional concepts\n    def __init__(self, \n                 word_embeddings: WordEmbeddings,",
        "detail": "src.word_manifold.visualization.symbolic_visualizer",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "src.word_manifold.visualization.symbolic_visualizer",
        "description": "src.word_manifold.visualization.symbolic_visualizer",
        "peekOfCode": "logger = logging.getLogger(__name__)\n@dataclass\nclass SymbolicPattern:\n    \"\"\"A pattern of symbols that can transform.\"\"\"\n    base_symbols: str  # Core symbols that make up the pattern\n    transformations: List[str]  # Sequence of transformation states\n    meaning: str  # Semantic meaning of the pattern\n    energy: float  # Current energy level (affects transformation rate)\n    resonance: Set[str]  # Terms that resonate with this pattern\nclass SymbolicVisualizer:",
        "detail": "src.word_manifold.visualization.symbolic_visualizer",
        "documentation": {}
    },
    {
        "label": "CellType",
        "kind": 6,
        "importPath": "src.word_manifold.types",
        "description": "src.word_manifold.types",
        "peekOfCode": "class CellType(Enum):\n    \"\"\"Types of cells with occult correspondences.\"\"\"\n    ELEMENTAL = auto()   # Corresponds to the four elements\n    PLANETARY = auto()   # Corresponds to planetary influences\n    ZODIACAL = auto()    # Corresponds to zodiac signs\n    TAROT = auto()       # Corresponds to tarot archetypes\n    SEPHIROTIC = auto()  # Corresponds to Kabbalistic sephiroth\n    OTHER = auto()       # Default/unclassified\nclass DistanceType(Enum):\n    \"\"\"Types of distance metrics for cell relationships.\"\"\"",
        "detail": "src.word_manifold.types",
        "documentation": {}
    },
    {
        "label": "DistanceType",
        "kind": 6,
        "importPath": "src.word_manifold.types",
        "description": "src.word_manifold.types",
        "peekOfCode": "class DistanceType(Enum):\n    \"\"\"Types of distance metrics for cell relationships.\"\"\"\n    EUCLIDEAN = auto()      # Standard Euclidean distance\n    COSINE = auto()         # Cosine distance (semantic similarity)\n    NUMEROLOGICAL = auto()  # Distance weighted by numerological values\n    HYBRID = auto()         # Combination of semantic and numerological",
        "detail": "src.word_manifold.types",
        "documentation": {}
    },
    {
        "label": "mock_manifold",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def mock_manifold():\n    \"\"\"Create a mock manifold for testing automata systems.\"\"\"\n    mock = Mock()\n    # Mock the cells attribute with some test data\n    mock.cells = {\n        0: Mock(centroid=np.zeros(10)),\n        1: Mock(centroid=np.zeros(10))\n    }\n    # Mock transform to return the same vectors\n    mock.transform = MagicMock(return_value=np.zeros((2, 10)))",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "base_embeddings",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def base_embeddings():\n    \"\"\"Create a WordEmbeddings instance with test terms.\"\"\"\n    embeddings = WordEmbeddings()\n    test_terms = {\n        \"thelema\", \"will\", \"love\", \"magick\", \"ritual\",\n        \"knowledge\", \"wisdom\", \"power\", \"light\", \"dark\"\n    }\n    embeddings.load_terms(test_terms)\n    return embeddings\n@pytest.fixture",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "base_system",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def base_system(mock_manifold):\n    \"\"\"Create a base AutomataSystem for testing.\"\"\"\n    from word_manifold.automata.cellular_rules import create_predefined_rules\n    rules = create_predefined_rules()\n    return AutomataSystem(\n        manifold=mock_manifold,\n        rules_dict=rules,\n        sequences_dict={},\n        evolution_pattern=EvolutionPattern.THELEMIC,\n        save_path=\"test_outputs\"",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "TestAutomataSystem",
        "kind": 6,
        "importPath": "tests.test_automata",
        "description": "tests.test_automata",
        "peekOfCode": "class TestAutomataSystem:\n    \"\"\"Tests for the AutomataSystem class.\"\"\"\n    def test_initialization(self, base_system, mock_manifold):\n        \"\"\"Test system initialization and basic properties.\"\"\"\n        assert base_system.manifold == mock_manifold\n        assert len(base_system.rules) > 0\n        assert base_system.generation == 0\n        assert base_system.evolution_pattern == EvolutionPattern.THELEMIC\n    def test_evolution_state(self, base_system):\n        \"\"\"Test evolution state management.\"\"\"",
        "detail": "tests.test_automata",
        "documentation": {}
    },
    {
        "label": "TestCellularRules",
        "kind": 6,
        "importPath": "tests.test_automata",
        "description": "tests.test_automata",
        "peekOfCode": "class TestCellularRules:\n    \"\"\"Tests for cellular automata rules.\"\"\"\n    def test_predefined_rules(self):\n        \"\"\"Test creation and properties of predefined rules.\"\"\"\n        rules = create_predefined_rules()\n        # Check basic rule properties\n        assert len(rules) > 0\n        for name, rule in rules.items():\n            assert isinstance(rule, CellularRule)\n            # assert rule.name in str(name).lower().replace(' ', '_')  # More flexible name matching",
        "detail": "tests.test_automata",
        "documentation": {}
    },
    {
        "label": "mock_manifold",
        "kind": 2,
        "importPath": "tests.test_automata",
        "description": "tests.test_automata",
        "peekOfCode": "def mock_manifold():\n    mock = Mock()\n    # Mock the cells attribute with some test data\n    mock.cells = {\n        0: Mock(centroid=np.zeros(10)),\n        1: Mock(centroid=np.zeros(10))\n    }\n    # Mock transform to return the same vectors\n    mock.transform = MagicMock(return_value=np.zeros((2, 10)))\n    # Mock get_manifold_state to return a valid state",
        "detail": "tests.test_automata",
        "documentation": {}
    },
    {
        "label": "base_system",
        "kind": 2,
        "importPath": "tests.test_automata",
        "description": "tests.test_automata",
        "peekOfCode": "def base_system(mock_manifold):\n    rules = create_predefined_rules()\n    return AutomataSystem(\n        manifold=mock_manifold,\n        rules_dict=rules,\n        sequences_dict={},\n        evolution_pattern=EvolutionPattern.THELEMIC,\n        save_path=\"test_outputs\"\n    )\nclass TestAutomataSystem:",
        "detail": "tests.test_automata",
        "documentation": {}
    },
    {
        "label": "TestCell",
        "kind": 6,
        "importPath": "tests.test_core_components",
        "description": "tests.test_core_components",
        "peekOfCode": "class TestCell:\n    \"\"\"Tests for the Cell data structure.\"\"\"\n    def test_cell_creation(self):\n        \"\"\"Test Cell dataclass creation and basic properties.\"\"\"\n        cell = Cell(\n            id=1,\n            terms=[\"thelema\", \"will\"],\n            centroid=np.array([0.1, 0.2, 0.3]),\n            type=CellType.TAROT,\n            numerological_value=93",
        "detail": "tests.test_core_components",
        "documentation": {}
    },
    {
        "label": "TestVectorManifold",
        "kind": 6,
        "importPath": "tests.test_core_components",
        "description": "tests.test_core_components",
        "peekOfCode": "class TestVectorManifold:\n    \"\"\"Tests for the VectorManifold class.\"\"\"\n    def test_initialization(self, base_embeddings):\n        \"\"\"Test VectorManifold initialization and basic properties.\"\"\"\n        manifold = VectorManifold(base_embeddings)\n        # Check basic properties\n        assert manifold.term_to_index is not None\n        assert len(manifold.term_to_index) == len(base_embeddings.terms)\n        assert manifold.n_cells == 22  # Default value\n        assert manifold.reduction_dims == 3  # Default value",
        "detail": "tests.test_core_components",
        "documentation": {}
    },
    {
        "label": "TestWordEmbeddings",
        "kind": 6,
        "importPath": "tests.test_core_components",
        "description": "tests.test_core_components",
        "peekOfCode": "class TestWordEmbeddings:\n    \"\"\"Tests for the WordEmbeddings class.\"\"\"\n    def test_initialization(self):\n        \"\"\"Test WordEmbeddings initialization.\"\"\"\n        embeddings = WordEmbeddings()\n        assert embeddings.model is not None\n        assert embeddings.tokenizer is not None\n        assert len(embeddings.terms) == 0\n    def test_term_loading(self, base_embeddings):\n        \"\"\"Test loading terms and computing embeddings.\"\"\"",
        "detail": "tests.test_core_components",
        "documentation": {}
    },
    {
        "label": "word_embeddings",
        "kind": 2,
        "importPath": "tests.test_ritual_visualizer",
        "description": "tests.test_ritual_visualizer",
        "peekOfCode": "def word_embeddings():\n    \"\"\"Create a WordEmbeddings instance for testing.\"\"\"\n    embeddings = WordEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n    test_terms = [\"light\", \"wisdom\", \"truth\", \"love\", \"power\"]\n    embeddings.load_terms(test_terms)\n    return embeddings\n@pytest.fixture\ndef test_output_dir(tmp_path):\n    \"\"\"Create a temporary directory for test outputs.\"\"\"\n    output_dir = tmp_path / \"test_ritual_viz\"",
        "detail": "tests.test_ritual_visualizer",
        "documentation": {}
    },
    {
        "label": "test_output_dir",
        "kind": 2,
        "importPath": "tests.test_ritual_visualizer",
        "description": "tests.test_ritual_visualizer",
        "peekOfCode": "def test_output_dir(tmp_path):\n    \"\"\"Create a temporary directory for test outputs.\"\"\"\n    output_dir = tmp_path / \"test_ritual_viz\"\n    output_dir.mkdir(exist_ok=True)\n    return str(output_dir)\n@pytest.fixture\ndef ritual_visualizer(word_embeddings, test_output_dir):\n    \"\"\"Create a RitualVisualizer instance for testing.\"\"\"\n    return RitualVisualizer(\n        word_embeddings=word_embeddings,",
        "detail": "tests.test_ritual_visualizer",
        "documentation": {}
    },
    {
        "label": "ritual_visualizer",
        "kind": 2,
        "importPath": "tests.test_ritual_visualizer",
        "description": "tests.test_ritual_visualizer",
        "peekOfCode": "def ritual_visualizer(word_embeddings, test_output_dir):\n    \"\"\"Create a RitualVisualizer instance for testing.\"\"\"\n    return RitualVisualizer(\n        word_embeddings=word_embeddings,\n        output_dir=test_output_dir,\n        n_dims=3,\n        frame_duration=100,  # Faster for testing\n        energy_threshold=0.7,\n        resonance_threshold=0.8\n    )",
        "detail": "tests.test_ritual_visualizer",
        "documentation": {}
    },
    {
        "label": "test_initialization",
        "kind": 2,
        "importPath": "tests.test_ritual_visualizer",
        "description": "tests.test_ritual_visualizer",
        "peekOfCode": "def test_initialization(ritual_visualizer, test_output_dir):\n    \"\"\"Test proper initialization of RitualVisualizer.\"\"\"\n    assert ritual_visualizer.output_dir == test_output_dir\n    assert ritual_visualizer.n_dims == 3\n    assert ritual_visualizer.frame_duration == 100\n    assert ritual_visualizer.energy_threshold == 0.7\n    assert ritual_visualizer.resonance_threshold == 0.8\n    assert os.path.exists(test_output_dir)\n    assert isinstance(ritual_visualizer.states, list)\n    assert isinstance(ritual_visualizer.term_evolution, dict)",
        "detail": "tests.test_ritual_visualizer",
        "documentation": {}
    },
    {
        "label": "test_process_transformation",
        "kind": 2,
        "importPath": "tests.test_ritual_visualizer",
        "description": "tests.test_ritual_visualizer",
        "peekOfCode": "def test_process_transformation(ritual_visualizer):\n    \"\"\"Test processing of term transformations.\"\"\"\n    initial_terms = {\"light\", \"wisdom\"}\n    transformed_terms = {\"illumination\", \"understanding\"}\n    ritual_visualizer.process_transformation(\n        initial_terms,\n        transformed_terms,\n        RitualPhase.TRANSFORMATION\n    )\n    assert len(ritual_visualizer.states) == 1",
        "detail": "tests.test_ritual_visualizer",
        "documentation": {}
    },
    {
        "label": "test_calculate_energy_levels",
        "kind": 2,
        "importPath": "tests.test_ritual_visualizer",
        "description": "tests.test_ritual_visualizer",
        "peekOfCode": "def test_calculate_energy_levels(ritual_visualizer):\n    \"\"\"Test energy level calculations.\"\"\"\n    terms = {\"light\", \"wisdom\", \"truth\"}\n    energy = ritual_visualizer._calculate_energy_level(terms)\n    assert isinstance(energy, float)\n    assert 0 <= energy <= 1\ndef test_determine_resonance(ritual_visualizer):\n    \"\"\"Test resonance pattern determination.\"\"\"\n    terms = {\"light\", \"wisdom\", \"truth\"}\n    resonance = ritual_visualizer._determine_resonance_pattern(terms)",
        "detail": "tests.test_ritual_visualizer",
        "documentation": {}
    },
    {
        "label": "test_determine_resonance",
        "kind": 2,
        "importPath": "tests.test_ritual_visualizer",
        "description": "tests.test_ritual_visualizer",
        "peekOfCode": "def test_determine_resonance(ritual_visualizer):\n    \"\"\"Test resonance pattern determination.\"\"\"\n    terms = {\"light\", \"wisdom\", \"truth\"}\n    resonance = ritual_visualizer._determine_resonance_pattern(terms)\n    assert isinstance(resonance, dict)\n    assert all(isinstance(k, HermeticPrinciple) for k in resonance.keys())\n    assert all(isinstance(v, float) for v in resonance.values())\n    assert all(0 <= v <= 1 for v in resonance.values())\ndef test_identify_dominant_principle(ritual_visualizer):\n    \"\"\"Test dominant principle identification.\"\"\"",
        "detail": "tests.test_ritual_visualizer",
        "documentation": {}
    },
    {
        "label": "test_identify_dominant_principle",
        "kind": 2,
        "importPath": "tests.test_ritual_visualizer",
        "description": "tests.test_ritual_visualizer",
        "peekOfCode": "def test_identify_dominant_principle(ritual_visualizer):\n    \"\"\"Test dominant principle identification.\"\"\"\n    terms = {\"light\", \"wisdom\", \"truth\"}\n    principle = ritual_visualizer._identify_dominant_principle(terms)\n    assert isinstance(principle, HermeticPrinciple)\ndef test_generate_visualization(ritual_visualizer, test_output_dir):\n    \"\"\"Test visualization generation.\"\"\"\n    # Process a few transformations\n    initial = {\"light\", \"wisdom\"}\n    transformed = {\"illumination\", \"understanding\"}",
        "detail": "tests.test_ritual_visualizer",
        "documentation": {}
    },
    {
        "label": "test_generate_visualization",
        "kind": 2,
        "importPath": "tests.test_ritual_visualizer",
        "description": "tests.test_ritual_visualizer",
        "peekOfCode": "def test_generate_visualization(ritual_visualizer, test_output_dir):\n    \"\"\"Test visualization generation.\"\"\"\n    # Process a few transformations\n    initial = {\"light\", \"wisdom\"}\n    transformed = {\"illumination\", \"understanding\"}\n    final = {\"enlightenment\", \"knowledge\"}\n    ritual_visualizer.process_transformation(initial, transformed, RitualPhase.PREPARATION)\n    ritual_visualizer.process_transformation(transformed, final, RitualPhase.TRANSFORMATION)\n    # Generate visualization\n    output_path = ritual_visualizer.generate_visualization()",
        "detail": "tests.test_ritual_visualizer",
        "documentation": {}
    },
    {
        "label": "test_error_handling",
        "kind": 2,
        "importPath": "tests.test_ritual_visualizer",
        "description": "tests.test_ritual_visualizer",
        "peekOfCode": "def test_error_handling(ritual_visualizer):\n    \"\"\"Test error handling for invalid inputs.\"\"\"\n    # Empty term sets\n    with pytest.raises(ValueError):\n        ritual_visualizer.process_transformation(set(), {\"light\"}, RitualPhase.PREPARATION)\n    with pytest.raises(ValueError):\n        ritual_visualizer.process_transformation({\"light\"}, set(), RitualPhase.PREPARATION)\n    # Invalid terms\n    with pytest.raises(ValueError):\n        ritual_visualizer.process_transformation(",
        "detail": "tests.test_ritual_visualizer",
        "documentation": {}
    },
    {
        "label": "test_state_tracking",
        "kind": 2,
        "importPath": "tests.test_ritual_visualizer",
        "description": "tests.test_ritual_visualizer",
        "peekOfCode": "def test_state_tracking(ritual_visualizer):\n    \"\"\"Test proper tracking of ritual state history.\"\"\"\n    transformations = [\n        ({\"light\"}, {\"illumination\"}, RitualPhase.PREPARATION),\n        ({\"illumination\"}, {\"enlightenment\"}, RitualPhase.TRANSFORMATION),\n        ({\"enlightenment\"}, {\"wisdom\"}, RitualPhase.INTEGRATION)\n    ]\n    for initial, transformed, phase in transformations:\n        ritual_visualizer.process_transformation(initial, transformed, phase)\n    assert len(ritual_visualizer.states) == len(transformations)",
        "detail": "tests.test_ritual_visualizer",
        "documentation": {}
    },
    {
        "label": "visualizer",
        "kind": 2,
        "importPath": "tests.test_semantic_tree_visualizer",
        "description": "tests.test_semantic_tree_visualizer",
        "peekOfCode": "def visualizer():\n    \"\"\"Create a test visualizer instance.\"\"\"\n    return SemanticTreeVisualizer(\n        output_dir=\"test_outputs/semantic_trees\",\n        color_scheme=\"viridis\",\n        node_size_base=800,\n        min_similarity=0.3\n    )\n@pytest.fixture\ndef sample_embedding():",
        "detail": "tests.test_semantic_tree_visualizer",
        "documentation": {}
    },
    {
        "label": "sample_embedding",
        "kind": 2,
        "importPath": "tests.test_semantic_tree_visualizer",
        "description": "tests.test_semantic_tree_visualizer",
        "peekOfCode": "def sample_embedding():\n    \"\"\"Create a sample embedding vector.\"\"\"\n    return np.random.rand(768)  # Common embedding dimension\ndef test_semantic_node_creation(sample_embedding):\n    \"\"\"Test creation of semantic nodes.\"\"\"\n    node = SemanticNode(\"test\", sample_embedding)\n    assert node.text == \"test\"\n    assert node.level == 0\n    assert node.parent is None\n    assert len(node.children) == 0",
        "detail": "tests.test_semantic_tree_visualizer",
        "documentation": {}
    },
    {
        "label": "test_semantic_node_creation",
        "kind": 2,
        "importPath": "tests.test_semantic_tree_visualizer",
        "description": "tests.test_semantic_tree_visualizer",
        "peekOfCode": "def test_semantic_node_creation(sample_embedding):\n    \"\"\"Test creation of semantic nodes.\"\"\"\n    node = SemanticNode(\"test\", sample_embedding)\n    assert node.text == \"test\"\n    assert node.level == 0\n    assert node.parent is None\n    assert len(node.children) == 0\n    assert node.similarity_to_parent == 1.0\n    assert node.semantic_weight == 1.0\ndef test_semantic_node_child_addition(sample_embedding):",
        "detail": "tests.test_semantic_tree_visualizer",
        "documentation": {}
    },
    {
        "label": "test_semantic_node_child_addition",
        "kind": 2,
        "importPath": "tests.test_semantic_tree_visualizer",
        "description": "tests.test_semantic_tree_visualizer",
        "peekOfCode": "def test_semantic_node_child_addition(sample_embedding):\n    \"\"\"Test adding child nodes.\"\"\"\n    parent = SemanticNode(\"parent\", sample_embedding)\n    child = SemanticNode(\"child\", sample_embedding)\n    parent.add_child(child, similarity=0.8)\n    assert len(parent.children) == 1\n    assert child.parent == parent\n    assert child.level == 1\n    assert child.similarity_to_parent == 0.8\ndef test_semantic_weight_calculation(sample_embedding):",
        "detail": "tests.test_semantic_tree_visualizer",
        "documentation": {}
    },
    {
        "label": "test_semantic_weight_calculation",
        "kind": 2,
        "importPath": "tests.test_semantic_tree_visualizer",
        "description": "tests.test_semantic_tree_visualizer",
        "peekOfCode": "def test_semantic_weight_calculation(sample_embedding):\n    \"\"\"Test semantic weight calculation.\"\"\"\n    root = SemanticNode(\"root\", sample_embedding)\n    child = SemanticNode(\"child\", sample_embedding)\n    grandchild = SemanticNode(\"grandchild\", sample_embedding)\n    root.add_child(child, similarity=0.8)\n    child.add_child(grandchild, similarity=0.7)\n    assert root.calculate_semantic_weight() == 1.0\n    assert abs(child.calculate_semantic_weight() - 0.8 * 0.8) < 1e-6\n    assert abs(grandchild.calculate_semantic_weight() - 0.8 * 0.7 * 0.8 * 0.8) < 1e-6",
        "detail": "tests.test_semantic_tree_visualizer",
        "documentation": {}
    },
    {
        "label": "test_visualizer_initialization",
        "kind": 2,
        "importPath": "tests.test_semantic_tree_visualizer",
        "description": "tests.test_semantic_tree_visualizer",
        "peekOfCode": "def test_visualizer_initialization(visualizer):\n    \"\"\"Test visualizer initialization.\"\"\"\n    assert os.path.exists(visualizer.output_dir)\n    assert visualizer.color_scheme == \"viridis\"\n    assert visualizer.node_size_base == 800\n    assert visualizer.min_similarity == 0.3\ndef test_tree_building(visualizer):\n    \"\"\"Test building a semantic tree.\"\"\"\n    root = visualizer.build_semantic_tree(\n        root_text=\"machine learning\",",
        "detail": "tests.test_semantic_tree_visualizer",
        "documentation": {}
    },
    {
        "label": "test_tree_building",
        "kind": 2,
        "importPath": "tests.test_semantic_tree_visualizer",
        "description": "tests.test_semantic_tree_visualizer",
        "peekOfCode": "def test_tree_building(visualizer):\n    \"\"\"Test building a semantic tree.\"\"\"\n    root = visualizer.build_semantic_tree(\n        root_text=\"machine learning\",\n        related_terms=[\n            \"neural networks\",\n            \"deep learning\",\n            \"artificial intelligence\",\n            \"data science\"\n        ],",
        "detail": "tests.test_semantic_tree_visualizer",
        "documentation": {}
    },
    {
        "label": "test_tree_visualization",
        "kind": 2,
        "importPath": "tests.test_semantic_tree_visualizer",
        "description": "tests.test_semantic_tree_visualizer",
        "peekOfCode": "def test_tree_visualization(visualizer):\n    \"\"\"Test tree visualization.\"\"\"\n    root = visualizer.build_semantic_tree(\n        root_text=\"python\",\n        related_terms=[\n            \"programming\",\n            \"coding\",\n            \"software\",\n            \"development\"\n        ],",
        "detail": "tests.test_semantic_tree_visualizer",
        "documentation": {}
    },
    {
        "label": "test_minimum_similarity_threshold",
        "kind": 2,
        "importPath": "tests.test_semantic_tree_visualizer",
        "description": "tests.test_semantic_tree_visualizer",
        "peekOfCode": "def test_minimum_similarity_threshold(visualizer):\n    \"\"\"Test minimum similarity threshold.\"\"\"\n    visualizer.min_similarity = 0.9  # Set very high threshold\n    root = visualizer.build_semantic_tree(\n        root_text=\"test\",\n        related_terms=[\"unrelated1\", \"unrelated2\"],\n        max_depth=2,\n        branching_factor=2\n    )\n    # Should have no children due to high similarity threshold",
        "detail": "tests.test_semantic_tree_visualizer",
        "documentation": {}
    },
    {
        "label": "test_invalid_terms_handling",
        "kind": 2,
        "importPath": "tests.test_semantic_tree_visualizer",
        "description": "tests.test_semantic_tree_visualizer",
        "peekOfCode": "def test_invalid_terms_handling(visualizer):\n    \"\"\"Test handling of invalid terms.\"\"\"\n    root = visualizer.build_semantic_tree(\n        root_text=\"test\",\n        related_terms=[\"\", \"   \", None],  # Invalid terms\n        max_depth=2,\n        branching_factor=2\n    )\n    # Should create root node without children\n    assert root.text == \"test\"",
        "detail": "tests.test_semantic_tree_visualizer",
        "documentation": {}
    },
    {
        "label": "embeddings",
        "kind": 2,
        "importPath": "tests.test_word_embeddings",
        "description": "tests.test_word_embeddings",
        "peekOfCode": "def embeddings():\n    \"\"\"Create a WordEmbeddings instance for testing.\"\"\"\n    return WordEmbeddings()\ndef test_initialization():\n    \"\"\"Test basic initialization with default model.\"\"\"\n    we = WordEmbeddings()\n    assert we.model_name == WordEmbeddings.DEFAULT_MODEL\n    assert we.cache_size == 1024\n    assert isinstance(we.embeddings, dict)\ndef test_model_fallback():",
        "detail": "tests.test_word_embeddings",
        "documentation": {}
    },
    {
        "label": "test_initialization",
        "kind": 2,
        "importPath": "tests.test_word_embeddings",
        "description": "tests.test_word_embeddings",
        "peekOfCode": "def test_initialization():\n    \"\"\"Test basic initialization with default model.\"\"\"\n    we = WordEmbeddings()\n    assert we.model_name == WordEmbeddings.DEFAULT_MODEL\n    assert we.cache_size == 1024\n    assert isinstance(we.embeddings, dict)\ndef test_model_fallback():\n    \"\"\"Test fallback to backup model with invalid model name.\"\"\"\n    we = WordEmbeddings(model_name=\"invalid_model_name\")\n    assert we.model_name == WordEmbeddings.BACKUP_MODEL",
        "detail": "tests.test_word_embeddings",
        "documentation": {}
    },
    {
        "label": "test_model_fallback",
        "kind": 2,
        "importPath": "tests.test_word_embeddings",
        "description": "tests.test_word_embeddings",
        "peekOfCode": "def test_model_fallback():\n    \"\"\"Test fallback to backup model with invalid model name.\"\"\"\n    we = WordEmbeddings(model_name=\"invalid_model_name\")\n    assert we.model_name == WordEmbeddings.BACKUP_MODEL\ndef test_embedding_generation(embeddings):\n    \"\"\"Test embedding generation for single and multiple terms.\"\"\"\n    # Single term\n    term = \"test\"\n    embedding = embeddings.get_embedding(term)\n    assert isinstance(embedding, np.ndarray)",
        "detail": "tests.test_word_embeddings",
        "documentation": {}
    },
    {
        "label": "test_embedding_generation",
        "kind": 2,
        "importPath": "tests.test_word_embeddings",
        "description": "tests.test_word_embeddings",
        "peekOfCode": "def test_embedding_generation(embeddings):\n    \"\"\"Test embedding generation for single and multiple terms.\"\"\"\n    # Single term\n    term = \"test\"\n    embedding = embeddings.get_embedding(term)\n    assert isinstance(embedding, np.ndarray)\n    assert embedding.shape == (embeddings.get_embedding_dim(),)\n    # Multiple terms\n    terms = [\"test\", \"example\", \"word\"]\n    batch_embeddings = embeddings.get_embeddings(terms)",
        "detail": "tests.test_word_embeddings",
        "documentation": {}
    },
    {
        "label": "test_embedding_caching",
        "kind": 2,
        "importPath": "tests.test_word_embeddings",
        "description": "tests.test_word_embeddings",
        "peekOfCode": "def test_embedding_caching(embeddings):\n    \"\"\"Test that embeddings are properly cached.\"\"\"\n    term = \"cache_test\"\n    # First call should compute embedding\n    first_embedding = embeddings.get_embedding(term)\n    # Second call should return cached value\n    second_embedding = embeddings.get_embedding(term)\n    assert np.array_equal(first_embedding, second_embedding)\n    assert term in embeddings.embeddings\ndef test_similar_terms(embeddings):",
        "detail": "tests.test_word_embeddings",
        "documentation": {}
    },
    {
        "label": "test_similar_terms",
        "kind": 2,
        "importPath": "tests.test_word_embeddings",
        "description": "tests.test_word_embeddings",
        "peekOfCode": "def test_similar_terms(embeddings):\n    \"\"\"Test finding similar terms.\"\"\"\n    # Load some test terms\n    test_terms = [\"king\", \"queen\", \"prince\", \"princess\", \"castle\"]\n    embeddings.load_terms(test_terms)\n    similar = embeddings.find_similar_terms(\"king\", n=2)\n    assert isinstance(similar, list)\n    assert len(similar) == 2\n    assert all(t in test_terms for t in similar)\n    assert \"king\" not in similar  # Should not include the query term",
        "detail": "tests.test_word_embeddings",
        "documentation": {}
    },
    {
        "label": "test_numerological_value",
        "kind": 2,
        "importPath": "tests.test_word_embeddings",
        "description": "tests.test_word_embeddings",
        "peekOfCode": "def test_numerological_value(embeddings):\n    \"\"\"Test numerological value calculation.\"\"\"\n    # Test basic calculation\n    assert embeddings.calculate_numerological_value(\"test\") <= 21\n    assert embeddings.calculate_numerological_value(\"\") == 0\n    # Test reduction to Tarot range\n    value = embeddings.calculate_numerological_value(\"pneumonoultramicroscopicsilicovolcanoconiosis\")\n    assert 0 <= value <= 21\ndef test_term_info(embeddings):\n    \"\"\"Test comprehensive term information retrieval.\"\"\"",
        "detail": "tests.test_word_embeddings",
        "documentation": {}
    },
    {
        "label": "test_term_info",
        "kind": 2,
        "importPath": "tests.test_word_embeddings",
        "description": "tests.test_word_embeddings",
        "peekOfCode": "def test_term_info(embeddings):\n    \"\"\"Test comprehensive term information retrieval.\"\"\"\n    info = embeddings.get_term_info(\"testing\")\n    assert isinstance(info, dict)\n    assert \"embedding\" in info\n    assert \"numerological_value\" in info\n    assert \"length\" in info\n    assert info[\"length\"] == 7\ndef test_error_handling(embeddings):\n    \"\"\"Test error handling for various edge cases.\"\"\"",
        "detail": "tests.test_word_embeddings",
        "documentation": {}
    },
    {
        "label": "test_error_handling",
        "kind": 2,
        "importPath": "tests.test_word_embeddings",
        "description": "tests.test_word_embeddings",
        "peekOfCode": "def test_error_handling(embeddings):\n    \"\"\"Test error handling for various edge cases.\"\"\"\n    # Empty string\n    embedding = embeddings.get_embedding(\"\")\n    assert isinstance(embedding, np.ndarray)\n    assert not np.any(embedding)  # Should be zero vector\n    # Very long input\n    long_text = \"a\" * 1000\n    embedding = embeddings.get_embedding(long_text)\n    assert isinstance(embedding, np.ndarray)",
        "detail": "tests.test_word_embeddings",
        "documentation": {}
    },
    {
        "label": "test_batch_processing",
        "kind": 2,
        "importPath": "tests.test_word_embeddings",
        "description": "tests.test_word_embeddings",
        "peekOfCode": "def test_batch_processing(embeddings):\n    \"\"\"Test batch processing efficiency.\"\"\"\n    # Generate a large batch of terms\n    terms = [f\"term_{i}\" for i in range(100)]\n    # Process in batch\n    batch_results = embeddings.get_embeddings(terms)\n    assert len(batch_results) == len(terms)\n    assert all(isinstance(e, np.ndarray) for e in batch_results.values())\n    # Verify dimensions\n    dim = embeddings.get_embedding_dim()",
        "detail": "tests.test_word_embeddings",
        "documentation": {}
    },
    {
        "label": "test_word_embeddings_initialization",
        "kind": 2,
        "importPath": "tests.test_word_embeddings",
        "description": "tests.test_word_embeddings",
        "peekOfCode": "def test_word_embeddings_initialization():\n    \"\"\"Test that WordEmbeddings initializes with default model.\"\"\"\n    embeddings = WordEmbeddings()\n    assert embeddings.model is not None\n    assert isinstance(embeddings.model, SentenceTransformer)\ndef test_word_embeddings_fallback():\n    \"\"\"Test that WordEmbeddings falls back to backup model.\"\"\"\n    embeddings = WordEmbeddings(model_name=\"invalid_model_name\")\n    assert embeddings.model is not None\n    assert isinstance(embeddings.model, SentenceTransformer)",
        "detail": "tests.test_word_embeddings",
        "documentation": {}
    },
    {
        "label": "test_word_embeddings_fallback",
        "kind": 2,
        "importPath": "tests.test_word_embeddings",
        "description": "tests.test_word_embeddings",
        "peekOfCode": "def test_word_embeddings_fallback():\n    \"\"\"Test that WordEmbeddings falls back to backup model.\"\"\"\n    embeddings = WordEmbeddings(model_name=\"invalid_model_name\")\n    assert embeddings.model is not None\n    assert isinstance(embeddings.model, SentenceTransformer)\ndef test_embedding_generation():\n    \"\"\"Test that embeddings are generated correctly.\"\"\"\n    embeddings = WordEmbeddings()\n    terms = [\"test\", \"example\", \"word\"]\n    embeddings.load_terms(terms)",
        "detail": "tests.test_word_embeddings",
        "documentation": {}
    },
    {
        "label": "test_embedding_generation",
        "kind": 2,
        "importPath": "tests.test_word_embeddings",
        "description": "tests.test_word_embeddings",
        "peekOfCode": "def test_embedding_generation():\n    \"\"\"Test that embeddings are generated correctly.\"\"\"\n    embeddings = WordEmbeddings()\n    terms = [\"test\", \"example\", \"word\"]\n    embeddings.load_terms(terms)\n    # Test single term embedding\n    emb = embeddings.get_embedding(\"test\")\n    assert isinstance(emb, np.ndarray)\n    assert len(emb.shape) == 1\n    assert emb.shape[0] == embeddings.get_embedding_dim()",
        "detail": "tests.test_word_embeddings",
        "documentation": {}
    },
    {
        "label": "test_similarity_search",
        "kind": 2,
        "importPath": "tests.test_word_embeddings",
        "description": "tests.test_word_embeddings",
        "peekOfCode": "def test_similarity_search():\n    \"\"\"Test finding similar terms.\"\"\"\n    embeddings = WordEmbeddings()\n    terms = [\"king\", \"queen\", \"prince\", \"princess\", \"duke\", \"duchess\"]\n    embeddings.load_terms(terms)\n    similar = embeddings.find_similar_terms(\"king\", n=2)\n    assert len(similar) == 2\n    assert \"king\" not in similar  # Should not include the query term\n    assert all(isinstance(term, str) for term in similar)\ndef test_numerological_values():",
        "detail": "tests.test_word_embeddings",
        "documentation": {}
    },
    {
        "label": "test_numerological_values",
        "kind": 2,
        "importPath": "tests.test_word_embeddings",
        "description": "tests.test_word_embeddings",
        "peekOfCode": "def test_numerological_values():\n    \"\"\"Test numerological value calculation.\"\"\"\n    embeddings = WordEmbeddings()\n    value = embeddings.calculate_numerological_value(\"test\")\n    assert isinstance(value, int)\n    assert 0 <= value <= 21  # For Tarot-based numerology",
        "detail": "tests.test_word_embeddings",
        "documentation": {}
    },
    {
        "label": "CodeChangeHandler",
        "kind": 6,
        "importPath": "dev_watch",
        "description": "dev_watch",
        "peekOfCode": "class CodeChangeHandler(FileSystemEventHandler):\n    \"\"\"Handle file system change events.\"\"\"\n    def __init__(self):\n        self.last_run = 0\n        self.debounce_seconds = 2.0  # Minimum seconds between runs\n    def on_modified(self, event):\n        if event.is_directory:\n            return\n        # Only process Python files\n        if not event.src_path.endswith('.py'):",
        "detail": "dev_watch",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "dev_watch",
        "description": "dev_watch",
        "peekOfCode": "def main():\n    \"\"\"Run the development watch script.\"\"\"\n    # Create an observer and event handler\n    observer = Observer()\n    handler = CodeChangeHandler()\n    # Watch both src and tests directories\n    paths_to_watch = [\"src\", \"tests\"]\n    for path in paths_to_watch:\n        observer.schedule(handler, path, recursive=True)\n    # Start the observer",
        "detail": "dev_watch",
        "documentation": {}
    }
]